rcn;id;acronym;status;programme;topics;frameworkProgramme;title;startDate;endDate;projectUrl;objective;totalCost;ecMaxContribution;call;fundingScheme;coordinator;coordinatorCountry;participants;participantCountries;subjects
11881;EV4V0111;EROS 2000;;FP1-ENVPROT 4C;;FP1;EUROPEAN RIVER OCEAN SYSTEM;01/02/1988;31/05/1990;;"TO INVESTIGATE THE BIOGEOCHEMICAL INTERACTIONS AFFECTING THE CYCLING AND TRANSFORMATION OF POLLUTANTS AND NUTRIENTS IN EUROPEAN COASTAL WATERS AND THEIR ENVIRONMENTAL IMPLICATIONS.

THE EROS 2000 PROJECT (EUROPEAN RIVER OCEAN SYSTEM) IS A LARGE-SCALE INTERDISCIPLINARY RESEARCH PROGRAMME BETWEEN 26 LABORATORIES FROM 11 EC-MEMBER STATES AIMING : 
- TO INVESTIGATE QUANTITATIVELY THE MAJOR SOURCES, CYCLES AND FATE OF NUTRIENTS AND MAJOR ORGANIC AND INORGANIC POLLUTANTS IN CONTRASTING EUROPEAN COASTAL REGIONS; 
- TO INVESTIGATE THE MECHANISMS AND RATES OF PROCESSES CONTROLLING BOTH THE BOUNDARY EXCHANGES AND THE INTERNAL CYCLING AND TRANSFORMATION OF METALS, NITROGEN AND ORGANICS; 
- TO STRENGHTEN THE SCIENTIFIC BASIS FOR THE MANAGEMENT OF WASTE DISPOSAL PROGRAMMES BY INTEGRATING THE CHEMICAL, BIOLOGICAL AND PHYSICAL RESULTS INTO PROCESS-SPECIFIC MODELS AND REGIONAL BIOGEOCHEMICAL MODELS IN REGARD TO INTERACTIONS BETWEEN NUTRIENTS AND POLLUTANTS. 

TO ACHIEVE THESE AIMS, EROS 2000 IS PLANNED AROUND THE FOLLOWING SUB-PROJECTS : 
I. INTEGRATION: MODELLING, STATISTICS AND REMOTE SENSING. 
II. BIO-ORGANIC PROCESSES: NUTRIENTS FLUXES AND EUTROPHICATION, ORGANIC POLLUTANTS AND BIOMARKERS. 
III. INORGANIC PROCESSES: INPUT, SPECIFICATION AND REACTIVITY OF TRACE METALS AND METALLOIDS. 
IV. PARTICULATES: SOURCES, TRANSPORT AND DEPOSITION RATES. 

IN ADDITION TO ASSESSING THE IMMEDIATE FATE OFF ANTHROPOGENIC POLLUTANTS, THE EROS 2000 PROJECT WILL ALSO ADDRESS A RANGE OF PROBLEMS OF STRATEGIC IMPORTANCE. ACCURATE EVALUATIONS OF RIVERINE INPUT WILL BE COMPARED TO ATMOSPHERIC INPUT DATA, AND ASSOCIATED PROCESSES WILL BE STUDIED IN ORDER TO IMPROVE THE KNOWLEDGE ABOUT CONTAMINATION PATHWAYS IN THE MARINE COASTAL ENVIRONMENT. STUDIES OF RELATIONSHIP BETWEEN BENTHIC PROCESSES AND PRIMARY PRODUCTION WILL CONTRIBUTE TO THE CONTROL OF LONG-TERM COASTAL EUTROPHICATION. DURING AN INITIAL PHASE OF TWO YEARS (1988-1989) THE EROS 2000 PROJECT WILL BE CARRIED OUT IN A PILOT ZONE LOCATED IN THE NW-MEDITERRANEAN SEA. AFTERWARDS IT IS ENVISAGED TO EXTEND THE PROJECT TO OTHER COASTAL REGIONS OF EUROPEAN SEAS.";;;;CSC;Centre National de la Recherche Scientifique (CNRS);FR;"University College Dublin;UNIVERSITY OF WALES - BANGOR;University of Southampton;Consiglio Nazionale delle Ricerche (CNR);NATIONAL RESEARCH COUNCIL OF ITALY;Consejo Superior de Investigaciones Cientòficas;INSTITUTO SUPERIOR TECNICO;FORSCHUNGSZENTRUM JUELICH GMBH;Netherlands Institute for Sea Research;UNIVERSITY OF AARHUS;NATIONAL AND KAPODISTRIAN UNIVERSITY OF ATHENS;UNIVERSITY OF HAMBURG;UNIVERSITE LIBRE DE BRUXELLES;UNIVERSITE DE LIEGE*ULG;THE UNIVERSITY OF LIVERPOOL;NERC Centre of Coastal and Marine Sciences";"IE;UK;IT;ES;PT;DE;NL;DK;EL;BE";
28481;ST2*0389;ILIHA;;FP1-STIMULATION 1C;;FP1;IBERIAN LITHOSPHERE HETEROGENEITY AND ANISOTROPY;01/06/1988;31/05/1992;;A large part of the lithosphere is to some extent seismically anisotrophic and laterally heterogeneous. Models that assume isotrophy and homogeneous geology are inadequate to explain details of lithospheric structure in complex areas - which are usually the ones of most interest. In the last ten years, much emphasis has been placed on learning more about these important features of the earth's crust and mantle. Most of this research has been carried out by earth scientists from European institutions. Moreover, many recent advances in this field have originated in Europe where the number of workers engaged in both practical and theoretical research is steadily increasing.;;;;CSC;Instituto Geográfico Nacional;ES;"Instituto y Observatorio de la Marina;INSTITUTO DE METEOROLOGIA;UNIVERSIDAD COMPLUTENSE DE MADRID;WISE & MUNRO LEARNING RESEARCH;Centre National de la Recherche Scientifique (CNRS);Consiglio Nazionale delle Ricerche (CNR);DUBLIN INSTITUTE FOR ADVANCED STUDIES;Generalitat de Catalunya;Instituto Nacional de Investigação Científica;UNIVERSITAT DE BARCELONA;UNIVERSITAET KARLSRUHE (TECHNISCHE HOCHSCHULE);UNIVERSITY OF COPENHAGEN;UNIVERSITE LOUIS PASTEUR, STRASBOURG 1";"ES;PT;NL;FR;IT;IE;DE;DK";
8407;419;IMU;;FP1-ESPRIT 1;;FP1;Image and Movement Understanding;01/12/1984;01/12/1989;;"Research in the IMU project was directed to understanding the computational bases of vision and movement, with particular reference to scene understanding and cursive script understanding. 
In scene understanding (based on stereo pairs or multiple views of pictorial images as input to the system), the project focused on the interface between the early stages of computation, which provide a rich but ambiguous description in terms of low-level features, and knowledge-based processing, which generates descriptions of the 3-D organisation of the visual world compatible with the properties of the physical world. Cognitive modelling techniques based on a functional description of objects and perce ptual rules were studied. The ultimate goal was to merge the data-driven and the knowledge-driven recognitionapproaches. 
 With regard to cursive script, basic knowledge still needs to be acquired about the mapping from linguistic material to hand trajectories; the aims of the project was to understand the writing process more than to recognise it. Techniques to code cursive script signals into symbolic descriptions were studied. 
Machine vision software (MAVIS) provides an image processing development environment with libraries aimed at normal and high performance requirements.

Research in the project was directed to understanding the computational bases of vision and movement, with particular reference to scene understanding and cursive script understanding. In scene understanding (based on stereo paris or multiple views of pictorial images as input to the system), the project focused on the interface between the early stages of computation, which provide a rich but ambiguous description in terms of low level features, and knowledge based processing, which generates descriptions of the 3-dimensional organization of the visual world compatible with the properties of the physical world. Cognitive modelling techniques based on a functional description of objects and perceptual rules were studied. The ultimate goal was to merge the data driven and the knowledge driven recognition approaches. With regard to cursive script, basic knowledge still needs to be acquired about the mapping from linguistic material to hand trajectories; the aim of the project was to understand the writing process more than to recognise it. Techniques to code cursive script signals into symbolic descriptions were studied. Basic libraries of computational modules that perform early processing of image data (including the integration of stereo and motion algorithms to obtain depth information) and cursive script data were developed. A portable interactive software environment was developed. This makes possible the generation and interrogation of multiple regional representations of images or image sequences (iconic representations, regional representations, contour representations). Cognitive driven modules that interface with low level representations of images using either basic perceptual rules for dealing with occlusions of surfaces in low level representations or semantic representations of objects for interpreting perceptual representations and describing scenes have been developed. The firmware necessary for the real time acquisition of sequences of stereo pairs o f images has been developed.
The following results were obtained: 
-Development of basic libraries of computational modules that perform early processing of image data (including the integration of stereo and motion algorithms to obtain depth information) and cursive script data. 
 -Development of a portable interactive software environment, VIS. This makes possible the generation and interrogation of multiple regional representations of images or image sequences (iconic representations, regional representations, contour representa tions). It has been implemented on PC-AT, Transputer network, 68020, VAX, etc. 
-Development of cognitive-driven modules that interface with low-level representations of images: 
.using basic perceptual rules for dealing with occlusions of surfaces in low level representations; 
.using semantic representations of objects for interpreting perceptual representations and describing scenes. 
-Development of the firmware necessary for the real-time acquisition of sequences of stereo pairs of images on the VDS Eidobrain workstation and the porting of VIS on the Eidobrain. 
Exploitation 
The results of the project will serve the R&D community, both academic and industrial, as conceptual and computational support when developing specific applications of image or movement analysis. Moreover, the VIS system, incorporating well-engineered implementations of advanced algorithms, could form the basis for a marketable product.";;;;;Università degli Studi di Genova;IT;"TRINITY COLLEGE DUBLIN;KATHOLIEKE UNIVERSITEIT NIJMEGEN;VIDEO DISPLAY SYSTEMS SRL;CAPTEC-COMPUTER APPLIED TECHNICS";"IE;NL;IT";
8882;1647;COSINE;;FP1-ESPRIT 1;;FP1;Cooperation for Open Systems Interconnection Networking in Europe;01/01/1990;01/01/1993;;"COSINE's aims are to: 
establish a pan-European computer-based network infrastructure that enables research workers to communicate with each other using Open Systems 
facilitate the introduction of and contribute to the market pull for Open Systems Interconnection (OSI) 
ensure that the infrastructure established becomes financially self-supporting. 

The project began with a specification phase undertaken by RARE (Rseaux Associs pour la Recherche Europenne) which concluded in autumn 1988. During 1989, work began on the implementation phase, again undertaken by RARE, which has established the COSINE Project Management Unit (CPMU) to carry out the work on its behalf. COSINE includes a number of subprojects and pilot services. The first pilot service to be available was the IXI X.25 backbone network. Several more are now underway, expanding on the ser vices already used at local and national level to bring Europe-wide connectivity in electronic mail, directories and information services. Further sub-projects and services are being established. The aim is that the complete infrastructure should be self-sustaining by the end of the COSINE implementation phase. 
The sub-projects being implemented are: 
ftam north american gateway 
international x.500 directory services (paradise) 
support and information service (concise) 
activities to support typical international user groups 
osi connectionless-mode network service trials. 
Contracts for ftam interoperability testing and full-screen terminal services sub-projects are under negotiation, and one on security mechanisms is being prepared. The pilot services provided to the user community are ixi and x.400 mhs message-handling services (interworking of national R&D management domains and US gateway).";;;;;RARE;NL;"Garr;HEANET;JANET;RCCN;ARIADNE;VUB-ULB;SURFNET;COSINE;SWITCH;NORDUnet;ACOnet;REUNIR;DFN";"IT;IE";
8441;1510;PALABRE;;FP1-ESPRIT 1;;FP1;Integration of Artificial Intelligence, Vocal I/O and Natural Language Dialogue: Application to Directory Services;10/03/1986;10/03/1990;;"The PALABRE project aimed to define and realise an acquisition and interrogation system for a large and evolving knowledge base. Information, interrogation and updating were performed using natural language. The input-outputs were to be either textual or vocal (speech understanding and synthesis). Common tools and methods were to be developed independently so that several languages (French, English, Italian) could be used. Requests were to be converted with the help of inference rules and sent to an intelligent retrieval process based on semantic knowledge representation. LISP and PROLOG on a LISP machine were used. The feasibility of such a system were to be demonstrated through a phone directory 'Yellow Pages' prototype application in Italian, English and French. . 
The project aimed to define and realise an acquisition and interrogation system for a large and evolving knowledge base. Information, interrogation and updating were performed using natural language. The input/outputs were either textual or vocal (speech understanding and synthesis). Common tools and methods were developed independently so that several languages (French, English, Italian) could be used. Requests were converted with the help of interference rules and sent to an intelligent retrieval process based on semantic knowledge representation. LISP and PROLOG on a LISP machine were used. Different parts of the system were identified and their interfaces defined. The general architecture was based on a blackboard approach to combine several sources of knowledge. Two different approaches were proposed to parse a query set by the user: a deterministic parser for written input, and an augmented transition network parser for spoken input. The knowledge was represented using KL-ONE. The deduction module allowing the interpretation of a user query by the knowledge base and the answer generation module were investigated.
Different parts of the system were identified and their interfaces defined. The general architecture was based on a blackboard approach to combine several sources of knowledge. Two different approaches were proposed to parse a query inputted by the user: a deterministic parser for written input, and an augmented transition network parser for spoken input. The knowledge was represented using KL-ONE. The deduction module allowing the interpretation of a user query by the knowledge-base and the answer generation module were investigated. 
Exploitations 
PALABRE served as a preliminary study for subsequent projects in the field of speech processing.";;;;;SOCIETE ETUDES SYSTEMS AUTOMATIONS (SESA);FR;"CNET France Télécom;Centre National de la Recherche Scientifique (CNRS);Sarin Telematica SpA;British Telecom plc (BT);GSI-ERLI";"FR;IT;UK";
8738;28;MULTOS;;FP1-ESPRIT 1;;FP1;A Multimedia Filing System;01/02/1985;01/02/1990;;"The aim of MULTOS was to develop an efficient and cost-effective system for filing and retrieving multimedia documents in the office environment. 
The MULTOS approach to office document filing and retrieval is intended to support applications where the processing of information is distributed, large volumes of documents are stored, and powerful retrieval by document contents (such as user-defined attributes, text and graphic images) is needed. 
Much of the processing within the MULTOS system is based on a conceptual model supporting a semantic-oriented description of documents. This semantic document representation is the basis for MULTOS's content-oriented processing, classification and retrieval techniques. The European standard for an Office Document Architecture (ODA) was adopted as the document interchange format (ODIF). The ODA model was also extended by providing conceptual description features more suitable for efficient retrieval by content. 
The main aspects of the project included document modelling, document type handling, query language design and query processing optimisation, image data modelling and retrieval, knowledge-based document classification, document management, indexing techniques, optical storage exploitation and support for user/system interaction. The main objectives were to: 
-develop an efficient and cost-effective system for the filing and retrieval of multimedia documents 
-integrate optical storage media for filing large numbers of documents 
-implement techniques for the content-based retrieval of text and attribute data and investigate techniques for the content-based retrieval of image data 
-investigate and implement knowledge-based techniques for automatic document classification 
-implement document management functions such as access control, security, integrity and version support 
-define a multimedia document model for document filing and retrieval 
-develop an application environment to test and evaluate the MULTOS system's capabilities. 
The aim of the multimedia filing system (MULTOS) was to develop an efficient and cost effective system for filing and retrieving multimedia documents in the office environment.

The MULTOS system is based on a client/server architecture. The user interacts with the system through the client subsystem, which provides a user friendly interface for document preparation, document acquisition, query formulation, document display and printing. The requests are issued to the server. There are 2 types of document servers, related to 2 groups of documents with different retrieval requirements. In the dynamic server, the documents can be updated and frequently accessed; in the archive server, the documents are stable and less frequently accessed. Document filing in the dynamic server is done using magnetic storage; the archive server integrates magnetic and WORM optical disks. Documents created or acquired in the Client environment can be classified either manually or automatically. The classification allows parts of the document to be associated with conceptual components for use in retrieving the documents later. Automatic classification is based on predicates associated with document conceptual components. Logical, layout and domain specific information is used during automatic classification.

Graphic images are analysed and the objects composing the image automatically extracted. Image analysis is based on user defined application domains. 2 different approaches to image analysis and retrieval have been experimented with. A first MULTOS prototype was implemented in 1987. The final prototype provides complete system functionality.
The MULTOS system is based on a Client/Server architecture. The user interacts with the system through the Client subsystem, which provides a friendly user interface for document preparation, document acquisition, query formulation, document display and printing. The requests are issued to the Server.There are two types of document servers, related to two groups of documents with different retrieval requirements. In the dynamic server, the documents can be updated and frequently accessed; in the archive server, the documents are stable and less frequently accessed. Document filing in the dynamic server is done using magnetic storage; the archive server integrates magnetic and WORM optical disks. 
Documents created or acquired in the Client environment can be classified either manually or automatically. The classification allows parts of the document to be associated with conceptual components for use in retrieving the documents later. Automatic classification is based on predicates associated with document conceptual components. Logical, layout and domain-specific information is used during automatic classification. 
Graphic images are analysed and the objects composing the image automatically extracted. Image analysis is based on user-defined application domains. Two different approaches to image analysis and retrieval have been experimented with. 
 A first MULTOS prototype was implemented in 1987 and demonstrated at the 1987 ESPRIT Conference. It supported dynamic and archive filing (integrating WORM optical disks) for documents containing text components only. The final prototype provides complete system functionality: multimedia documents can be created in the Client subsystem, classified automatically, and stored on the Server subsystem. The same documents can be retrieved using text, image and document attributes. 
Exploitation 
A pilot application has been developed using the MULTOS system. The application is based on a newspaper scenario. It demonstrates the capabilities of MULTOS system in real office environments and allows its evaluation. 
Many papers have been published about the project in international journals. The consortium recently published Multimedia Office Filing and Retrieval: The MULTOS Approach, edited by  C. Thanos, in the North-Holland series Human Factors in Information Technology.";;;;;Ingegneria C. Olivetti and C. SpA;IT;"Battelle-Institut eV;ERITEL S.A.;TRIUMPH ADLER AG;CRETAN COMPUTER INSTITUTE;EPSILON SOFTWARE LTD;PHILIPS DUPONT OPTICAL;NATIONAL RESEARCH COUNCIL OF ITALY";"DE;ES;EL;NL;IT";
8320;477;COSIMA;;FP1-ESPRIT 1;;FP1;Control Systems for Integrated Manufacturing;01/01/1985;01/01/1990;;"The objective of this project was to design, develop and test the software modules required for the Production Activity Control (PAC) of small batch manufacturing. The main aims of COSIMA were to: 
-define a standard architecture for PAC in discrete parts manufacturing 
-demonstrate that the solution is suitable for different small batch manufacturing environments 
-develop design and integration tools to support engineers in analysing, designing and developing PAC systems. 
The objective of this project was to design, develop and test the software modules required for the production activity control (PAC) of small batch manufacturing. The PAC architecture that was specified and designed during the first half of the project can integrate the following components:
5 basic building blocks to perform the activities demanded in PAC (monitoring, scheduling, dispatching, moving, producing);
a manufacturing profile to collect the static and dynamic data describing the system layout and behaviour;
a Petri-net simulator to model the reactions of the real system to the PAC commands;
an application network, implementing procedural application sequencing and system wide data management (through a manufacturing data dictionary), to interconnect all the above components.

In the second half of the project the architecture was validated through 3 pilot implementations:
a flexible manufacturing system for robots and work cell standard components production;
an assembly line for electronic boards production;
a part production system for car components.

The application network, a complete set of technical specifications, the final implementation guides and 2 books are the tools available to the partners for designing and implementing similar systems.
The PAC architecture that was specified and designed during the first half of the project can integrate the following components: 
-five basic building blocks to perform the activities demanded in PAC (monitoring, scheduling, dispatching, moving, producing) 
-a manufacturing profile to collect the static and dynamic data describing the system layout and behaviour 
-a Petri-net simulator to model the reactions of the real system to the PAC commands 
-an application network, implementing procedural application sequencing and system-wide data-management (through a manufacturing data dictionary), to interconnect all the above components. 
In the second half of the project the architecture was validated through three pilot implementations: 
-a flexible manufacturing system for robots and work-cell standard components production in the COMAU Grugliasco (I) plant. 
-an assembly line for electronic boards production in the DEC Clonmel (IRL) plant. 
-a part production system for car components in the Renault Cleon (F) plant. 
The application network, a complete set of technical specifications, the final implementation guides and two books are the tools available to the partners for designing and implementing similar systems. 
Exploitation 
The project has produced several spin-offs: 
-the study of proprietary products such as COMAU's CIMtegrator software platform and DEC's CDD\ Data Dictionary has been influenced by the COSIMA architecture and by the application network manufacturing data dictionary 
-European companies such as Unilever, Volvo and Philips have demonstrated a tangible interest in COSIMA implementations 
-the analysis made by DEC and by the CIMRU of the University College of Galway of applying the COSIMA architecture in the Clonmel pilot implementation has been used to create a parallel PAC implementation (PACKETS: PAC Kernel in Objects) and a Petri-netsimulator that introduced the partners to object-oriented and Petri-net modelling and implementation techniques.";;;;;Comau SpA;IT;"Digital Equipment GmbH;Renault Automation";"DE;FR";
8573;1563;ACAFS;;FP1-ESPRIT 1;;FP1;Automatic Control of an ASIC Fabrication Sequence as Demonstrated in the Plasma Etch Area;01/04/1987;01/12/1990;;"The objective of ACAFS was to develop a methodology and to acquire know-how for a wafer fabrication sequence control system. Because of its critical nature, the plasma etch area was the one chosen in which to implement the methodology. The work involved s everal domains, such as optical sensor integration for 'smart' information collection, plasma etching process modelling for control and supervision purposes, communication between equipment manipulators and computers, as well as hardware and software for real-time processing control. Recent powerful techniques in model identification, multivariable process control and artificial intelligence were used to efficiently address the various control, supervision, and decision-making problems related to the proposed hierarchical control structure. 
In the field of thin film industries, the in situ control of layer thickness has become of great importance in monitoring, in real time, the process parameters during processing or for stopping the process when layers have reached the desired thickness. The technique developed is based on the measurement of the spectral reflectivity of a multilayer sample irradiated with a white light beam. The spectrum of the reflected light is sent to a computer which computes the optical parameters of the thin film stack and especially the thickness. The incident and reflected light are driven through optical fibres.
 This technique presents several advantages such as resolution, sensitivity, ease of use and cost over the other current methods.

The objective was to develop a methodology for a wafer fabrication sequence control system. Because of its critical nature, the plasma etch area was the one chosen in which to implement the methodology. Recent powerful techniques in model identification, multivariable process control and artificial intelligence were used to address the various control, supervision, and decision making problems related to the proposed hierarchical control structure. Software was developed to control the plasma etch process parameters online, in a closed loop. The purpose of the controller software was to improve process reliability and reactor yield. Work on extracting the parameters affecting the yield and on developing models, using statistical process control (SPC) methods, to predict etch process results from process parameters was completed. Effort was devoted to transparent layer plasma etching processes. Effort was devoted to transparent layer plasma etching processes. An in situ layer thickness probe based on white light interferometry and a single point interferometer for end point detection were designed. The highly sensitive metallization etching was chosen as the process to be used in the final demonstrator of the whole automatic control concept. Optical emission spectroscopy was studied for in situ etch rate and uniformity monitoring purposes, and it was demonstrated that it can be successfully used for this purpose. Added emphasis was put on enhancing the fault detection and machine maintenance scheduling capabilities of the system. Appropriate supervision software was developed. The closed loop control concept was validated. An evaluation of various automated product tracking and transfer approaches was made. An overview of the different techniques available for in situ wafer surfacestemperature measurement during plasma etching will be provided.
Software was developed to control the plasma etch process parameters online, in a closed loop. The software runs on a PC connected to the etcher via a SECS II link. The PC receives information such as etch-rate or uniformity from an in situ sensor and compares this with a theoretical model in order to adjust the process parameters in real time. The purpose of the controller software was to improve process reliability and reactor yield. 
Work on extracting the parameters affecting the yield and on developing models, using statistical process control (SPC) methods, to predict etch process results from process parameters was completed. The necessary studies were realised on appropriate teststructures. 
During the first two years, effort was devoted to transparent (SiO2 and polysilicon) layer plasma etching processes. An in situ layer thickness probe based on white light interferometry and a single-point interferometer for end-point detection were designed. 
Based on the experience of the first two-year period, the highly sensitive metallisation etching was chosen as the process to be used in the final demonstrator of the whole automatic control concept. Optical emission spectroscopy was studied for in situ etch-rate and uniformity monitoring purposes, and it was demonstrated that it can be successfully used for this purpose. 
Over the last 16-month period added emphasis was put on enhancing the fault detection and machine maintenance scheduling capabilities of the system. Appropriate supervision software was developed. The closed loop control concept was validated at Plasma Technology on an RIE reactor. The whole automated control system and its impact on yield was planned to be demonstrated at the ES2 production line on a new ECR etcher under development by Plasma Technology. However, due to technical problems in the etcher development, the demonstration was not possible, and the project was terminated four months before its planned completion-date. 
An evaluation of various automated product tracking and transfer approaches was made in the first two years. Furthermore, an overview of the different techniques available for in situ wafer surface temperature measurement during plasma etching will be provided. 
Exploitation 
The layer thickness and end-point detection probes developed will be commercialised by Bertin & Cie and Leybold Heraeus, respectively. Plasma Technology (now called Oxford Plasma Technology) is already using the PC controller developed on all its new lineetchers. The user companies, Mietec and ES2, developed methodologies and tools for plasma etch process modelling and general statistical process control, which they are using routinely in new process development. 
Bertin & Cie is planning to market the two software packages on equipment maintenance and fault detection it developed, and is also actively looking for partners to implement the closed loop control system in a production environment.";;;;;Bertin & Cie;FR;"MIETEC NV;LEYBOLD HERAEUS GMBH;European Silicon Structures SA;Plasma Technology Ltd";"BE;DE;FR;UK";
8405;1490;SIP;;FP1-ESPRIT 1;;FP1;Advanced Algorithms and Architectures for Speech and Image Processing;16/09/1984;16/09/1989;;"The objective of SIP was to develop the algorithmic and architectural techniques required for recognising and understanding spoken and visual signals, and to demonstrate these techniques by means of suitable applications. 
The work was planned in three parallel areas: speech analysis, image analysis and pattern recognition and understanding. 
With respect to speech, the initial application target was to extend as far as possible current state-of-the-art techniques for speech recognition. The resulting system was to be tested using a vocabulary of the order of 1,000 words with constrained syntax and using continuous speech. 
For image processing, the project attempted to go beyond treating the image merely as sampled data. Applications involved in medical imagery and industrial inspections were used to test the tools and to study architectural and implementation issues. At the higher level of processing, close commonality can be expected between techniques for speech and image processing. Subsequent work will study architectures suitable for the higher levels, which can interface with the lower level systems. 
Algorithms and prototype equipment are available for recognition of continuous speaker dependent speech and for understanding phrases within restricted semantic domain, and also for image feature extraction and recognition. Applications are in fields such as medicine, robotics and telecommunications.
A prototype was made available on 29/03/89
The operating environment is as follows :
Hardware: special hardware coupled with Symbolics

The objective of speech and image processing (SIP) was to develop the algorithmic and architectural techniques required for recognising and understanding spoken and visual signals and to demonstrate these techniques by means of suitable applications. The work was planned in 3 parallel areas: speech analysis, image analysis and pattern recognition and understanding.
Progress on speech processing was made along 2 complementary lines: a statistical approach and a knowledge based approach. Preliminary results were obtained from the statistical approach, based on a first implementation, using very large lexicons. For the knowledge base approach, a methodology for representation of the lexical and acoustical knowledge was chosen. In addition, the architecture of the acoustical front end was realized and the first digital signal processing boards tested.
A coordinated set of algorithms and architectures for image recognition and understanding was developed and demonstrated. Layer approaches based on single instruction multiple data (SIMD) and multiple instruction multiple data (MIMD) machine were realized for image feature extraction.
Implementation aspects of the physical architecture for high level processing based on transputers fully interconnected through a switching network were analyzed in detail. A switching element for nonlocal communication was designed outside the project, and the first building-block, comprising 2 processing elements and a hardware emulation of the interconnection network, is now available.
Progress on speech processing was made along two complementary lines: a statistical approach and a knowledge-based approach. Preliminary results were obtained from the statistical approach, based on a first implementation, using very large lexicons. For the knowledge-based approach, a methodology for representation of the lexical and acoustical knowledge was chosen. In addition, the architecture of the acoustical front-end was realised and the first digital signal processing boards tested. The lexical access and the verification based on a Hidden Markov Model were demonstrated on a VAX machine on a set of short sentences uttered by a single speaker in a noisy environment. Methods to incorporate syntactic and semantic information were studied to achieve understanding of uttered sentences. A small question-answering system running on a Symbolics machine was demonstrated. The system starts from the word lattice produced by the speech system, builds a representation of the query-using syntax and semantics, and  inally answers the query. 
A coordinated set of algorithms and architectures for image recognition and understanding was developed and demonstrated. Layer approaches based on Single Instruction Multiple Data (SIMD) and Multiple Instruction Multiple Data (MIMD) machine were realised for image feature extraction. A heterogeneous approach was taken, linking a SIMD GAPP array for the low-level processing and an MIMD transputer-based machine or an array processor for the medium-level processing. The interfaces and the I/O of the data we re developed and optimised. Estimates of performance were derived from a set of algorithms running on the different parts of the architecture. This was improved by setting up real benchmarks. Specific work was done to provide a coordinated set of algorithmic tools for digital angiography applications. 
 Implementation aspects of the physical architecture for high-level processing based on transputers fully interconnected through a switching network were analysed in detail; a switching element for non-local communication was designed outside the project, and the first building-block, comprising two processing elements and a hardware emulation of the interconnection network, is now available. 
PIPES, the first prototype realisation of a Prolog transputer-based machine where the transputers are fully interconnected using a packet-switched network, was demonstrated. It will be implemented on the high-level architecture for speech and image understanding and applied to real-time tasks. 
Exploitation 
SIP has been the source of applications in sound, vision and robotics through the development of a coordinated set of algorithms and architectures for image recognition and understanding. It provides the foundation for applications in medicine, in industry and in other domains. Project results also support the development of intelligent workstations to support both graphic and image processing. 
The successful combination of statistical techniques and knowledge-based techniques for speech recognition will result in a major breakthrough in the field. The complete real-time stand-alone system displaying spoken Italian which is now under developmentwill be adapted for French and German.";;;;;Centro Studi e Laboratori Telecomunicazioni SpA;IT;"Thomson CSF;Université de Strasbourg I (Université Louis Pasteur);Daimler-Benz AG;GEC-Marconi Materials Technology Ltd";"FR;DE;UK";
8649;1620;ASTRA;;FP1-ESPRIT 1;;FP1;Advanced and Integrated Office Systems Prototypes for European Public Administrations;01/02/1986;01/02/1990;;"The main objectives of the ASTRA project were to contribute to the common understanding of office automation problems in public administrations in different European countries, and to integrate state-of-the-art technology, concepts and results. 
The project consisted of the following phases: 
-definition of user requirements for a system supporting different types of objects 
-definition of an office model with the identification of functional blocks and cooperation strategies 
-implementation and assembly of components 
-development of a prototype system. 
The prototype makes use of advanced storage and retrieval systems based on optical discs. The results of the project were targeted at the public administrations of European member states. 
The main objective of the advanced and integrated office systems prototypes for European public administrations (ASTRA) project were to contribute to the common understanding of office automations problems in public administrations in different European countries, and to integrate state of the art technology, concepts and results.

The methodology was defined for the analysis of user requirements in the 4 partner states, the user requirements analysis completed in the selected public adminstrations, and a synthesis of requirements achieved. The technological basis for the prototypes was also established.

Procedures, standards and technqiues for public administration information systems can be derived from the project results. The main target was the integration of large scale information handling within national bodies. The information flow has primarily been supported through the processing of multimedia documents. A document specification has been established for document filing and retrieval, covering the document viewed as a set of frames and with a document profile attached.

The hardware and system software specification was completed. A prototype has been established based on the Olivetti and Bull hardware and system software in an open system. The application software specification has also been completed; it is based on a client server model, concentrated on the processing of multimedia documents.
The methodology was defined for the analysis of user requirements in the four partner states, the user requirements analysis completed in the selected public administrations, and a synthesis of requirements achieved. The technological basis for the prototypes was also established. 
Procedures, standards and techniques for public administration information systems can be derived from the project results. The main target would be the integration of large-scale information handling within national bodies. 
The information flow has primarily been supported through the processing of multimedia documents. An ASTRA document specification has been established for document filing and retrieval, covering the document viewed as a set of frames and with a document profile attached. 
 The hardware and system software specification was completed. A prototype has been established based on the Olivetti and Bull hardware and system software in an open system. The application software specification has also been completed; it is based on a client-server model, concentrated on the processing of multimedia documents. The client-servers cover the following functionalities: archive, directory, file, mail (X.400) and print. 
Guidelines for the design of office information systems in the public sector have also been produced. The ASTRA project's results were demonstrated at the 1989 ESPRIT Conference and the 1990 Hannover Fair.";;;;;Società Generale d'Informatica SpA;IT;"Ingegneria C. Olivetti and C. SpA;PLANET SA;Syntax Sistemi Software SpA;MC2;Datenzentrale Schleswig-Holstein;BULL SA;I/S DATACENTRALEN AF 1959;GSI TECSI Software SA;Silogia;Consorzio Campano di Ricerca per l'Informatica e l'Automazione Industriale;CESIA";"IT;EL;FR;DE;DK";
8403;401;ASPIS;;FP1-ESPRIT 1;;FP1;Application Software Prototype Implementation System;24/03/1985;24/03/1989;;"The objective of this project was to construct tools, called 'Assistants', to support the partial automation of the first phases of the life-cycle, by the exploitation of state-of-the-art techniques in the fields of specification languages and artificial intelligence. 
The main problems tackled by ASPIS were: 
-capturing the domain knowledge to be used by the Assistants 
-choosing an appropriate representation formalism for coding knowledge 
-defining the basic architecture of Assistants 
-defining an appropriate language for interaction between Assistants and users. 
The final objective of the project was the creation of a set of advanced methods and tools allowing a flexible approach to applications software production based on an interactive style, including: 
-rapid prototyping by interpretation of the components specifications 
-reusability of components through knowledge-based Assistants. 
The final result was a fully integrated prototype environment system able to provide assistance in the early phases of the systems development life cycle. The environment consists of several expert systems (termed assistants) based on a common knowledge representation formalism, KRS. Analysis, design and reuse assistants were developed. These expert systems have access to 2 common knowledge bases containing methodological knowledge (independent from the application domain) and domain knowledge. A rapid prototyping facility is included in the analysis assistant. The environment was fully demonstrated in the final review through the simulation of the development of a realistic access control system with hardware and software components for an industrial site. Two versions of the reuse assistant were demonstrated: one applied to the analysis and therefore interfacing the analysis assistant and another one for the design assistant. A mechanism of interfacing the analysis and the design assistant, enabling an incremental development, is also included in the environment.
The final result of ASPIS was a fully integrated prototype environment system able to provide assistance in the early phases of the systems development life-cycle. 
The ASPIS environment consists of several expert systems (termed Assistants) based on a common knowledge representation formalism, KRS. Analysis, Design and Reuse Assistants were developed. These expert systems have access to two common knowledge-bases containing methodological knowledge (independent from the application domain) and domain knowledge. A rapid prototyping facility is included in the Analysis Assistant. 
The ASPIS environment was fully demonstrated in the final review through the simulation of the development of a realistic access control system with hardware and software components for an industrial site. This case-study was brought to the project by oneof the partners, a company with great experience in developing such systems for customers. Two versions of the Reuse Assistant were demonstrated: one applied to the analysis and therefore interfacing the Analysis Assistant and another one for the DesignAssistant. A mechanism of interfacing the Analysis and the Design Assistant, enabling thus an incremental development, is also included in the environment. 
Exploitation 
The implementation of Assistants for the early phases of the systems development life-cycle and their application in commercial developments will help reduce the misinterpretation of user requirements by the different development teams involved in these phases. The problems arising from these misinterpretations constitute one of the major sources of errors in the systems development process. 
The development of ASPIS tools as part of a CASE environment is being exploited by the consortium.";;;;;Ingegneria C. Olivetti and C. SpA;IT;"CAP GEMINI INNOVATION;GEC Marconi Research Centre;Université de Grenoble I (Université Joseph Fourier);Tecsiel SpA";"FR;UK;IT";
12591;EN3S0087;SOLINFO;;FP1-ENNONUC 3C;;FP1;TECHNOLOGY TRANSFER FROM THE SOLAR R&D COMMUNITY TO THE EUROPEAN BUILDING PROFESSIONS;01/08/1986;31/10/1990;;"THE CEC R&D SUB-PROGRAMME, SOLAR ENERGY APPLICATIONS IN BUILDINGS, FACES AN UNUSUALLY DIFFICULT TASK IN THE DISSEMINATION OF ITS RESULTS BECAUSE OF THE DIVERSITY AND SIZE OF ITS TARGET AUDIENCE. SOLINFO AIMS TO PROMOTE THE TRANSFER OF INFORMATION FROM THE SOLAR RESEARCH COMMUNITY TO THE BUILDING DESIGN AND CONSTRUCTION PROFESSIONS. THE AREAS OF WORK MAY BE CATEGORISED BROADLY AS FOLLOWS: 
- INFORMATION REQUIREMENTS; 
- UNDERGRADUATE EDUCATION; 
- MID-CAREER EDUCATION; 
- PROFESSIONAL PRACTICE; 
- RESEARCH DISSEMINATION. 
CLOSE LINKAGES EXIST BETWEEN THE SOLINFO AND ARCHISOL PROJECTS. 

A SERIES OF NATIONAL REVIEWS, UNDERTAKEN IN 1986 BY EXPERTS IN EACH OF THE MEMBER STATES, HAS ALLOWED THE SOLINFO PROJECT TO BUILD ON APPROPRIATE EXISTING EUROPEAN RESEARCH BY IDENTIFYING PREVIOUS STUDIES AND PINPOINTING EUROPEAN CENTRES OF EXCELLENCE IN SEVERAL AREAS. THE REVIEWS HAVE BEEN ANALYSED AND CONTINUE TO BE UPDATED PERIODICALLY. 
A DETAILED STUDY INTO INFORMATION REQUIREMENTS FOR ARCHITECTS WAS BEGUN IN AUGUST 1987 AND COMPLETED IN APRIL 1988. THE AIM OF THE STUDY WAS TO GENERATE CRITERIA WHICH COULD BE USED TO IMPROVE THE DESIGN OF INFORMATION FOR ARCHITECTS IN THE AREA OF PASSIVE SOLAR DESIGN. ITS FINDINGS ARE BEING INCORPORATED IN ALL OUTPUT FROM SOLINFO AND ARCHISOL. 
A WORKSHOP WAS ARRANGED IN OCTOBER 1987 TO ENCOURAGE AN INTERCHANGE OF EXPERIENCE BETWEEN EUROPEAN CENTRES OF EXCELLENCE IN THE TEACHING OF PASSIVE AND LOW-ENERGY ARCHITECTURE TO ARCHITECTURAL STUDENTS. MORE THAN TWENTY LEADING TEACHER/ARCHITECTS ATTENDED THE SUCCESSFUL WORKSHOP, THE FIRST OF ITS KIND IN EUROPE. ARISING FROM THIS INITIATIVE, SOLINFO IS DEVELOPING A RANGE OF APPROPRIATE RESOURCE MATERIALS FOR TEACHERS AND WHICH WILL BE DISSEMINATED THROUGHOUT THE EC. 
A RANGE OF DRAWING-BOARD AIDS FOR ARCHITECTS IS BEING DEVELOPED AND COPIES OF THE PRELIMINARY EDITION OF THE EUROPEAN PASSIVE SOLAR HANDBOOK HAVE BEEN PLACED IN MAJOR ARCHITECTURAL LIBRARIES ACROSS EUROPE. HANDBOOKS HAVE ALSO BEEN DISSEMINATED THROUGH A SERIES OF ARCHITECTS' WORKSHOPS. 
THE SOLINFO PROJECT IS CO-ORDINATING THE REVISION OF THE EUROPEAN PASSIVE SOLAR HANDBOOK. AN EDITORIAL GROUP HAS BEEN APPOINTED TO OVERSEE THE REVISION. THE REVISED HANDBOOK WILL COMPRISE A SUITE OF COMPLEMENTARY VOLUMES, NAMELY: AN INTRODUCTORY DESIGN PRIMER, A DETAILED DESIGN MANUAL, A PASSIVE SOLAR RESOURCE GUIDE AND A COMPONENTS CATALOGUE. SEVERAL OF THE VOLUMES ARE NEARING COMPLETION. 
A SERIES OF CEC RESEARCH DIGESTS IS BEING PRODUCED. THE DIGESTS ARE INTENDED TO BRING NEWS AND RESULTS OF THE COMMISSION'S SOLAR THERMAL RESEARCH PROJECTS SPEEDILY TO A WIDER AUDIENCE. IN ADDITION, A NUMBER OF EXTENSIVE MAILING LISTS AND OTHER DATABASES HAVE BEEN ESTABLISHED WHICH ARE AT THE SERVICE OF THIS AND OTHER PROJECTS WITHIN THE COMMUNITIES' SOLAR THERMAL R&D PROGRAMME.";;;;CSC;UNIVERSITY COLLEGE DUBLIN;IE;;;
8426;973;ALPES;;FP1-ESPRIT 1;;FP1;Advanced Logical Programming Environments Support;18/06/1986;18/06/1990;;"The ALPES project aimed to analyse and define a complete programming environment, based on logic programming, analysing program synthesis from first-order logic specifications, theorem proving and meta-reasoning, distributed logic programming, and abstract data type specifications. 
The application of these results to classical environment tools, such as debuggers, browsers, editors and interfaces with graphic systems, and to the specific needs of logic programming, was developed in parallel. 
Finally, these results were integrated in programming environment modules. 
The project aimed to analyse and define a complete programming environment, based on logic programming, analysing program synthesis from first order logic specifications, theorem providing and metareasoning, distributed logic programming, and abstract data type specifications. The application of these results to classical environments tools, such as debuggers, browsers, editors and interfaces with graphic systems, and to the specific needs of logic programming, was developed in parrallel. Finally, these results were integrated in programming environment modules. The main characteristics of the environment architecture can be summarized as follows: the architecture is open; modules (units) are reusable; it is fully customizable; it is self revealing.
The major outcome of the project was the ALPES environment, a general-purpose programming environment for logic programming and, in particular, Prolog. The ALPES environment includes tools such as: 
-Prolog and graphics systems, for handling graphical objects as Prolog objects 
-hybrid (text/structured) multi-window specialised editor 
-generic and extensible browser for logic programming. 
-distributed logic programming system, aiming at executing logic programs across networks while keeping the classical behaviour of Prolog programs, including backtracking 
-data typing and type checker for logic programs 
-semi-automatic program construction tool for building logic programs from their specification in full first-order logic 
-automatic program transformation tool (especially for optimising their speed of execution) 
-program transformation tool for their execution of parallel architectures 
-static analysis of Prolog programs tool for detection of potential loops 
-rational debugger. 
The following topics were addressed, and produced state-of-the-art results: 
-meta-level and intelligent control of logic programs 
-types, functions and objects in logic programming, including issues on equality handling 
-extension of Prolog towards non-classical logics. 
Another important domain where state-of-the-art results were achieved is the architecture of programming environments for logic programming. The main characteristics of the ALPES environment architecture can be summarised as follows: 
-The architecture is open. Contrary to C-Prolog's philosophy of protecting system primitives from the users, in ALPES all parts are available for extension and/or replacement. 
-Modules (units) are reusable: all parts of ALPES are available, and are easily locatable (through a special system folder and its sub-folders) to be used, modified or extended by small modular additions. 
-ALPES is fully customisable: users can tailor the environment to support their own style or preferences. 
-ALPES is self-revealing: information about the internal workings of the system is immediately available. 
Exploitation 
The results of the ALPES project are manifold, since it addressed the topic of advanced architectures for logic programming as well as the topic of building advanced tools. 
The industrial exploitation of the results of the project is taking place in several ways: 
 -CRIL is putting into use the know-how and technology acquired through the project by developing a programming environment for a logic programming-based expert system shell, SPIRAL. This shell was developed by one of CRIL's customers, CEA. SPIRAL is used  to develop expert systems requiring real-time behaviour in safety-critical areas. Based on a Prolog-like interpreter working with objects (in the object-oriented paradigm sense), SPIRAL is close to the basic ALPES language so that most of the concepts de vised for the environment and the advanced tools can be re-used. 
-CRIL is seeking financial support for the direct industrialisation of ALPES on a Prolog compiler developed and marketed by the company. 
 -ENIDATA is using ALPES to develop applications in the advanced information processing field; the possibilities for industrialisation of the results of the project are being investigated. In particular, an expert system for coke production furnace monito ring was developed for AGIP using the ALPES environment. 
-The possibility of launching spin-off companies from UNL and DEIS to exploit and market the results of the project is being studied. 
With respect to the academic exploitation of the project's results, most of the universities in the consortium have been using ALPES as a practical development tool within logic programming courses, and will base further research on ALPES.";;;;;Conception et Réalisation Industrielle de Logiciel (CRIL);FR;"UNIV NOVA DE LISBOA;Enidata SpA;Université de Paris XI (Université Paris-Sud);Bull SA;Technische Universitaet Muenchen";"PT;IT;FR;DE";
8647;1616;UCOL-1;;FP1-ESPRIT 1;;FP1;Ultra-Wideband Coherent Optical LAN;01/02/1985;01/02/1988;;"The UCOL-1 project investigated the feasibility of using coherent optical techniques for high-capacity communications in a local area network (LAN). 
In applying these techniques to LANs, the project set particular emphasis on the implications of the interactions between the adopted technology, the selected transmission techniques, the statistical characteristics of the traffic and the management confi guration, in order to ensure that the outcome of the design would be an efficient system. The network concept developed within the project provides a total capacity of several Gbit/s. All types of service are supported, and its geographical range exceeds that of conventional LANs. 
Binary PSK was selected because it needs the lowest optical signal power for a given error probability. Differential PSK was adopted because it avoids the need for complex circuitry for carrier recovery. The constraints placed upon the receiver response time when operated within a multichannel, multi-user environment are severe if network efficiency is not to be compromised. Rapid inter-message response was a principal design objective from the outset. 
The project investigated the feasibility of using coherent optical techniques for high capacity communications in a local area network (LAN).

A laboratory demonstration of the underlying detection principle was successfully staged. The theoretical work on the system concept, and the experimental activity carried out on 3 of the most important building blocks (the narrow lined source, the comb generator and the receiver), indicated that the physical structure necessary to support network operation was feasible and can offer high performance. The ultrawideband coherent optical local area network project showed how it was possible to exploit the star configuration in a high efficiency time division multiplexing (TDM) protocol which regulates access to each individual optical frequency. Time slot division of individual optical channels permits efficient service integration and TDM on each individual optical frequency allows flexibility in bandwidth allocation and therefore agile mixing of high band width and low band width users. Furthermore, delay sensitive applications can be dealt with within their timeconstraints. Frequency domain switching between channels was therefore exploited to obtain inexpensive adaptive network reconfiguration without hardware modifications.
A laboratory demonstration of the underlying detection principle was successfully staged. The theoretical work on the system concept, and the experimental activity carried out on three of the most important building blocks (the narrowlined source, the comb generator and the receiver), indicates that the physical structure necessary to support network operation is feasible and can offer high performance. 
UCOL-1 showed how it is possible to exploit the star configuration in a high-efficiency TDM protocol which regulates access to each individual optical frequency. Time-slot division of individual optical channels permits efficient service integration and TDM on each individual optical frequency allows flexibility in bandwidth allocation and therefore agile mixing of high bandwidth and low bandwidth users. Furthermore, delay-sensitive applications can be dealt with within their time constraints. Frequency-domain switching between channels is therefore exploited to obtain inexpensive adaptive network reconfiguration without hardware modifications. 
Exploitation 
The range of specific applications is extremely large. A preliminary survey was carried out during the UCOL feasibility study to assess its potential and the most suitable application areas. The study proved that with coherent optical techniques it will be possible to build a network with a very high capacity and excellent performance in information-flow handling. 
The results of UCOL-1 are being used in project 2054, UCOL-2.";;;;;Alcatel Face Standard SpA;IT;"GEC Marconi Research Centre;Politecnico di Milano";"UK;IT";
8402;1488;CFID;;FP1-ESPRIT 1;;FP1;Communication Failure in Dialogue: Techniques for Detection and Repair;01/01/1985;01/01/1989;;"The aim of CFID was to develop a robust and portable natural-language interface to a relational database system. 
The initial stages of the project involved the study of human dialogues in a simulated database-query environment, including recovery from various types of communication failure. From an analysis of these dialogues a formal model of the dialogue process w as to be developed to serve as a basis for a computer implementation of an English and Italian natural-language front-end to a student record database. An important element of the implementation was the use of non-verbal systems (e.g. graphics, pointing, icons) in roles analogous to the non-verbal components of human dialogue. The robust dialogue component of the project was seen to have potential applications, outside the database domain, in the development of a front-end expert systems, or for information retrieval in an office environment. 
The aim of the project was to develop a robust and portable natural language interface to a relational database system. The initial stages of the project involved the study of human dialogues in a simulated database query environment, including recovery from various types of communication failure. From an analysis of these dialogues a formal model of the dialogue process was developed to serve as a basis for a computer implementation of an English and Italian natural language front end to a student record database. An important element of the implementation was the use of nonverbal systems in roles analogous to the nonverbal components of human dialogue. The robust dialogue component of the project was seen to have potential applications, outside the database domain, in the development of front end expert systems, or for information retrieval in an office environment. A review of the various approaches to human-computer dialogue was completed; particular care was taken to exploit possibilities of multidisciplinary cooperation and nonverbal communication. A system for the classification of dialogue was developed, and tools defined, some of which have been implemented. A series of experiments were carried out to evaluate the proposed approach. The development of a hardware and software configuration for the collection of dialogue data was completed, the general dialogue model specified, and a prototype demonstrated. An interface metaphor was designed and implemented. Various tools were developed and demonstrated to support the general dialogue model: graphic representation, gesture analysis and interpretation, knowledge representation, and a language, SAIL, to design dialogues accounting detection and repair of miscommunication.
A review of the various approaches to human-computer dialogue was completed; particular care was taken to exploit possibilities of multidisciplinary cooperation and non-verbal communication. A system for the classification of dialogue was developed, and tools defined, some of which have been implemented. A series of experiments were carried out to evaluate the proposed approach. The development of a hardware and software configuration for the collection of dialogue data was completed, the general dialogue model specified, and a prototype demonstrated. An interface metaphor was designed and implemented. Various tools were developed and demonstrated to support the general dialogue model: graphic representation, gesture analysis and interpretation, knowledge representation (HUSSERL), and a language, SAIL, to design dialogues accounting detection and repair of miscommunication. 
Exploitation 
The construction of a formal model of dialogue and communication breakdown has potential applications in producing more user-friendly natural language interfaces for systems of various kinds. The integration of non-verbal information, such as gestures, in this model could form the basis of very intelligent and robust interfaces, although this is a longer-term prospect. In view of the burden of translation from natural language in the extensive and increasing use of relational databases, ensuing products a re likely to have a substantial industrial impact.";;;;;ST PATRICK'S COLLEGE;IE;"Università degli Studi di Pisa;MEMORY COMPUTER PLC;LINGUISTICS INSTITUTE OF IRELAND;Alcatel;University of Leeds";"IT;IE;UK";
8347;1136;DASIQ;;FP1-ESPRIT 1;;FP1;Distributed Automated System for Inspection and Quality Control;01/03/1986;01/03/1990;;"The objective of this project was to design a new distributed system for inspection and quality control in flexible manufacturing systems (DASIQ). DASIQ was to comprise three subsystems: inspection of surface finish, coarse dimensional control and high-precision inspection. The objectives were to: 
-design the system architecture and define the distributed subsystems and interfaces 
-design inspection subsystems capable of interfacing with most types of existing sensors for data acquisition and information processing 
-integrate already existing optical inspection techniques 
-provide diagnosis and alarms for the FMS management system, with special attention paid to the interfaces with CAD. 
The objective of this project was to design a new distributed system for inspection and quality control in flexible manufacturing systems (DASIQ). DASIQ was to comprise 3 subsystems inspection of surface finish, coarse dimensional control and high precision inspection. The objectives were to: design the system architecture and define the distributed subsystems and interfaces; design inspection subsystems capable of interfacing with most types of existing sensors for data acquisition and information processing; integrate already existing optical inspection techniques; and provide diagnosis and alarms for the flexible manufacturing system (FMS) management system, with special attention paid to the interfaces with computer aided design (CAD). The design of the different inspection subsystemswas completed.
The design of the different inspection subsystems was completed, but the project had to be terminated after three years due to withdrawal of one of the partners.";;;;;Société d'Applications Générales d'Électricité et de Mécanique;FR;"VISITEC;Microtecnica SpA;Universität Hannover;Commissariat à l'Energie Atomique (CEA)";"BE;IT;DE;FR";
8413;874;CONCORDIA;;FP1-ESPRIT 1;;FP1;Integrated Environment for Reliable Systems;01/12/1985;01/12/1986;;"The CONCORDIA project aimed to provide an environment which integrated a set of hardware and software mechanisms and components in order to facilitate the construction and support the operation of reliable distributed application systems based on local area networks. 
The architecture was intended to provide a programming model integrating the communication needs of distributed software with the various mechanisms required for fault tolerance. 
The model was to allow the construction of fault-tolerant systems based on the concept of active stand-by, with software redundancy supported by hardware redundancy in the network. 
The project aimed to provide an environment which integrated a set of hardware and software mechanisms and components in order to facilitate the construction of and support the operation of reliable distributed application systems based on local area networks. The architecture was intended to provide a programming model integrating the communication needs of distributed software with the various mechanisms required for fault tolerance. The model was to allow the construction of fault tolerant systems based on the concept of active stand by, with software redundancy supported by hardware redundancy in the network. The project completed system architecture and demonstration task specifications. The environment provides a computational model in which objects communicate by means of remote operations calls. Objects are replicated at different nodes of the system for backup in the event of a node failure. Checkpointing is invoked automatically during the remote operations calls, thus ensuring that a backup object will start executing from a known state in the event of a failure.
The project completed system architecture and demonstration task specifications. 
The environment provides a computational model in which objects communicate by means of remote operations calls. Objects are replicated at different nodes of the system for reasons of back-up in the event of a node failure. 
Checkpointing is invoked automatically during the remote operations calls, thus ensuring that a back-up object will start executing from a known state in the event of a failure. 
Exploitation 
The results of the project were used in project 818, DELTA-4.";;;;;MARI Applied Technologies Ltd;UK;"Telettra SpA;JEAN LEFEBVRE TELECOM;Università degli Studi di Bologna";"IT;FR";
8432;928;RUBRIC;;FP1-ESPRIT 1;;FP1;A Rule-Based Approach to Information Systems Development;01/02/1986;01/08/1989;;"The objective of RUBRIC was to develop a system for creating information systems for business applications which matched the requirements of users more accurately than was currently possible. 
Individual end-user requirements were collected using a rule-based approach. This data was then integrated into a single model and used to generate the applications software. 
A prototype system was developed consisting of: 
-a rule-based fact-gathering and presentation system with different views for presentation and with validation tools 
-a unified rule base (URB) to store, aggregate and validate individual requirements 
-an application generating system to realise applications from rule-based descriptions in the URB, either by transformation or by interpretation of the rules. 
The objective of the project was to develop a system for creating information systems for business applications which matched the requirements of users more accurately than was currently possible. Individual end user requirements were collected using a rule based approach. These data were integratedinto a single model and used to generate the applications software. A prototype system was developed consisting of a rule based fact gathering and presentation system with different views for presentation and with validation tools, a unified rule base (URB) to store, aggregate and validate individual requirements, and an application generating system to realise applications from rule based descriptions in the URB, either by transformation or by interpretation of the rules. The main result of the project was a language, with associated tools to represent and process knowledge about business applications. The langauge integrated concepts from 3 different paradigms (entity relationship, object oriented and rule based). As an intermediate result, an object oriented extension of Prolog, AMORE, was developed and fully tested during the implementation phase of the other tools. The final phase of the project was dedicated to the demonstration of the feasibility of applying the developed langauge to a concrete business situation.
The major outcome of RUBRIC was a language and associated tools able to represent and process knowledge about business applications. A language integrating concepts from three different paradigms (entity-relationship, object-oriented and rule-based) was developed and implemented. 
As an intermediate result, an object-oriented extension of Prolog, AMORE, was developed and fully tested during the implementation phase of the other RUBRIC tools. 
The final phase of the project was dedicated to the demonstration of the feasibility of applying the developed language to a concrete business situation. The Irish Electricity Supply Board (IESB) provided the trial site for this experiment. The other partners in the consortium developed training material for the IESB and provided the necessary training sessions in order that the application might be completely developed by IESB staff. 
Exploitation 
The RUBRIC project established and validated the basic principles for the use of AI technology in the development of business applications software. It can be expected that AI technology will not only contribute to increasing the productivity (and therefore decreasing the costs) of business software development, but will also permit applications of increased scope and complexity to be tackled. The IESB case study proved the exploitability of RUBRIC's results.";;;;;JAMES MARTIN ASSOCIATES;BE;"BIM SA;Micro Focus Ltd;UNIVERSITY OF MANCHESTER INSTITUTE OF SCIENCE AND TECHNOLOGY";"BE;UK";
8318;975;TRACIT;;FP1-ESPRIT 1;;FP1;Transponders for Real-Time Activity Control of Manufacturing Links to CIM Information Technology Systems;01/04/1986;01/04/1989;;"The objective of this project was to develop a transponder system for the identification of parts and assemblies flowing through automated assembly plants. The transponder had to fulfil the following requirements: 
-the ability to reliably survive manufacturing processes involving vibration, dust, oil, acid, paint and heat 
-no requirement for special positioning of transponders or interrogators 
-no faults in allocation, even in high-density stocking 
-programmability.
A transponder identifying parts and assemblies in an automated assembly environment must be able to cope with arduous operating conditions including vibration, dust, oil and heat. It must be programmable, freely positionable and achieve error free identification even in high density stocking situations. The intelligent transponder developed under this project will permit reliable and efficient tracking of parts and other objects both in factories and elsewhere. The provision of local storage will considerably reduce the load and dependency on the central computer integrated manufacture (CIM) database and related communication channels.

The objective of this project was to develop a transponder system for the identification of parts and assemblies flowing through automated assembly plants. The transponder had to fulfil the following requirements: the ability to survive manufacturing processes involving vibration, dust, oil, acid, paint and heat; no special positioning; no faults in allocation, even in high-density stocking; and programmability. Hardware and software requirements were defined and transponders with 2 Kbyte storage developed and tested. The data transfer rates were speeded up by a factor of 5 to 10. Software for connecting read/write stations to automobile manufacturing workstations wasdeveloped. Several tests carried out with a motorway tolling company were very promising: cars could be identified when passing at speeds up to 70 km/h.

There have been no negotiations about the first small installations but quite a number of large installations have been carried out, including installations in Hoesch, Thyssen, Volkswagen, Citroën and Mercedes.
Hardware and software requirements were defined and transponders with 2 Kbyte storage developed and tested. The data transfer rates were speeded up by a factor of 5 to 10. Software for connecting read/write stations to automobile manufacturing workstations was developed. 
Several tests carried out with a motorway tolling company were very promising: cars could be identified when passing at speeds up to 70 km/h. 
Exploitation 
The results will be applied to the computer-integrated manufacture of automobiles, where up to now no information carrier has been available which can be used throughout the manufacturing process. They are also targeted for application in material flow management systems, essential in CIM environments. 
Tests in several car manufacturing plants have led to negotiations which should lead to the first small orders. 
The intelligent transponder system will enable the reliable and efficient tracking of parts through the factory as well as outside it. The provision of local storage will considerably reduce the load and dependency on the central CIM database and on the related communication channels. 
The results of the project have led to a DIN standard which will be used first in Volkswagen and hopefully later on throughout the European automotive industry.";;;;;Redar Nah-Ortungstechnik GmbH;DE;POLYDATA LTD;EL;
8404;1489;PALAVDA;;FP1-ESPRIT 1;;FP1;Parallel Architectures and Languages for AIP:a VLSI-Directed Approach;01/11/1984;01/11/1989;;"PALAVDA was launched to study the performance of different approaches to symbolic processing on parallel architecture computers as a step towards establishing a European standard for a generic architecture for logic, functional and object-oriented languages. 
The project aimed to investigate different non von-Neuman architectures and to implement some of them. The prime objective was to reduce the execution times required by AI applications by a substantial factor. Concurrency was to be achieved through a large number of identical processing elements implemented in VLSI. Ideally, a concurrent machine should support all three programming styles (object-oriented, functional and logic), which will allow the full exploitation of concurrency, but the principles upo n which such a machine could be based are not yet fully understood. All three styles were to be explored through studies of machines which support each programming style separately, and through common working groups which were to explore several areas of general relevance. 
The project was divided into a series of subprojects: 
 -A, where the relation between an object-oriented style with active and passive objects and a highly parallel architecture was investigated and developed. The parallel architecture typically contained up to 1024 Processor/Communication Modules (PCMs). Th ree applications (a natural language translator, a knowledge-based system and a multi-level VLSI simulator) were implemented on the machine. 
-B, where the relation between a functional style and a highly paralleled architecture was investigated. Here the approach was how a paralleled reduction machine could be supported by up to 10 000 PCMs. 
-C, where the relation between a logic programming style and a highly parallel architecture was studied. The approach here was how a parallel inference machine could be supported by PCMs. 
 -D, where the relation between a mixed logic and functional style and a highly parallel architecture was studied. Here, the algorithmic parts of an application were to be handled within the functional part, while the non-deterministic (inferential) parts were treated within the logical subset of the language. This improved efficiency. Of course, an important point was the relation between the semantics of functional and logic styles. The question was again how this style could be supported by PCMs. 
-E, where the relation between functional programming and data-flow was investigated. The approach was to study how the data-flow machine could be structured from about 100 PCMs and supported by a high-level application language. 
-F, which addressed the three main styles of new generation programming:functional, parallel and logic. The long-term objective was to arrive at a VLSI implementation of a highly parallel inference machine. On the way to that objective the connection method was to be used. 
All the subprojects were based on messages passed between identical units (PCMs), consisting of communication hardware, processing hardware and local memory. In addition to the subprojects, an application study group was formed to select applications withwhich the various styles might be evaluated and their suitability for various fields of application established. 
The parallel multilevel simulator (PMLS) for very large scale integration (VLSI) circuits runs on general purpose parallel machines and combines multilevel simulation and exploitation of parallelism on the circuit level (ie distributed discrete event simulation using circuit partitioning) to achieve high performance. The parallel multilevel simulator is, to our knowledge, the first general purpose parallel multilevel simulator for very large scale integration circuits. It provides high flexibility (due to object oriented programming) and a highly interactive user interface including zooming (ie dynamic change of the abstraction level).

The parallel fault simulator (PFS), running on a local area network (LAN), divides a set of faults into subsets which are then processed as parallel tasks in the network processors. A control process controls the execution processors and gathers and analyses the results. The use of local area networks accelerates fault simulation.

The project was intended to study the performance of different approaches to symbolic processing on parallel architecture computers as a step towards establishing a European standard for a generic architecture for logic, functional and object oriented languages. The project aimed to investigate different non-von Neuman architectures and to implement some of them. The prime objective was to reduce the execution times required by artificial intelligence (AI) applications by a substantial factor. Concurrency was achieved through a large number of identical processing elements implemeted in very large scale integration (VLSI). Ideally, a concurrent machine should support all 3 programming styles (object oriented, functional and logic), allowing the full explitation of concurrency. Firstly, the relation between an object oriented style with active and passive objects and a highly parallel architecture was investigated. A parallel object oriented language POOL has been designed and implented. Two semantics, proved equivalent, were developed for POOL: denotational and operational. A 100 node prototype, POOMA, has been developed. Each node consists of a processor, a memory, and a communication processor designed in the project. It exhibits 200 Mips, 10 Mflops, 1.6 Gbyte main memory, 15 Gbyte background memory and 1 Gbyte/s communication bandwidth. An operating system has been developed for POOMA. Various applications were developed, the most advanced one being a parallel VLSI simulator. Secondly, the relation between a functional style and a highly parallel architecture was examined. The results are mainly theoretical. A parallel evaluation model for functional languages has been designed and implemented on a network of transputers. Thirdly, the relation between a logic programming style and a highly parallel architecture was investigated. The major contribution was the development of the Alexander method and its execution model. This allows the merging of recursive and non recursive views in queries. The execution model was implemented in a twin SPS7 multiprocessor architecture with good performance results. Fourthly, the relation between a mixed logic and functional style and a highly parallel architecture was studied. A language called IDEAL, which subsumes Prolog and functional languages, has been designed and implemented. The speedup obtained shows real performance improvements via parallelism over the best sequential technology. Fifthly, the relation between functional programming and dataflow was examined. A data flow language has been designed and a 4 node data flow multiprocessor machine constructed, together with an operating system and a language. The machine was experimented on with database applications. Sixthly, use of the connection method to integrate cell 3 styles of programming. The major results concern the field of theorem proving, where a sequential and a parallel theorem prover based on the connection method have been implented. A functional parallel language, FP2, was used to specify the provers.
A 
Results fall mainly into three categories: 
-Language 
A parallel object-oriented language POOL has been designed and implemented. Two semantics, proved equivalent, were developed for POOL: denotational and operational. 
-Hardware and System Software 
 a 100 node prototype, POOMA, has been developed. Each node consists of a processor, a memory, and a communication processor designed in the project. It exhibits 200 Mips, 10 Mflops, 1.6 Gbyte main memory, 15 Gbyte background memory and 1 Gbyte/s communic ation bandwidth. An operating system has been developed for POOMA. 
-Application 
Various applications were developed, the most advanced one being a parallel VLSI simulator. 
B 
The results are mainly theoretical. A parallel evaluation model for functional languages has been designed and implemented on a network of transputers. 
C 
The major contribution was the development of the Alexander method and its execution model. This allows the merging of recursive and non-recursive views in queries. The execution model was implemented in a twin SPS7 multiprocessor architecture with good performance results. 
D 
 A language called IDEAL, which subsumes PROLOG and functional languages, has been designed and implemented on the PIPE parallel transputer machine developed in project 26. The speed-up obtained shows real performance improvements via parallelism over the best sequential technology. 
E 
A data-flow language has been designed and a four-node data-flow multiprocessor machine constructed, together with an operating system and a language. The machine was experimented on with database applications, and the performances obtained are promising.F 
The major results concern the field of theorem-proving, where a sequential and a parallel theorem-prover based on the connection method have been implemented. A functional parallel language, FP2, was used to specify the provers. 
On the whole, the project has shown the crucial importance of compilation techniques and the importance of getting the 'grain to communication' ratio right for the application. Several books and numerous scientific papers have been published on the various aspects of the project. 
Exploitation 
The PALAVDA project has played an important role in the scientific progress of parallel computer systems for symbolic and advanced information processing in the past five years. Through its broad scope, covering the dominant programming styles and the entire spectrum of system and application design, it has been able to contribute to the advances in various fields and disciplines that together are needed to design a parallel computer. 
Finally, PALAVDA has largely contributed to the fact that Europe now has a large number of experienced researchers and system designers in the area of symbolic parallel computer systems. 
The results of the project will provide a solid basis for a variety of more development-oriented projects.";;;;;Philips GmbH;DE;"Siemens Nixdorf Informationssysteme AG;DAIMLER-BENZ AG;Centro Studi e Laboratori Telecomunicazioni SpA;GEC-Marconi Materials Technology Ltd;Bull SA";"DE;IT;UK;FR";
8425;974;KNOSOS;;FP1-ESPRIT 1;;FP1;A Knowledge-Based Environment for Software System Configuration Reusing Components;01/06/1986;01/06/1989;;"The objective of KNOSOS was to develop an environment supporting a method for components reuse during software configuration. 
The user requirements for such an environment were captured through studies conducted by industries familiar with large applications development. A KNOSOS prototype was constructed by integration and adaptation of a relational DBMS, a knowledge representation and manipulation tool, a software configurer, an automated configuration management system, and a common user interface with graphics capabilities. This prototype was evaluated through field trials. 
KNOSOS was related to project 1094, PRACITIONER. 
The objective was to develop an environment supporting a method for components reuse during software configuration. The user requirements for such an environment were captured through studies conducted by industries familiar with large application development. A prototype was constructed by integration and adaptation of a relational database management system (DBMS), a knowledge representation and manipulation tool, a software configurer, an automated configuration management system, and a common user interface with graphics capabilities. The project provided a model for representation of software development components (from specifications to code modules), an associated methodoloy for reusing such components and configuring large software systems, and a prototype system. This prototype was based upon the so-called KNOSOS building blocks (already existing and fully proved software tools brought to the project by the different partners). The KNOSOS building blocks consisted of a relational database management system, a knowledge representation and manipulation tool based on LISP, a tool for configuration management, and a common user interface based on the object oriented approach and having graphics capabilities. As a side effect, an interface between LISP and the relational DBMS being used was also developed and exploited. Preliminary partial prototypes emphasising particular aspects of the interfaces between the building blocks were built and demonstrated during the development phase of the project. The final prototype was demonstrated on a number of case studies, ranging from software tools for several engineering domains to space applications.
Two kinds of results emerged from the KNOSOS project: a model for representation of software development components (from specifications to code modules), an associated methodology for reusing such components and configuring large software systems, and a prototype system. This prototype was based upon the so-called KNOSOS building blocks (already existing and fully proved software tools brought to the project by the different partners). 
The KNOSOS building blocks consisted of a relational database management system, a knowledge representation and manipulation tool based on LISP, a tool for configuration management, and a common user interface based on the object-oriented approach and having graphics capabilities. As a side-effect, an interface between LISP and the relational DBMS being used was also developed and exploited. 
Preliminary partial prototypes emphasising particular aspects of the interfaces between the building blocks were built and demonstrated during the development phase of the project. 
The final KNOSOS prototype was demonstrated on a number of case studies developed by the main industrial partners in their domains of expertise, ranging from software tools for several engineering domains to space applications. 
Exploitation 
The impact of reuse techniques in increasing the productivity of the software development process does not need further demonstration, particularly with respect to the development and configuration of large software systems (thousands of modules), like the ones used in space applications. 
The technology and expertise developed by the companies participating in the consortium, particularly the end-user industrialists, will be fully exploited in their internal developments, resulting in an increase of productivity in the development of new systems from reusable components and in their eventual maintenance and upgrading. The LISP relational DBMS interface was fully exploited and is now integrated in the relational DBMS and is being commercialised by one of the partners.";;;;;ENGINEERING SYSTEM INTERNATIONAL SA;FR;"CNET France Télécom;ALCATEL TITN;DORNIER SYSTEM GMBH;Yard Software Systems Ltd;MATRA SA";"FR;DE;UK";
6454;MA1E0094;CEAM II;;FP1-EURAM;;FP1;CONCERTED EUROPEAN ACTION ON MAGNETS II;01/10/1988;31/03/1991;;"CEAM II operates on the basis of a series of general and topical meetings. There is a quarterly newsletter, and an information service and database operated from the Laboratoire Louis Neel, Grenoble. By bringing together most of the European manufacturers and uses of rare- earth iron permanent magnets, along with the academic research groups specializing in this branch of magnetism in a unique collaborative effort, it has proved possible to strengthen significantly the capabilities of European players in this field. 

A COORDINATED ACTIVITY ON RARE EARTH IRON PERMANENT MAGNETS AND THEIR APPLICATIONS IS PROPOSED. IT IS INTENDED TO BUILD ON THE ACHIEVEMENTS OF THE CONCERTED EUROPEAN ACTION ON MAGNETS (CEAM) WHICH RAN FROM 1ST OCTOBER 1985 TO 30TH SEPTEMBER 1988 AND WHICH LED TO THE ESTABLISHMENT OF STRONG LINKS BETWEEN RESEARCH ON ADVANCED MAGNETS AND THEIR INDUSTRIAL APPLICATIONS. 

THE PRINCIPAL AIM OF CEAM II IS A COORDINATED RESEARCH EFFORT ON THE PHYSICAL PROPERTIES, FABRICATION AND APPLICATION OF ADVANCED RARE-EARTH IRON PERMANENT MAGNETS WITHIN THE EUROPEAN COMMUNITY. APPROXIMATELY SIXTY ACADEMIC AND INDUSTRIAL LABORATORIES ARE TO BE INVOLVED IN THE PROGRAMME. 

THE TOPICS OF RESEARCH AND DEVELOPMENT ARE TO BE FOLLOWING: 
     - SYNTHESIS OF NEW INTERMETALLIC COMPOUNDS AND DUPLEX ALLOYS OF POTENTIAL INTEREST AS PERMANENT MAGNETS. 

     - INTRINSIC MAGNETIC PROPERTIES OF THESE NEW COMPOUNDS, AND SPECIFIC IMPROVEMENTS CONCERNING THE R2T14B SERIES. 

     - MECHANISMS FOR THE DEVELOPMENT OF COERCIVITY AND HYSTERISIS 

     - METALLURGICAL MICROSTRUCTURE AND PHASE RELATIONS 

     - STABILITY AND CORROSION STUDIES 

     - IMPROVEMENT OF THE PROCESSING OF RARE-EARTH IRON MAGNETS BY THE POWDER METALLURGY ROUTE. 

     - DIRECT PROCESSING ROUTES SUCH AS HOT WORKING OF INGOT OR DIRECT CASTING. 

     - BONDED MAGNETS WITH BOTH ORGANIC AND SOFT METAL MATRICES. 

     - APPLICATION OF BONDED MAGNETS IN REDESIGNED SUBFRACTIONS HORSE POWER MOTORS. 

     - IMPROVED INDUSTRIAL MACHINES FOR USE AT ELEVATED TEMPERATURES. 

     - DETAILED INVESTIGATION OF ASSEMBLY AND MAGNETIZATION STRATEGIES. 

     - EXPLOITATION OF HIGH-PERFORMANCE ND-FE-B MAGNETS FOR HIGH TORQUE-DRIVES, STEPPER MOTORS, BRUSHLESS D C MOTORS, SYNCHRONOUS MOTORS AND ACTUATORS. 

     - STATIC APPLICATIONS OF HIGH-PERFORMANCE MAGNETS. 

     - HIGH-ENERGY PERMANENT MAGNETS IN MEDICAL APPLICATIONS";;;;CSC;CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE;FR;"TRINITY COLLÈGE;TECHNISCHE UNIVERSITAT BERLIN";IE;
8633;395;INCA;;FP1-ESPRIT 1;;FP1;An Integrated Network Architecture for Office Communications;01/09/1984;01/09/1989;;"The principal purpose of the INCA project was to define and design an integrated network architecture for office communications within the framework of current international standards, particularly Open Systems Interconnection (OSI). It was also intended  to demonstrate aspects of the architecture with interworking implementations. The INCA architecture was intended to allow the interchange of many different representations of information (text, graphics, image, voice) over a wide variety of sub-networks, while presenting to the user a single integrated interface. 
The principal purpose of the project was to define and design an integrated network architecture for office communications within the framework of current international standards, particularly open systems interconnection (OSI).

Although international standards are technically stable in many of the areas covered by integrated network architecture for office communications (INCA) there are other areas (such as directory services and network management) where they are only just reaching maturity. Even in cases where the base standards are stable, few functional profiles have been completely defined, and the concept of International Standardized Profiles (ISP) has only recently emerged. As a result, it was necessary for the INCA project to define the required profiles and, as the international standards emerge, migrate to the appropriate standard. A significant amount of effort was expended in feeding the results of the INCA project into various standards bodies and influencing international standards design. Network management was an area of particular interest to the INCA team. It is a vital requirement for any integrated network architecture but, as yet, the standards are still being developed. Contribution has been made to the development of these standards and some implementation work has been undertaken.
Although international standards are technically stable in many of the areas covered by INCA, there are other areas (such as directory services and network management) where they are only just reaching maturity. Even in cases where the base standards are stable, few functional profiles have been completely defined, and the concept of International Standardised Profiles (ISPs) has only recently emerged. As a result, it was necessary for the INCA project to define the required profiles and, as the international standards emerge, migrate to the appropriate standard. A significant amount of effort was expended in feeding the results of the INCA project into various standards bodies and influencing international standards design. 
 Network management was an area of particular interest to the INCA team. It is a vital requirement for any integrated network architecture but, as yet, the standards are still being developed. The INCA partners have contributed to the development of these standards and Modcomp and UCL have undertaken some implementation work. 
Exploitation 
The project's output is leading to considerable commercial exploitation, either as a direct result of the project or by feeding the results to other projects. Some of this exploitation has already taken place. 
 GEC's main area of interest has been in FDDI networks, and a prototype FDDI station has been developed, incorporating station management software for use in a digital switching system. It is expected that this work will be incorporated into real projects within the next year. On a rather longer timescale, the work on network management is likely to be included in telecommunications systems. 
The work in INCA on the LAN controller has been taken as the reference for most of Olivetti's developments for both the PC and the new LSX minicomputer product lines. In the case of the latter, the INCA work on a SCSI board provided valuable experience, although the actual SCSI board developed did not become a product. The INCA work on protocol architectures and network management has been used as the foundation for Olivetti network products. 
In the case of Nixdorf (now SNI), the prototype of the high-resolution display developed within INCA has been further developed to become a commercial product (as part of SNI's Professional Workstation). A further (20') display is under development. The early work on the Standard Document Editor has led to a module of the PWS-X workstation. Later work (following the transition to ODA) has been used as input to the PODA projects (numbers 1024, 2374 and 5320). 
The Virtual Automated Processor (VAP) developed by Modcomp is available within the AEG group on proprietary hardware, but it can be modified to run in other environments such as Unix. Modcomp intend to market the Unix version initially in Europe but laterworldwide. Various other tools developed under INCA (such as the Ethernet monitor) are also likely to become commercially available. 
University College London has exploited the results of INCA in a somewhat different manner. Firstly, the results of the project are fed into teaching and into the wider research community. Secondly, there has been direct commercial exploitation by means of agreements between UCL and commercial organisations. Thirdly, the work is being used in further collaborative projects (such as the PODA projects mentioned above and project 2404, PROOF).";;;;;GEC-Marconi Materials Technology Ltd;UK;"Ingegneria C. Olivetti and C. SpA;System Wizards Srl;AEG-ATM;Siemens Nixdorf Informationssysteme AG;Birkbeck College, University of London";"IT;DE;UK";
8435;1507;PIMS;;FP1-ESPRIT 1;;FP1;A Project Integrated Management System;23/12/1985;23/06/1989;;"The PIMS project aimed to develop an integrated project management support system to be used as a consultant or as training system. The prototype management consultant and management instructor will be evaluated through field trials. 
This project was associated with project 938, IMPW. 
The project aimed to develop an integrated project management support system to be used as a consultant or as a training system. A theoretical approach developed the concept of a storyboard as a suitable vehicle for representing the general activity of project management. The representation of project management knowledge in a more formal way was also investigated. Important insights were gained from a series of structured interview sessions with individual project managers from the three industrial partners of the consortium. A tools survey identified and appraised many commercial packages aimed at project management. The first complete prototype emphasised a truly integrated toolset covering all phases and tasks of project management.
A theoretical approach developed the concept of a story-board as a suitable vehicle for representing the general activity of project management. The representation of project management knowledge in a more formal way was also investigated. 
Important insights were gained from a series of structured interview sessions with individual project managers from the three industrial partners of the consortium. 
A tools survey identified and appraised many commercial packages aimed at project management. 
The first complete prototype (PIMS*1) was successfully demonstrated in February 1988. This prototype emphasised a truly integrated toolset covering all phases and tasks of project management. 
Exploitation 
The results are being used by CAP-Sogeti and PACTEL. 
There has also been an exchange of results with the Integrated Product Management Workbench (project 938, IMPW) and a transfer to the EUREKA ESF. 
This project will have immediate impact on project management in the software industry when the resulting prototype is industrialised and marketed. The potential for exploitation appears very promising once this system has been integrated within a software factory in the 1990s.";;;;;CAP GEMINI INNOVATION;FR;"P A Consulting Group;BSO-BUREAU VOOR SYSTEEMONTWIKKELING;Turing Institute Ltd";"UK;NL";
12587;EN3S0089;PASCAUD;;FP1-ENNONUC 3C;;FP1;PASSIVE SOLAR IN COMPUTER AIDED URBAN DESIGN.;01/07/1986;31/10/1988;;"ONE OF THE MOST SIGNIFICANT RESULTS OF LAST DECADE'S NEW ENERGIES RESEARCH IS THE INTEGRATION OF SOLAR SYSTEMS INTO THE ARCHITECTURAL DESIGN OF INDIVIDUAL HOUSES AND BUILDINGS. YET, TO FACILITATE THE LARGE SCALE DEVELOPMENT OF SOLAR ARCHITECTURE, THIS IN TURN WILL HAVE TO BE INTEGRATED INTO THE REGULAR URBAN DESIGN PRACTICE OF TOWNS AND CITIES. TO ADDRESS THIS POTENTIAL BOTTLENECK, A FEASIBILITY STUDY WAS MADE ON LARGE SCALE USE OF PASSIVE SOLAR ENERGY IN THE MUNICIPALITY OF HAARLEMMERMEER, HOLLAND AS EARLY AS 1981. THE CONCLUSION OF THIS STUDY LED TO THE DEVELOPMENT OF A DEMONSTRATION PROJECT OF 275 HOUSES IN ONE OF HAARLEMMERMEER'S TOWN EXTENSIONS (OVERBOS 8). THIS DEVELOPMENT, ALTHOUGH SUCCESSFUL IN ENERGY AND COMFORT TERMS, SHOWED THAT SOLAR ARCHITECTURE IS IN FACT FACING THE URBAN DESIGNER WITH A DILEMMA. 
IN ORDER TO MANAGE THE COMPLEXITY OF THE URBAN DESIGN PROCESS, THE CONVENTIONAL WAY OF WORK ADHERES TO A TOP-DOWN DEVELOPMENT. IN THIS LINEAR PROCESS, DETAILED ARCHITECTURAL ASPECTS HAVE NO PLACE. YET SOLAR ARCHITECTURE ASKS FOR ITERATIVE LOOPS IN WHICH DETAILS LIKE GLAZING, ROOF SHAPES AND SHADOW FROM OTHER BUILDINGS ARE TO BE CONSIDERED ON THE URBAN DESIGN LEVEL. THIS NECESSITY OF CREATING ITERATIVE LOOPS BETWEEN GLOBAL (URBAN) DESIGN AND DETAILED (ARCHITECTURAL) DESIGN IS NOT CONFINED TO SOLAR ISSUES ALONE THOUGH. THE NEED FOR FEED-BACK LOOPS IN DESIGNING IS THE 'RAISON D'ETRE' FOR MOST COMPUTER AIDED DESIGN SYSTEMS. PRESUMINGLY ONE OF THE MOST EFFECTIVE WAYS OF INTEGRATING SOLAR ARCHITECTURE INTO THE URBAN DESIGN PROCESS IS THEREFORE TO INTEGRATE IT WITH THE ONGOING DEVELOPMENTS IN COMPUTER AIDED-URBAN-DESIGN. 
THIS ABSTRACT REPORTS ON THE FINAL STAGE OF A PROJECT AIMED AT INTEGRATING PASSIVE SOLAR ASPECTS INTO A COMPUTER AIDED URBAN DESIGN SYSTEM. THE PROJECT IS CALLED PASCAUD, PASSIVE SOLAR IN COMPUTER AIDED URBAN DESIGN AND IS CARRIED OUT AS A CASE-STUDY IN THE MUNICIPALITY OF HAARLEMMERMEER. THE STUDY ADHERES TO A STANDARD METHODOLOGY OF SYSTEMS DEVELOPMENT AND IS UP TO THE FINAL PHASE AT PRESENT. THE END-PRODUCT OF THIS PHASE WILL CONTAIN A SOFTWARE PACKAGE FOR THE INTERGRAPH CAD SYSTEM OF HAARLEMMERMEER, A MANUAL AND A FINAL REPORT. THIS FINAL REPORT WILL DESCRIBE THE: 
- INFORMATION REQUIREMENTS MODEL OF THE URBAN DESIGN PROCESS, 
- TECHNICAL DESIGN DETAILS OF THE SOFTWARE THAT IS TAILORED TO THIS MODEL, 
- USABILITY OF THE SOFTWARE, 
- REUSABILITY OF THE SOFTWARE MODULES FOR MODIFICATION PURPOSES AND FOR TRANSLATION ON COMPUTERS OF DIFFERENT MANUFACTURERS, 
- REUSABILITY OF THE SOFTWARE DEVELOPMENT PROCESS ITSELF. 
IT WILL ALSO CONTAIN A COMPARISON WITH THE REUSABILITY APPROACH OF THE SOFTWARE TECHNOLOGY OBJECTIVES OF ESPRIT. AND IT WILL ASSESS THE USE OF THE SOFTWARE DEVELOPMENT TOOL BLUES AS A WAY TO ATTAIN STATE-OF-THE-ART REUSABILITY OF ENERGY SOFTWARE.";;;;CSC;FUGRO ENGINEERS B.V.;NL;;;
8451;1072;DIAMOND;;FP1-ESPRIT 1;;FP1;Development and Integration of Accurate Operations in Numerical Data Processing;01/01/1986;01/01/1989;;"The objective of DIAMOND was to develop methods and tools for accurate floating-point arithmetic on computers, based on a mathematical theory of computer arithmetic in which all operations are defined by so-called semimorphisms. Such a systematic theory of computer arithmetic aims to perform the basic arithmetic operations to maximum accuracy and to provide sufficient control over the rounding process so as to ensure reliable error bounds. This project pursued several different approaches: embedding of convenient arithmetic notations into ADA and Pascal; AI techniques for formula transformation and symbolic manipulation; and construction of a methodological framework and a knowledge-base for numerical programming. . 
The objective was to develop methods and tools for accurate floating point arithmetic on computers, based on a mathematical theory of computer arithmetic in which all operations are defined by so called semimorphisms. Such a systematic theory of computer arithmetic aims to perform the basic arithmetic operations to maximum accuracy and to provide sufficient control over the rounding process so as to ensure reliable error bounds. This project pursued several different approaches: embedding of convenient arithmetic notations into the languages ADA and Pascal; artificial intelligence (AI) techniques for formula transformation and symbolic manipulation; and construction of a methodological framework and a knowledge base for numerical programming. Packages for general scientific computation were implemented in Pascal SC (Scientific Pascal) and Ada. They accurately state the intervals (due to truncation and rounding) in which their results lie. They include real and complex arithmetic, operations on scalars, vectors, matrices and linear equations, and the computation of eigenvalues and the roots of polynomials. The application of the prototypes to some critical examples demonstrated the greater accuracy and reliability of the new operators in comparison to classical arithmetic operators. A facility to allow problems to be stated by the use of symbolic notation was specified and is being implemented. This will simplify system use and give faster execution of operations. A Pascal SC-Ada translator was completed for use in the translation of the Pascal-SC modules, and has been used to create some Ada packages with market potential. A submission of a joint American-European proposal to standardize Ada was made.
-Packages for general scientific computation were implemented in Pascal SC (Scientific Pascal) and Ada. They accurately state the intervals (due to truncation and rounding) in which their results lie. They include real and complex arithmetic, operationson scalars, vectors, matrices and linear equations, and the computation of eigenvalues and the roots of polynomials. 
-The application of the prototypes to some critical examples demonstrated the greater accuracy and reliability of the new operators in comparison to classical arithmetic operators. 
-DIAMOND has been presented at eleven international conferences. Workshops have been held to tell potential users about DIAMOND's tools. 
-A facility to allow problems to be stated by the use of symbolic notation was specified and is being implemented. This will simplify system use and give faster execution of operations. 
-A Pascal SC-Ada translator was completed for use in the translation of the Pascal-SC modules, and has been used to create some Ada packages with market potential. 
-A submission of a joint American-European proposal to standardise Ada was made. 
-A book entitled 'DIAMOND: Accurate Numerical Algorithm' has been published by Springer Verlag in the ESPRIT series. 
Exploitation 
The improved accuracy, reliability and efficiency that the use of the project's packages brings to numerical programming is a field of interest for many scientific and industrial domains. Consequently, the market possibilities of the DIAMOND results are being studied, in particular, through a French initiative on numerical quality. 
 Tools are being released through the numerical algorithms library (NAG), for which the first edition of the catalogue has been published. The exploitation of DIAMOND's tools and the standardisation of floating-point arithmetic is to be expected in ESPRIT II through the participation of the partners in SUPERNODE II, GENESIS and other projects. 
Tools, documents and demonstrations are available on request.";;;;;Siemens AG;DE;"Universität Fridericana Karlsruhe (Technische Hochschule);CWI-CENTRUM VOOR WISKUNDE & INFORMATICA;VSN International Limited";"DE;NL;UK";
8440;967;PADMAVATI;;FP1-ESPRIT 1;;FP1;Parallel Associative Development Machine as a Vehicle for Artificial Intelligence;24/02/1986;24/02/1990;;"The objective of PADMAVATI was to develop a high-performance computer system suitable for symbolic and time-critical applications such as real-time speech and image understanding. 
The machine architecture is based on an array of computational transputer nodes, each containing a high-performance multiprocessor and memory and communication interfaces. The use of an associative memory architecture (hashed DRAM and a CAM) accelerates the programming languages and applications. The programming environment was standard Prolog and LE-LISP with extensions to support parallel execution. The complete machine has been tested by implementing experimental, computationally-intensive tasks from the fields of parallel expert systems, speech, and image understanding. 
The objective was to develop a high performance computer system suitable for symbolic and time critical applications such as real time speech and image understanding. The machine architecture is based on an array of computational transputer nodes, each containing a high performance multiprocessor and memory and communication interfaces. The use of an associative memory architecture (hashed dynamic and random access memory (DRAM) and a content addressable memory (CAM)) accelerates the programming languages and applications. The programming environment was standard Prolog and LE-LISP with extensions to support parallel execution. The complete machine has been tested by implementing experimental, computationally intensive tasks from the fields of parallel expert systems, speech, and image understanding. Processor nodes were built, and tested. The associative memory (CAM) chips have been designed and built, and are being packaged using TAB bonding. A message passing run time system was developed, to support communication in the network. The symbolic languages LE-LISP and Prolog were extended to exploit the architecture and allow macro parallelism (the code is annotated by the user when parallelism is required). A micro parallel Prolog, LOGARITHM, was developed. Three prototypes, comprising 16 nodes with a reconfigurable network and 1 to 16 CAMs have been integrated.
DYNET, a dynamically reconfigurable and cascadable routing chip, is now available as a commercial product. It allows up to 256 nodes to be connected in the desired network topology. 
 Processor nodes (a T800 transputer and CAM with 8 or 16 Mbytes of DRAM) were built, and tested. The associative memory (CAM) chips have been designed and built, and are being packaged using TAB bonding. The CAM can be seen either as an intelligent memory with a constant-time search with 'don't cares', or alternatively as a SIMD processor array. 
A message-passing run time system was developed, to support communication in the network. 
The symbolic languages LE-LISP and PROLOG were extended to exploit the architecture and allow macro-parallelism (the code is annotated by the user when parallelism is required). A micro-parallel Prolog, LOGARITHM, was developed as well. 
Three prototypes, comprising 16 nodes with a reconfigurable network and one to sixteen CAMS have been integrated. 
Exploitation 
Many applications can be envisaged for the state-of-the-art CAM. The viability of associative devices in an efficient implementation of concurrent LISP and sequential and parallel Prolog have been demonstrated. 
By allowing physically distant nodes to communicate directly, DYNET allows users to integrate now functionalities that will be available in the next-generation transputer; users can explore this new functionality before the new transputer becomes available.";;;;;THOMSON CSF;FR;"FIRST INTERNATIONAL;Centro Studi e Laboratori Telecomunicazioni SpA;GEC-Marconi Materials Technology Ltd";"EL;IT;UK";
8424;1503;GRADIENT;;FP1-ESPRIT 1;;FP1;Graphics and Knowledge-Based Dialogue for Dynamic Systems;01/10/1985;01/10/1990;;"The objectives of the GRADIENT project were to investigate the use of knowledge-based systems to support operators of industrial supervision and control systems, and to enable such operators to conduct an intelligent dialogue with the process, supported by graphical expert systems. 
These objectives were to be achieved by building a set of cooperating expert systems which supported a dynamic dialogue. This complex of systems was to be designed to provide the system operator with intelligent support during fault investigation, emergency containment and system modification, as well as during normal operation. The GRADIENT system was intended to be introduced as additional support to be used in parallel with existing supervision and control systems, with a potential of replacing the conventional systems in the future. 
A further aim of the project was to assemble KBS demonstrators for use in 'hard-tech' industrial environments and to identify appropriate metrication aspects and methods. 
The objective of the project were to investigate the use of knowledge based systems to support operators of industrial supervision and control systems, and to enable such operators to conduct an intelligent dialogue with the process, supported by graphical expert systems. The final system is implemented as a number of independent modules cooperating in predefined roles. They include the quick response expert system, responsible for fast reaction to system faults; the response evaluation system, which monitors the operator actions and relates them to procedural plans; the dialogue system, which channels communications between the operator and the system; and the support expert system, which helps the operator in a failure situation. The first version of the intelligent graphical editor was demonstrated in another demonstrator; this is an offline tool for the design of graphics displays. The system integrating all the modules was demonstrated in the context of 2 applications at the final review. These applications are the control of conventional power plants and the control of a communication network. In parallel, a collection of decision support systems for materials and treatment selection in the field of corrosion was demonstrated; studies on metrication aspects have been completed with those systems.
The final GRADIENT system is implemented as a number of independent modules cooperating in predefined roles. These modules have been implemented and demonstrated. In particular, the Quick Response Expert System, responsible for fast reaction to system faults (October 1987); the Response Evaluation System, which monitors the operator actions and relates them to procedural plans (October 1988); the Dialogue System, which channels communications between the operator and the system (October 1988); and the Support Expert System, which helps the operator in a failure situation (April 1990), were initially demonstrated in the context of one demonstrator. In addition, the first version of the Intelligent Graphical Editor was demonstrated in another demonstrator (June 1988); this is an off-line tool for the design of graphics displays. Furthermore, the second version, called IGE2, was demonstrated (November 1989), leading to the IGE3 demonstration (April 1990). The system integrating all the modules was demonstrated in the context of two applications at the final review in October'90. These applications are the control of conventional power plants and the control of a communication network. 
In parallel, a collection of decision support systems for materials and treatment selection in the field of corrosion was demonstrated (October 1988); studies on metrication aspects have been completed with those systems. 
Exploitation 
Two of the system nodules are being further developed for introduction in actual control systems by ABB. This should open the way for introducing more of the advanced ideas developed in GRADIENT in real applications in the future. The network control system will serve as a basis for internal operations for one of CRI's partners. The expert systems for decision support in the field of corrosion are being industrially exploited by DENAC, a subcontractor of KUL. The University of Kassel is trying to commercialise the visual presentation system developed. A prototype was displayed at CeBit.";;;;;CRI A/S;DK;"KATHOLIEKE UNIVERSITEIT LEUVEN RESEARCH AND DEVELOPMENT;Asea Brown Boveri AG;University of Strathclyde;Universität Gesamthochschule Kassel";"BE;DE;UK";
8434;1505;DELTA-4;;FP1-ESPRIT 1;;FP1;Definition and Design of an Open Dependable Distributed Computer System Architecture;01/03/1986;01/03/1989;;"The objectives of the DELTA-4 project were to formulate, develop and demonstrate an open system, fault-tolerant, distributed computer connection architecture conforming to the OSI model. The architecture was to be capable of being configured to support a range of performances and dependabilities and to manage distributed processing, as well as offering transparent fault-tolerant and network management to the user. These features, plus the ability to connect heterogeneous computer systems into one architecture, were perceived to be directly applicable to the computer-integrated manufacturing and office systems areas. Emphasis was particularly placed on new communication techniques (optical and electrical) and concepts. A key feature of the project was to be a series of progressive demonstration prototypes, which were to form the basis for rapid commercial exploitation of the results. . 
The microcomputer based prototype system consists of 3 units:
 the data acquisition unit, installed inside the vehicles, that reads vehicle status;
 the registration unit that stores the data, read by the data acquisition unit, in a digital cassette;
 the processing unit that reads the digitised information for the whole fleet and gives statistics and the current status of the fleet.

The objectives of the project were to formulate, develop and demonstrate an open system, fault tolerant, distributed computer connection architecture conforming to the open system interconnection (OSI) model. The initial phase concentrated on the 3 main topics needed to build an open dependable distributed system. Firstly, specification and implementation of a multicast communication system (MCS) on a local area network (LAN). A prototype of the MCS was demonstrated. Secondly, specification of a high performance, cost effective network station to support the system architecture. Specifications were produced and 2 demonstrators developed. Thirdly, network management to guide the overall work on dependability. A first level of specification was achieved. These developments continued in the main phase, augmented by work on: design and development of an application support environment, to give distributed computer systems protection against local station failures via replication of tasks over the network; validation of protocols through the use of the ESTELLE formal description technique; and a study of pilot sites, to be used in the next phase. Results from these areas provided the project with a network which supports advanced protocols, a node architecture, and the global framework to integrate dependability into a distributed system.
The initial phase concentrated on the three main topics needed to build an open dependable distributed system: 
-Specification and implementation of a multicast communication system on a LAN. A prototype of the MCS was demonstrated. 
-Specification of high-performance, cost-effective 'network station' to support the DELTA-4 system architecture. Specifications were produced and two demonstrators developed (RT Unix and RSR (Remote Service Request) prototypes). 
-DELTA-4 network management to guide the overall work on dependability. A first level of specification was achieved. 
These developments continued in the main phase, augmented by work on: 
-design and development of an application support environment, to give distributed computer systems protection against local station failures via replication of tasks over the network 
-validation of protocols through the use of the ESTELLE formal description technique (see work carried out in projects 410, SEDOS, and 1265, SEDOS DEMO 
-study of pilot sites, to be used in the next phase. 
Results from these areas provided the project with: 
-a network which supports advanced protocols 
-a node architecture 
-the global framework to integrate dependability into a distributed system. 
Exploitation 
The interconnection equipment for heterogeneous systems delivered by this project is particularly relevant for distributed applications in computer-integrated manufacturing and office systems. 
Product marketing is planned by Bull, and Ferranti is marketing a Unix-based real-time system derived from work on this project.";;;;;Bull SA;FR;"Gesellschaft für Mathematik und Datenverarbeitung mbH;Fraunhofer-Gesellschaft zur Förderung der Angewandten Forschung eV (FhG);INESC-INSTITUTO DE ENGENHARIA DE SISTEMAS E COMPUTADORES;Telettra SpA;JEAN LEFEBVRE TELECOM;Institut National Polytechnique de Grenoble;NATIONAL RESEARCH COUNCIL OF ITALY;CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE;Università degli Studi di Bologna;Ferranti International plc;MARI Applied Technologies Ltd";"DE;PT;IT;FR;UK";
8394;390;PROSPECTRA;;FP1-ESPRIT 1;;FP1;Program Development by Specification and Transformation;01/03/1985;01/03/1990;;"The objective of this project was to develop a strict methodology for program development by applying successive transformations to an initial requirement specification down to the final implementation. This allows the user to prove that the implementation meets the specification, and that the program is correct. A wide-spectrum language ranging from formal specifications to Ada programs was to be defined, with its semantics covering concurrency aspects. The use of Ada and Anna as a basis ensured a high portability of the methodology. In order to support it, a collection of tools was developed. 
At each level of the methodology (from requirement specification to implementation) tools were generated according to a uniform paradigm; this includes a syntax-directed editor, a transformation and control language, a method bank (where rules and heuristics are stored) a library manager (where objects like developments and versions can be stored), and a verifier. 
PROSPECTRA was closely associated with PROSPECTRA-D, project 835. 
The PROSPECTRA system is designed to support program development by specification and transformation. Starting from formal (algebraic) specifications of system requirements, efficient implementations shall be constructed by transformation.
The system comprises:
 a language oriented editor for Trafola, a transformation definition language;
 a transformer generator for Trafola;
 a language oriented editor for PAnndA-S, the PROSPECTRA Ada-Anna subset language (for writing specifications);
 an interactive transformer for PAnndA-S programs;
 a verifier for checking the applicability of transformations;
 a library manager and a controller.

The objective of this project was to develop a strict methodology for program development by applying successive transformations to an initial requirement specification down to the final implementation. This allows the user to prove that the implementation meets the specification, and that the program is correct. A wide spectrum language ranging from formal specifications to Ada programs was defined, with its semantics covering concurrency aspects. In order to support it, a collection of tools was developed. At each level of the methodology (from requirement specification to implementation) tools were generated according to a uniform paradigm; this includes a syntax directed editor, a transformation and control language, a method bank (where rules and heuristics are stored) a library manager (where objects like developments and versions can be stored), and a verifier. Abstraction and development mechanisms are now better understood.
PROSPECTRA made significant progress in a number of areas: 
-at the methodology level, where the abstraction and development mechanisms are now better understood 
-at the transformation level, where considerable experience was gained by developing the OPTRAN System (a generator for batch-made transformers on attributed trees). 
The semantics of PAnndA-s (Prospectra Ada/Anna), which is based on a two-valued logic, have also been stabilised, and scenarios were designed to investigate the applicability of the PROSPECTRA methodology to practical systems. 
PROSPECTRA and PROSPECTRA-D produced a design support system which guides the user through the successive refinements by proposing a set of rules which ensure that correctness is preserved as the design process proceeds. 
In addition to this, some work was also carried out on verification techniques, one outcome being the so-called CEC (Conditional Equational Completion) system, originally based on Knuth-Bendix completion techniques. 
Experiments were carried out that resulted in PROSPECTRA's basic system architecture being based on the Cornell Synthesiser Generator, with the benefit of ensuring a high degree of homogeneity among the various tools developed. 
Exploitation 
 The PROSPECTRA project made significant advances in the field of the 'transformational' approach (most of the partners formerly contributed to the CIP project, which was a leader in that area), and has brought this closer to real industrial exploitation. To this end, a demonstrator project was coupled with PROSPECTRA (see project 835), and very tight links established between the academic and industrial partners.";;;;;UNIVERSITAET BREMEN;DE;"SAARLAND UNIVERSITY;UNIVERSITÄT PASSAU;SYSECA SA;CRI-COMPUTER RESOURCES INTL. A/S;ALCATEL STANDARD ELECTRICA SA;SYSTEAM KG;University of Strathclyde;Universität Dortmund";"DE;FR;DK;ES;UK";
8646;1614;CSA;;FP1-ESPRIT 1;;FP1;Communications Systems Architecture;29/11/1984;29/11/1989;;"Within the office and communications environments there is a trend towards multivendor systems with distributed computing power. By its very nature information and the associated input/output resources are distributed on different nodes and accessed by many users from a variety of terminal devices. It is this complex picture which motivated the CSA consortium to investigate how such systems could be constructed and managed in a consistent manner. The team was convinced that major benefits could be realised if a consistent platform could be provided for application systems irrespective of whether the underlying resources were single system/single vendor or distributed over multivendor systems. 
The overall aim of the project was to specify and design an architecture that provides an environment consistent with the above objectives. In order to achieve this the following architectural requirements were identified: 
-abstraction from heterogeneity of different hardware and operating systems, thus providing portability 
-abstraction from distribution, thus providing location-transparent communication 
-support for communication with non-CSA systems 
The five-year project was organised into two major phases: 
-Identification of the needs for communication by analysis of user requirements, followed by development of the architectural specification (years 1 and 2). 
-Development of a prototype system based on currently available technology using appropriate standards and existing communication networks, followed by the demonstration of distributed applications on top of this system (years 3, 4 and 5). 
Within the office and communications environments there is a trend towards multivendor systems with distributed computing power. By its very nature information and the associated input/output resources are distributed on different nodes and accessed by many users from a variety of terminal devices. This complex picture motivated the investigation into how such systems could be constructed and managed in a consistent manner.

The overall strategic architecture was defined and based on an object oriented approach for structuring the problems associated with the office and communications environments. The architecture provided integrated techniques for managing resources and handling communication between entities. A prototype machine was demonstrated in September 1988. It incorporated those features required to provide abstraction from the underlying hardware and operating system of a single machine. A prototype system consisted of a number of these machines, and illustrated the architectural features that support abstraction from distribution.
The overall strategic architecture was defined in December 1986. It is based on an object-oriented approach for structuring the problems associated with the office and communications environments. The architecture provides integrated techniques for managing resources and handling communication between entities. 
A prototype machine was demonstrated in September 1988. It incorporated those features required to provide abstraction from the underlying hardware and operating system of a single machine. A prototype system demonstrated at the 1989 ESPRIT Conference exhibition consisted of a number of these machines, and illustrated the architectural features that support abstraction from distribution. Some distributed applications were implemented and demonstrated as well.";;;;;Roke Manor Research Ltd;UK;"VALVO BAUELEMENTE PHILIPS GMBH;SYNERGIE INFORMATIQUE & DEVELOPPEMENT;ITK Informations-Technologie Kiel GmbH;MARI Applied Technologies Ltd";"DE;FR;UK";
8652;1623;TODOS;;FP1-ESPRIT 1;;FP1;Tools for Designing Office Systems;01/01/1986;01/01/1989;;"The aim of the TODOS project was to develop tools to support office systems design. These tools were to cover all phases from the planning stage to the proposal of an office systems architecture. The tools developed were to support requirements collectionand analysis, logical design, the rapid prototyping of office systems to validate requirements, and architecture design. 
The objectives of the work programme were to: 
-investigate models for office systems design, from feasibility analysis through to implementation specification 
-provide a design support environment, based on graphic interfaces and using expert techniques, to guide the designer and to identify problems and incorrect specifications 
-provide tools for the evaluation of the proposed office models during the different development phases 
-provide tools for the design of the office system architecture 
-provide tools for office prototyping based on the specification of the conceptual model. 
The aim of the project was to develop tools to support office systems design. These tools were to cover all phases from the planning stage to the proposal of an office systems architecture. The tools developed were to support requirements collection and analysis, logical design, the rapid prototyping of office systems to validate requirements, and architecture design.

A report was produced on office characteristics, office models, design methodologies, design support tools and system development methodologies and environments. Existing multimedia databases were investigated and a conceptual model and a specification language were specified. A rapid prototyping model was developed as were tools for the practical validation of the methods and concepts developed.
The achievements of TODOS were as follows: 
-a report was produced on office characteristics, office models, design methodologies, design support tools and system development methodologies and environments 
-existing multimedia databases were investigated 
-a TODOS conceptual model and a specification language were specified 
-a rapid prototyping model was developed 
-tools were developed for the practical validation of the methods and concepts developed. 
The results achieved in project 56, FAOR were successfully developed in this project. 
Exploitation 
The TODOS project developed methodologies and support tools for office systems design which will enable the more effective and efficient introduction of IT technologies in the office.";;;;;Dornier System GmbH;DE;"Universität Köln;SEMA METRA GROUP SA;OCE-NEDERLAND BV;THOMSON INFORMATIQUE SERVICES;Systems and Management SpA;Italtel Telematica SpA;Université de Paris I (Panthéon - Sorbonne);NATIONAL RESEARCH COUNCIL OF ITALY;Politecnico di Milano";"DE;FR;NL;IT";
8565;1551;AMS;;FP1-ESPRIT 1;;FP1;Advanced Manufacturing System;09/12/1986;09/12/1990;;"The manufacturing process of ICs has special requirements concerning the establishment of long-term strategy on software and hardware packages for its full automation. The objective of this project was to satisfy those requirements within an advanced integrated manufacturing system concept. In particular, attention was paid to problems associated with increased fabrication complexity, small device geometries, large chip-size, flexibility (process, product, equipment, facility, etc), increased yield (maintenance concepts, process stability, people and process-production interactions), increased wafer diameter, new process concepts, automation, and fast materials cycle time. 
The following topics were addressed: 
-production information systems 
-networking, communications, interfaces 
-automation island definition and experiment 
-facility monitoring systems 
-materials handling systems 
-manufacturing line integration 
-manufacturing requirements with emphasis on quality, service and production cost issues. 
Advanced manufacturing system (AMS) was a development programme to explore the software requirements and the automation concepts, to provide capability and competitiveness to the European semiconductor industry.

Without supplying new products (software, equipment), AMS tested packages and developed experimental tools in real industrial situations, to demonstrate the potential benefits by defining specifications for interfaces and communication protocols, as well as for software functions.

The objective of this project was to satisfy these requirements for automation of an advanced integrated manufacturing system concept. In particular, attention was paid to problems associated with increased fabrication complexity, small device geometries, large chip size, flexibility, increased yield, increased wafer diameter, new process concepts, automation, and fast materials cycle time. The following topics were addressed: production information systems; networking, communications, interfaces; automation island definition and experiment; facility monitoring systems; materials handling systems; manufacturing line integration; and manufacturing requirements with emphasis on quality, service and production cost issues. Comprehensive studies and requirement analyses were carried out, and reports delivered on the application model and functional architecture of the production information system, statistical process modelling, definition of network requirements and evaluation of software packages, connection of equipment with host computers, linkage of equipment in the photolithography area, analysis and requirements for material handling systems, and software and hardware flexibility for automated very large scale integration (VLSI) manufacturing. An initial demonstrator was set up in the photolithography area. A common model of a computer aided manufacture CAM system was defined with equipment interfacing, automation island, software and sensors for facility monitoring, wafer storage and transportation, wafer marking, modelling and fab simulation. Subsequently, detailed specifications of common CAM system requirements, and the development of specific modules for tracking products and equipment recipes were produced, as were interface modules for equipment connection and distributed databases. Cell controller definition, development and implementation in different environments and experimental robot installations were carried out. An expert system was developed for o perator help in 2 applications, and a software tool for wafer fab modelling/simulation. The system demonstration was centred around 2 automation islands, photolithography and diffusion.
During the first year of the project, comprehensive studies and requirement analyses were carried out, and reports delivered on the application model and functional architecture of the production information system, statistical process modelling, definiti on of network requirements and evaluation of software packages, connection of equipment with host computers, linkage of equipment in the photolithography area, analysis and requirements for material handling systems, and software and hardware flexibility for automated VLSI manufacturing. An initial demonstrator was set up in the photolithography area. 
In the second year and the first half of the third year, work was mainly devoted to the definition of a common model of CAM system, equipment interfacing, automation island, software and sensors for facility monitoring, wafer storage and transportation, wafer marking, modelling and fab simulation. 
Highlights of the third year's progress were: 
-detailed specifications of common CAM system requirements, and the development of specific modules for tracking products and equipment recipes 
-interface modules for equipment connection and distributed databases 
-cell controller definition, development and implementation in different environments and experimental robot installations 
-export system development for operator help in two applications 
-software tool for wafer fab modelling/simulation. 
During the fourth and last year of the project, the participants have consolidated and completed the work planed on the technical topics mentioned above. 
The system demonstration was centred around two automation islands, photolithography and diffusion. 
Exploitation 
Process line integration/automation has now become one of the key factors of success in the manufacturing of commodity or specialised (ASIC) ICs. 
The exploitation of the project's results will help the Community IC manufacturers concerned to improve their manufacturing capabilities. A technical interest group on VLSI manufacturing automation has been set up as part of the project, organising regular workshops to which other Community organisations are invited to attend. In this way it is expected to ensure a higher degree of harmonisation and to further increase the impact of the project. 
The results of the project are also being used in the Manufacturing Science and Technology project (number 5081).";;;;;SGS Thomson Microelectronics SA;FR;"Thomson Microelectronics Srl (SGS);GEC Marconi Electronic Devices Ltd";"IT;UK";
8423;1502;PROSPECTRA-D;;FP1-ESPRIT 1;;FP1;Demonstration of PROSPECTRA Methodology and System;01/11/1986;01/11/1989;;"PROSPECTRA-D aimed to show the feasibility of applying the PROSPECTRA methodology and its support tools to real-life industrial projects, as well as providing feedback to PROSPECTRA itself. The two projects were tightly coupled. 
PROSPECTRA (project 390) provided a rigorous methodology for developing correct software based on transformations, together with a comprehensive support system. Both the method and the tools represent a significant departure from current practice in the industry. 
PROGRESS AND RESULTS 
Technology transfer actions by means of courses taught by some academic members of the PROSPECTRA project were undertaken. The transfer has also been made more effective by having some members of the PROSPECTRA-D project participate directly in PROSPECTRAitself. 
Preliminary experiments were conducted on specifying some examples with the specification language PANNDAA-S. Data was collected about the way the PROSPECTRA methodology is understood by its users, and this feedback has influenced the PROSPECTRA system design and architecture. 
EXPLOITATION 
The partners have gradually introduced this new technology into their industrial practice. Its effectiveness and efficiency are being tested by applying both the methodology and the support system to a class of larger problems. 
The project aimed to show the feasibility of applying the PROSPECTRA methodology and its support tools to real life industrial projects, as well as providing feedback to PROSPECTRA itself. The two projects were tightly coupled. PROSPECTRA provided a rigorous methodology for developing correct software based on transformations, together with a comprehensive support system. Both the method and the tools represent a significant departure from current practice in the industry. Technology transfer actions by means of courses taught by some academic members of the PROSPECTRA project were undertaken. The transfer has also been made more effective by having some members of the project participate directly in PROSPECTRA itself. Preliminary experiments were conducted on specifying some examples with the specification language PANNDAA-S. Data was collected about the way the PROSPECTRA methodology is understood by its users, and this feedback has influenced the PROSPECTRA system design and architecture.";;;;;ALCATEL STANDARD ELECTRICA SA;ES;SYSECA SA;FR;
8401;1486;EPSILON;;FP1-ESPRIT 1;;FP1;Advanced Knowledge Base Management System;15/11/1984;15/11/1989;;"The objective of EPSILON was to build an environment for the development and use of knowledge-based management systems (KBMS) based on standard technologies, namely relational databases and Prolog. It was to be portable, extensible, and available on a wide range of minicomputers and workstations. 
Three technical goals were set for these objectives to be achieved: 
-integration of logic programming and database technologies 
-linguistics extensions and analysis and verification tools 
-a user interface for non-expert users. 
The objective was to build an environment for the development and use of knowledge based management systems (KBMS) based on standard technologies, namely relational databases and Prolog. It was to be portable, extensible, and available on a wide range of minicomputers and workstations. Three technical goals were set for these objectives to be achieved: integration of logic programming and database technologies; linguistics extensions and analysis and vertification tools; a user interface for nonexpert users. The project made progress in the prototypeintegration of the general system, in the development of a kernel inference engine allowing the construction of different inference machines by specifying the control structure, in the development of a graphical user interface, using window techniques, and in the connection of distributed data and knowledge bases through local area networks. The project developed the notion of theories and the object oriented concept of links between theories. Techniques that allow a combination of rules and relational algebraic expressions were established. A prototype system was developed to assess company credit worthiness in accordance with the financial and credit policies of the Italian government. A further system assists banker in their assessment of customer loan applications.
The EPSILON project made progress in the following four areas: 
-prototype integration of the general system 
-development of a kernel inference engine allowing the construction of different inference machines by specifying the control structure 
-graphical user interface, using window techniques 
-connection of distributed data and knowledge bases through local area networks (LANs). 
The project developed the notion of theories and the object-oriented concept of links between theories. Techniques that allow a combination of rules and relational algebraic expressions were established. 
A prototype system was developed to assess company credit-worthiness in accordance with the financial and credit policies of the Italian government. A further system (the Loan Expert) assists bankers in their assessment of customer loan applications.Exploitation 
A prototype workstation was produced which allows the use of Unix-based Prolog and a commercially available relational database in one system. 
A second prototype connects the DBMS workstations to form an integrated KBMS. 
The work on theories could prove to be a very flexible and powerful approach to the development of knowledge-based systems, especially in a Prolog environment. 
EPSILON will be ported and experimented on parallel architecture developed in project 2025 (EDS).";;;;;S & M Advanced Technologies;IT;"ADR-CRISS;Institut National des Sciences Appliquées de Lyon (INSA);BENSE KG;UNIVERSITA DEGLI STUDI DI PISA;Universität Dortmund";"FR;DE;IT";
8661;367;SOMIW;;FP1-ESPRIT 1;;FP1;Secure, Open, Multimedia, Integrated Workstation;01/01/1985;01/01/1989;;"The aim of the SOMIW project was to build an advanced multimedia workstation for office workers. The project focused on the following topics: 
-Communications: the goal was to enable the user to communicate through different types of network, in particular ISDN, with communication protected against intrusion by using a cryptosystem based on public keys. 
 -Multimedia input/output components: the aim was to integrate different I/O components in the workstation, including classical devices, such as the mouse and the keyboard, and intelligent ones, such as an OCR (Optical Character Recognition) module, a voi ce recognition and synthesis component, an image processor (allowing acquisition and display of animated colour images for transmission or archiving purposes), and a voice processor for coding voice at different rates. 
 -User Interface Management System (UIMS): UIMS was added to the project to manage the interaction with the user. Separating application development and user interface development allowed the splitting of responsibilities, with a specialist handling the d ifficult task of designing and implementing a dialogue structure (including the command syntax). 
 -Integrated applications: for preparing and handling documents, a multimedia WYSIWYG (What You See Is What You Get) editor, formatter, printer server and a filing and retrieval system were to be developed. The object-oriented operating system and the use r interface management system were designated to facilitate the integration of all the software components (editor, formatter-printer server, filing, retrieval, and screen management). 
A workstation design, the Metaviseur, was adopted to permit the integration of the proposed devices, thereby defining a standard reference architecture. 
A black and white video camera has been developed with automatic video level command for adjustment to light variations. The camera, the dimensions of which are 50 x 50 x 30 mm, uses a sensor cooling system based on the Peltier effect.

The aim of the project was to build an advanced multimedia workstation for office workers, enabling the user to communicate through different types of network with communication protected against intrusion by a cryptosystem based on public keys. Different input/output components were integrated in the workstation, including classical devices, such as the mouse and the keyboard, and intelligent ones, such as an optical character recognition module, a voice recognition and synthesis component, an image processor and a voice processor for coding voice at different rates. A user interface management system (UIMS) was added to the project to manage the interaction with the user. Separating application development and user interface development allowed the splitting of responsibilities, with a specialist handling the difficult task of designing and implementing a dialogue structure. For preparing and handling documents, a multimedia 'what you see is what you get' editor, formatter, printer server and a filing and retrieval system were developed. The object oriented operating system and the user interface management system were designed to facilitate the integration of all the software components (editor, formatter, printer server, filing, retrieval, and screen management). A workstation design, the Metaviseur, was adopted to permit the integration of the proposed devices, thereby defining a standard reference architecture. For the integration of software an object oriented operating system was adopted and extended for distribution. The system eased the final integration of the different applications and modularized the services offered by the operating system by basing them on a minimal kernel. Window management, screen and screen management, multiplexing of video images and the integration of these different functionalities are available as services from the operating system. The document handling applications were integrated into the common object oriented document arch itecture offered by the filing and retrieval module. For this a common document architecture based on the office document architecture (ODA) standard was adopted. A first nonintegrated version of the different components has been successfully demonstrated.
For the integration of software an object-oriented operating system was adopted and extended for distribution. The SOMIW Operating System (SOS) eased the final integration of the different applications and modularised the services offered by the operatingsystem by basing them on a minimal kernel. SOS is Unix-compatible. Window management, screen and screen management, multiplexing of video images and the integration of these different functionalities are available as services from the operating system.The document-handling applications were integrated into the common object-oriented document architecture offered by the filing and retrieval module. For this a common document architecture based on the ODA standard was adopted. A first non-integrated version of the different SOMIW components has been successfully demonstrated on several occasions, including the Hannover Fair and the ESPRIT Conference Week. 
Exploitation 
Based on the results of the project, Bull plans to develop its work in 3-D graphics and voice processing; BALZAC, a document editor, and RAPHAEL, a structured graphics editor (both spin-off products from SOMIW) have already been launched. The Metaviseur adopted in the SOMIW project will be used in the design of the DPX 1000, another Bull product. The achievements of the screen hardware subproject (Iselqui) will be used in future projects in Italy. The UIMS know-how acquired (INESC), will be exploited in future developments, and UIMS itself will be used as an application development tool in future ESPRIT projects. The network interface and the audio-video codes (CSELT) will be implemented in future ESPRIT projects. The audio/video multiplexer will be integrated in a VLSI component. The results achieved on the printer server (Sobemap), OCR interface (AEG), and filing and retrieval (Sarin) subprojects will be further developed in either industry or future ESPRIT projects.";;;;;BULL SA;FR;"INESC-INSTITUTO DE ENGENHARIA DE SISTEMAS E COMPUTADORES;SEMA GROUP BELGIUM S.A.;Sarin Telematica SpA;AEG ELECTROCOM GMBH;SCK - C.E.N.;Italtel Telematica SpA;Institut National de Recherche en Informatique et en Automatique - INRIA;Centro Studi e Laboratori Telecomunicazioni SpA";"PT;BE;IT;DE;FR";
8645;1610;COGNISIM;;FP1-ESPRIT 1;;FP1;Cognitive Simulator for User Interface Design;01/01/1985;01/05/1987;;"The objectives of this project were to: 
-provide the Cognitive Design Aid (CDA), a software package incorporating the principles of cognitive psychology that could be used by a designer of a user interface to help assess human-machine cognitive compatibility 
-prepare design guidelines derived during the development of the design aid 
-to assess current trends in interface technology. 

CDA incorporates modules based on principles extracted from cognitive psychology. These modules handle the inputs from designer to CDA. These inputs are a description of the interface and can vary from a general to a detailed level, depending on the stateof development of the design. 
Interfaces which were well tested were used for validating the CDA. Their descriptions were input to the CDA, which provided cognitive compatibility indices. Human error performance was also directly measured from use of the interfaces. Four different indices were found to be strongly predictive of errors and were used in the CDA. The existing CDA is thus potentially highly useful for predicting errors. The final report also discusses possible future extensions and developments. 
The CDA is supplemented with an operational description and a report describing the psychological foundations of the project. 
The Design Guidelines operational description is intended for both designers and human factors specialists who require a comprehensive and accessible set of cognitive psychology design principles. The principles are presented with examples and areas of application in a manner which allows the relevant research to be traced. The design principles include those on which the CDA is based, and those for which automatic assessment by a CDA is not yet possible. 
A report, Trends in Human-Computer Interface Technology, describes those developments, particularly in electronic office systems, that are relevant to cognitive compatibility. This information can be used for further development of the CDA and the next statement of design principles. 
Exploitation 
 The experience gained during the project and presented in the project deliverables will have an impact on both academic and industrial practice. The power of the CDA to predict average user error for the interfaces chosen merits further research. If this is shown to be a general result, it will be of great importance for cognitive psychology and practical user-interface design. 
During the development of the CDA the partners studied topics which will be highly useful to them and others in subsequent projects (for example, methods for interface description and evaluation). The Guidelines and Trends in Technology documents are already in use by the partners in their human factors work and, like all the reports in this project, are publicly available.";;;;;ESPRIT INFORMATION DESK;BE;"Alcatel;Logos Progetti Srl;Medical Research Council (MRC);GEC-Marconi Materials Technology Ltd";"UK;IT";
8429;892;DAIDA;;FP1-ESPRIT 1;;FP1;Advanced Interactive Development of Data-Intensive Applications;28/02/1986;28/02/1990;;"The DAIDA project aimed at the definition and prototype implementation of languages, methods, software tools, and environments to support the interactive development and maintenance of data-intensive information systems. Particular emphasis was placed on integrating all stages of the information systems development life-cycle with each other and with system maintenance. To achieve this goal, a knowledge-based management system (KBMS) perspective was taken as a basis for going beyond expert systems for software development. The evolving results of analysis, design and implementation were each treated as co-operating knowledge bases, rather than being under the control of existing external expert systems. 
The overall aim of the project was to contribute to the definition and implementation of tools for the production of quality software products for data-intensive applications. Behind the chosen approach lay the conviction that the problem of software engineering is not solvable, in general, using current technology, and that the introduction of knowledge-based environments for all stages of the software life-cycle was needed. 
The systems modelling language (SML) tool supports conceptual modelling of large information systems and knowledge bases. It supplies reasoning, inconsistency detection and prototyping capabilities to the user, including full explanation and graphical representation.
A prototype was made available on 08/31/89
The operating environment is as follows :
Hardware: SUN workstations \Operating system: UNIX \ Software: BIM-PROLOG

The project aimed at the definition and prototype implementation of languages, methods, software tools, and environments to support the interactive development and maintenance of data intensive information systems. Particular emphasis was placed on integrating all stages of the information systems development life cycle with each other and with system maintenance. To achieve this goal, a knowledge based management system (KBMS) perspective was taken as a basis for going beyond expert systems for software development. The evolving results of analysis, design and implementation were each treated as cooperating knowledge bases, rather than being under the control of existing external expert systems. Work progressed in parallel in a number of key project areas, including language design, functional analysis of the knowledge based tools, and design of the development support environments. The extensions from conceptual modelling language CML to a systems modelling language (SML) were established, and the implementation begun. A first tool development language (TDL) design was completed, largely satisfying the diverse requirements of compatibility with SML (designing from functional specifications in the context of a world model); with the database programming language (DBPL) (designing from modular relationally oriented database programming); and with Prolog (design into full functional prototypes). Preliminary prototypes of the mappings between the 3 layers mentioned above were demonstrated. The principles, methods, tools, etc, behind the prototyping activity (in Prolog) were also demonstrated. For database structure and transaction design and implementation, an environment for the database programming language DBPL was built. This included syntax oriented components as well as database and transaction design tools. Each level was equipped with knowledge based mapping assistants that support the realization of requirements set by the level above. A global knowledge base manager observed the development process and recorded information about the use of the development environments; this information subsequently facilitated efficient and consistent maintenance of the multilayered system representation.
After a preparatory phase, work progressed in parallel in a number of key project areas, including: 
-language design (SML, TDL) 
-functional analysis of the knowledge-based tools (mapping assistants, global KBMS) 
-design of the DAIDA development support environments (prototyping, user interface questions, architectural integration of tools). 
The main achievements of the project were as follows: 
-The extensions from CML to a Systems Modelling Language were established, and the implementation begun. 
 -A first TDL design was completed, largely satisfying the diverse requirements of compatibility with SML (designing from functional specifications in the context of a world model); with DBPL (designing for modular relationally oriented database programmi ng); and with Prolog (design into full functional prototypes). 
-Preliminary prototypes of the mappings between the three layers mentioned above were demonstrated (May 1988). 
-The principles, methods, tools etc behind the prototyping activity (in Prolog) were also demonstrated (May 1988). 
-For modelling and requirements specification, a System Modeling Language (SML) and a design support environment was developed. These included a SADT-like interface and PROLOG-based prototyping, and theorem-proving tools for validation and verification.-For logical system design, the TAXIS language was redesigned as a pure design language (TDL) with predictive specifications for transactions; the TDL environment included editors, viewing and prototyping. 
-For database structure and transaction design and implementation, an environment for the database programming language DBPL was built. This was to include syntax-oriented components as well as database and transaction design tools. 
Each level was equipped with knowledge-based mapping assistants that support the realisation of requirements set by the level above. A global knowledge-base manager observed the development process and recorded information about the use of the developmentenvironments; this information subsequently facilitated efficient and consistent maintenance of the multi-layered system representation. 
The basis of SML, as well as of the global KBMS, was the Conceptual Modelling Language (CML). The hardware/software environment was based on advanced workstations (Sun-3 and Micro Vax), making intensive use of BIM-PROLOG. 
Progress towards formulating concepts for a uniform design of the SML, TDL, and DBPL environments was substantial, and initial experiments with the existing components to be included were completed. 
Work has been successfully completed in the three areas described. The DAIDA programmers' manual has been released and a DAIDA book prepared for publication. 
Exploitation 
The impact of using the techniques developed in this project could well be to increase the productivity and quality of the software products of the European IT industry. 
The reaction to the DAIDA programmers' manual will provide first evidence of DAIDA's commercial viability. However, this complex set of concepts will require many refinements (mainly syntactical) before being ready for commercial exploitation.";;;;;BIM SA;BE;"UNIVERSITÄT PASSAU;FORTH-RESEARCH CENTER OF CRETE;GROUPE FRANCAIS INFORMATIQUE;Johann-Wolfgang-Goethe-Universität Frankfurt;Scientific Control Systems Informationstechnik Gmbh";"DE;EL;FR";
8656;956;COCOS;;FP1-ESPRIT 1;;FP1;Components for Future Computing Systems;01/01/1986;01/01/1989;;"The main objective of this project was the provision of a set of common tools for building information systems. Hardware and software issues were to be combined in a top-down design. 
At the application level, the user was to be provided with a dynamic environment in which to create and define an application through a man-machine interface. The environment was to include tools for viewing different tasks simultaneously (multi-windowing), for quickly switching between these tasks, and for invoking actions with natural commands such as graphic symbols. 
The middle level was to be a self-contained environment acting as the conduit between the applications and the lowest levels, providing support for programming language interfaces to services and functions commonly provided by operating systems, as well as an underlying homogeneous object model with a fine level of granularity. 
The lowest level was to contain the hardware circuitry that best supported the application language. RISC CPUs and dedicated VLSIs were to be investigated, and network and disc interfaces and memory management studied along with the selected CPU. 
A report on all the relevant technologies involved in the project has been produced. This report covers areas such as hardware, standard central processing unit (CPU) chips, reduced instruction set computer (RISC) chips, internal and external bus architecture, and interconnection schemes in multiprocessor systems, together with software (including operating systems), distributed systems, programming languages, object oriented environments, and the man machine interface.
After one year of work, a report on all the relevant technologies that were to be involved in the project was produced. This report covers areas such as hardware, standard CPU chips, RISC chips, internal and external bus architecture, and interconnection schemes in multiprocessor systems, together with software (including operating systems), distributed systems, programming languages, object-oriented environments, and the man-machine interface. 
 A new area of research emerged within the framework of the project: in order to integrate many of the concepts studied, several partners have decided to focus on tasks relating to multimedia workstations. These tasks range from studying the human factors of the new multimedia input and output devices, to the specification of an appropriate architecture using second-generation RISC chips. 
Exploitation 
With the results achieved: 
-Bull plans to further develop its work in 3-D graphics and voice processing. 
-Olivetti's and Acorn's developments in hardware architecture have helped to define the next generation of workstation CPUs and peripheral subsystems. 
-ICL's work on software architectures is the basis from which the whole MULTIWORKS interactive environment has developed (see projects 2105 and 2713).";;;;;BULL SA;FR;"Ingegneria C. Olivetti and C. SpA;Siemens Nixdorf Informationssysteme AG;Thomson Microelectronics Srl (SGS);Institut National de Recherche en Informatique et en Automatique - INRIA;International Computers Ltd (ICL)";"IT;DE;FR;UK";
8448;1517;FOR-ME-TOO;;FP1-ESPRIT 1;;FP1;Formalisms, Methods and Tools;01/02/1985;01/06/1987;;"The goal of FOR-ME-TOO project was to define, implement and experiment with a technology for the systematic development, verification and validation of software systems, based on the principle of reusability of software components. The software development process, conceived of as a process with special attention given to the reuse of pre-fabricated components and to the structuring of the system to be developed into usable components as building blocks, was characterised as a combination of 'top down' and 'bottom up' approaches. 
Reusability of descriptions and analysis of the sequential aspects of software systems was based on a specification language defined by using some of the primitives of ASL (a kernel specification language with loose semantics). 
Reusability of descriptions and analysis of the concurrent aspects of software systems was based on various classes of Petri-nets, ranging from condition-event to high-level and stochastic nets. 
An environment of support tools was constructed to assist developers in following a discipline for the stepwise derivation and development of software components, for the retrieval of components and for the composition of software components. 
The project was to define, implement and experiment with a technology for the systematic development, verification and validation of software systems, based on the principle of reusability of software components. The software development process, conceived of as a process with special attention given to the reuse of prefabricated components and to the structuring of the system to be developed into usable components as building blocks, was characterized as a combination of 'top down' and 'bottom up' approaches. Reusability of descriptions and analysis of the sequential aspects of software systems was based on a specification language defined by using some of the primitives of ASL, a kernal specification language with loose semantics. Reusability of descriptions and analysis of the concurrent aspects of software systems was based on various classes of Petri-nets, ranging from condition-event to high-level and stochastic nets. An environment of support tools was constructed to assist developers in following a discipline for the stepwise derivation and development of software components, for the retrieval of components and for the composition of software components. Language de programmation generique (LPG) specification and programming language was studied. A taxonomy of reusable components and requirements for a library of reusable components were determined.
Work was undertaken in the following areas: 
-study of the LPG (Langage de Programmation Gnrique) specification and programming language 
-taxonomy of reusable components and requirements for a library of reusable components 
-investigation of Petri-nets and algebraic techniques. 
Exploitation 
Through its extensive use of case studies, the FOR-ME-TOO project should improve the general understanding of components reusability within a project development task.";;;;;Siemens Nixdorf Informationssysteme AG;DE;"SYSECA SA;Centro Studi e Laboratori Telecomunicazioni SpA;Bull SA";"FR;IT";
8658;1628;DOMESDAY;;FP1-ESPRIT 1;;FP1;An Intelligent General Public Data, Voice and Picture Storage Retrieval System;18/12/1985;18/04/1988;;"The DOMESDAY project undertook a range of research and development activities in the field of intelligent data, voice and image storage and retrieval systems. It covered the development of a compact electronic storage system capable of providing rapid random access to very large volumes of multimedia information, such as maps, photographs and other analogue-stored pictures held with digitally held text and data. Moving video and sound were also incorporated in the database. Particular emphasis was given to a very user-friendly interface which implemented knowledge-engineering techniques. The project aimed at improving the acceptability of these systems and making them complementary to current systems through prototyping LaserVision technology combined with new advanced user interfaces based on high-level expert systems. The design of the system concentrated on widely available low-cost workstations. s. 

A series of major demonstrator projects were completed using the LaserVision ROM system in the field of multimedia image-based storage and retrieval systems for DOMESDAY, ECODISC, VOLCANOES and EUROFLORE. 
The analysis of hardware architecture based on the LaserVision ROM for a future system was supported by the Imageur Documentaire, in which the key requirements were for an interactive and user-friendly image databank. 
Exploitation 
The general and public usage of large-scale, multimedia databases was greatly stimulated. In the case of the DOMESDAY system, more than one thousand copies are now in use, mainly in the UK. 
 The development of a LaserVision optical disc player ran in parallel with the ROM disc development. Two additional authoring packages have been developed, Domesday Display and DataMerge. These are both floppy disc based add-ons. Domesday Display consists of two discs, 'Presenter' and 'Captions'. 'Presenter' is like an electronic notebook, and allows the user to store, in any sequence, the results of their searches for easy recall and presentation. 'Captions' allows the user to produce a storybook of up to200 images from the vast pictorial resources on LaserVision discs. The original system consisted of a BBC micro and a LaserVision player. Later developments in the project resulted in a PC-compatible system in order to align with standards in Europe.In addition, studies of image databanks and of the pertinent market sectors were conducted.";;;;;ESPRIT INFORMATION DESK;BE;"PHILIPS DUPONT OPTICAL;CRIN;Societe Europeenne de Propulsion SA (SEP);BUREAU VAN DIJK;British Broadcasting Corporation (BBC);Logica Ltd";"NL;FR;BE;UK";
8539;1553;SOI;;FP1-ESPRIT 1;;FP1;Silicon-on-Insulator  Materials and Processing: Towards 3-D Integration;01/01/1985;01/01/1988;;"The objective was to investigate new silicon technologies suitable for 3-D integration in order to achieve higher density integration, higher speed of operation and multifunctional signal processing. Three main technological steps were explored: 
-the growth of SOI active layers with electronic properties needed for the realisation of high quality devices and circuits 
-the stacking of two active levels in a way that avoids any degradation of already built devices 
-single-level SOI processing for the fabrication of individual components and for their connection, and the development of a process incorporating two active layers. 
A final demonstration was presented during the ESPRIT Conference in November 1988. 
The objective was to investigate new silicon technologies suitable for 3-dimensional integration in order to achieve higher density integration, higher speed of operation and multifunctional signal processing. 3 main technological steps were explored:
the growth of silicon on insulator (SOI) active layers with electronic properties needed for the realisation of high quality devices and circuits;
the stacking for 2 active levels in a way that avoids any degradation of already built devices;
single level SOI processing for the fabrication of individual components and for their connection, and the development of a process incorporating 2 active layers.

High quality SOI devices have been produced, and fine geometry bulk complementary metal oxide semiconductor (CMOS) devices which had undergone SOI recrystallisation were found to be essentially unaffected by the procees. These device results confirm the viability of the demonstrator production technique. Full demonstrator device batches were processed. A working chip, integrated in a prototype board and activating a stepper motor, was shown.

The chosen demonstrator is a first step towards the integration of very different functions on the same chip in a way which allows, simultaneously, the independent optimisation of each function and their complete dielectric isolation, thus opening the route for complex 3-dimensional system integration on chips, allowing more reliability and better performance.
The first two years' experimental work demonstrated the capacity to fabricate monocrystalline SOI layers compatible with the underlying bulk silicon layers and with limited influence of the first device level on the SOI characteristics. Specifically:-industrial E-beam equipment was built for SOI preparation, and two different research laser systems were optimised 
-unified test structures and characterisation methods were adopted for quantitative comparison of the crystallisation techniques of E-beam, laser zone melting and CVD epitaxy. 
In parallel, design options and product application studies showed two possible choices for 3-D circuits: 
-conventional applications (high-density high-performance VLSI) 
-system applications (specialised superimposed layers and performance-independence of different functions). 
One major conclusion of the application study was that 3-D SOI CMOS for VLSI is unlikely to provide sufficient benefit, in terms of packing density and circuit speed, to compete with single-level technologies using bulk or SOI substrates. In contrast, thedevelopment of silicon technologies, where devices of different types (eg CMOS, bipolar and power transistors) can be fabricated on a single chip, was demonstrated as an important application area for 3-DSOI. Such mixed technologies are difficult to produce in a single level of silicon, as the requirements of the different device types often conflict. However, using a 3-D SOI approach, the development of a mixed technology with individual optimisation of the separate device levels can be envisaged.In the light of these findings the orientation of the project and the end of the year 3demonstrator was focused on the development of a 'smart power' technology using a 3micron CMOS SOI level to control medium current/voltage (1 A/50 V) LDMOS bulk transistors. The particular application considered was a stepper motor controller using a gate array design approach for both the CMOS and LDMOS levels. A 'mezzanine' layout was adopted whereby the SOI devices are displaced laterally from the underlying bulk devices. 
 On the materials development side, significant improvements in the SOI starting material, especially the use of selective epitaxial growth of silicon in the seed windows, together with refinements of the laser and electron beam recrystallisation systems, have allowed the production of device-grade SOI compatible with the requirements of the end of project demonstrator. High-quality SOI devices have been produced, and fine geometry bulk CMOS devices which had undergone SOI recrystallisation under similar c onditions were found to be essentially unaffected by the process. These device results confirm the viability of the demonstrator production technique. Full demonstrator device batches were processed in December1987. A working chip, integrated in a protot ype board and activating a stepper motor, was shown during the ESPRIT Conference in November1988. 
Exploitation 
The chosen demonstrator is a first step towards the integration of very different functions on the same chip in a way which allows, simultaneously, the independent optimisation of each function and their complete dielectric isolation, thus opening the route for complex 3-D system integration on chips, allowing more reliability and better performance.";;;;;SGS Thomson Microelectronics SA;FR;"Commissariat à l'Energie Atomique (CEA);NATIONAL MICROELECTRONICS RESEARCH CENTRE;THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE;GEC-Marconi Materials Technology Ltd;Centre National d'Études des Télécommunications (CNET)";"FR;IE;UK";
8438;940;DMA;;FP1-ESPRIT 1;;FP1;Depth and Motion Analysis;01/06/1986;01/06/1991;;"The objective of DMA was to develop a vision system integrating passive information from stereo and motion analysis for industrial robotics and passive navigation, with hardware realisation of real-time vision modules. The system will be integrated in twodemonstrators: 
-a mobile vehicle to move in different environments, avoiding obstacles and making visual maps of the scene. 
-a manipulating arm for industrial robots for object manipulation and inspection, and for tool assembly. 
The project was organised into different tasks covering passive stereo vision, motion analysis, integration of stereo and motion, the computation and representation of 3-D shapes and motion, and hardware implementation of demonstrators in the context of amobile vehicle and a manipulating arm. 
The objective was to develop a vision system integrating passive information from stereo and motion analysis for industrial robotics and passive navigation, with hardware realization of real time vision modules. The project was organized into different tasks covering passive stereo vision, motion analysis, integration of stereo and motion, the computation and representation of 3-dimensional shapes and motion, and hardware implementation of demonstrators in the context of a mobile vehicle and a manipulating arm. During the methodological period of the project, 3 strongly interrelated lines of research were followed: a study of algorithms for passive stereo and motion analysis, a hardware feasibility study, and a specification of the demonstrators (mobile vehicle and robot manipulator). In particular, a 3 camera approach was selected for stereometric purposes. A concentration on real time capabilities led to the definition and realization of a hardware architecture capable of solving stereo and motion problems at a speed suitable for application in both robot arm manipulation and vehicle guidance fields. During the realization phase a set of hardware modules was developed to implement the algorithmic chain. The project has provided systems that recognise objects well enough for a robotic inspection to be made both from mobile and stationary platforms and for the object positions to be estimated within sufficient accuracy for them to be grasped by a robot hand.
During the methodological period of the project, three strongly interrelated lines of research were followed: a study of algorithms for passive stereo and motion analysis, a hardware feasibility study, and a specification of the demonstrators (mobile vehicle and robot manipulator). In particular, a three-camera approach was selected for stereometric purposes. 
Besides the need to look for a methodological solution to this class of problems, the aim of getting results as close as possible to industrial exploitation brought a remarkable concentration on real-time capabilities; this led to the definition and realisation of a hardware architecture capable of solving stereo and motion problems at a speed suitable for application in both robot-arm manipulation and vehicle guidance fields. 
During the realisation phase a set of hardware modules was developed to implement the algorithmic chain. The modules are now available and their integration is at an advanced stage of progress. 
DMA has provided systems that recognise objects well enough for a robotic inspection to be made both from mobile and stationary platforms and for the object positions to be estimated within sufficient accuracy for them to be grasped by a robot hand. 
Exploitation 
It is apparent that despite the remarkable advances achieved in understanding and implementing visual processes, vision systems are not as widely used in practice as was foreseen a few years ago. 
This is mainly because of the computing flexibility required by vision processes and the unavailability of hardware machines capable of implementing them reliably in real-time. 
DMA tried to find answers to these problems or, at least, to the more computation-intensive phases of a three-dimensional vision process, namely the early vision stages. 
Three different kinds of demonstrations were built in the last phase of the project: 
-mobile vehicle 
-3-D object recognition for robot arm manipulation 
-automatic 3-D model reconstruction. 
All industrial partners in the project are active in markets where intelligent sensors in general, and artificial vision in particular, are considered as strategic (all these companies have been deeply involved in vision research for many years). Examples are ELSAG's applications in robotics and on measuring machines, space applications by MATRA ESPACE, and robot arm manipulation for ITMI. Besides these particular applications, the DMA architecture can be used in much more extended fields where data fusio n from multiple or time-sequence images has to be applied.";;;;;Elsag Bailey SpA;IT;"NOESIS;MATRA SA;THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF CAMBRIDGE;ITMI;Institut National de Recherche en Informatique et en Automatique - INRIA;Università degli Studi di Genova;GEC-Marconi Materials Technology Ltd";"FR;UK;IT";
8406;432;METEOR;;FP1-ESPRIT 1;;FP1;An Integrated Formal Approach to Industrial Software Development;01/10/1984;01/10/1989;;"The objective of METEOR was to develop an integrated formal approach to industrial software development, particularly for the telecommunications industry. The development process was studied and modelled by individualising building components for analysing existing methods and by developing new methods of software development. 
 A language for requirement engineering was defined, with a semantics covering temporal aspects. Algebraic methods were adopted for specifying passive and active objects (process algebras and the algebraic specification language, ASL). Denotational models of concurrent systems were to provide a basis for defining a calculus in which various properties of such systems could be proved. 
In particular, the project aimed to integrate the object-based language paradigm, the algebraic approach to software specification, the relational approach, and so-called formal heuristics. 
The impact on management and metrics of the application of formal methods in software development was considered. Industrial take-up, especially in the area of constructing real-time distributed systems, was provided for by the planned construction of prototype environments. 
The objective of the project was to develop an integrated formal approach to industrial software development, particularly for the telecommunications industry. The development process was studied and modelled by individualizing building components for analysing existing methods and by developing new methods of software development. A language for requirement engineering was defined, with semantics covering temporal aspects. Algebraic methods were adopted for specifying passive and active objects (process algebras and the algebraic specification language, ASL). Denotational models of concurrent systems provided a basis for defining a calculus in which various properties of such systems could be proved. The impact on management and metrics of the application of formal methods in software development was considered. After a pilot phase devoted mainly to an extensive survey of existing methods, the project made advances in several fields. Industrial achievements include the development of a requirement engineering methodology based on an extension of the entity relationship model ERAE, and the definition of a powerful formal design language, COLD. In addition, the relational algebra, ALGRES, has been extended, and the RAP rapid prototyping system created. Progress was also made in the formal specification of concurrency in algebra of communicating process (ACP). A software engineering toolbase was developed through the establishment of a generic environment. A telecommunication transfer node was taken as a case study to prove the feasibility of the transitions from the ERAE requirement to the RAP prototype implementation.
After a pilot phase devoted mainly to an extensive survey of existing methods, METEOR made advances in several fields. Industrial achievements include the development of a requirement engineering methodology based on an extension of the entity-relationship model ERAE, and the definition of a powerful formal design language, COLD. Both these tools are currently under field test in real-life software product development environments. In addition, the relational algebra, ALGRES, has been extended, and the RAP rapid prototyping system created. 
Progress was also made in the formal specification of concurrency in ACP (Algebra of Communicating Process), an extension of Hoare's and Milner's work. 
A software engineering toolbase was developed through the establishment of a generic environment. This facilitated the work of the project teams and provided a setting for the investigation of the various formalisms. 
The different facets of METEOR, which addressed most of the fields in software technology, were presented in a three-day workshop. This supported the processes of technology integration and transfer. 
A telecommunication transfer node was taken as a case study to prove the feasibility of the transitions from the ERAE requirement to the RAP prototype implementation through the intermediate SFP stage of the specification. 
Exploitation 
Some preliminary results have already been applied by one of the partners for a customer. Prototypes and the requirement engineering methodology, ERAE, and the design language, COLD, are both currently in field test in real-life production environments.In the universities, the RAP rapid prototyping system is being taught at the University of Passau, and the PLUSS algebraic specification language developed by Orsay University is being used by LRI and CGE. The various formalisms, each addressing a different segment of the software development activity, are being investigated in the IDEAS environment. TXT have exploited ALGRES through the SUN catalogue of SW products. Further industrial and academic installations are being evaluated.";;;;;SEMA GROUP BELGIUM;BE;"CWI-CENTRUM VOOR WISKUNDE & INFORMATICA;UNIVERSITÄT PASSAU;Alcatel Alsthom Recherche;TXT Ingegneria Informatica SpA;COPS (EUROPE) LTD;PHILIPS SA;ATT TELECOMMUNICATION BEDR;Université de Paris XI (Université Paris-Sud);Philips GmbH";"NL;DE;FR;IT;IE;BE";
8641;1607;COMANDOS-1;;FP1-ESPRIT 1;;FP1;Construction and Management of Distributed Office Systems;01/03/1986;01/03/1991;;"The primary objective of COMANDOS was the creation of a flexible, reliable and easy-to-use environment for the development and management of distributed applications in the office. In order to create this type of environment a range of tools had to be designed and implemented. These can be functionally divided into tools supporting: 
-the development of distributed applications 
-the execution of distributed applications 
-the user's activities. 
An important objective of the project was to combine and advance the state of the art of different technologies such as distributed databases, languages, software technology and communications into innovative and generalised tools for different application environments. The subgoals were to: 
-define an architecture for workable distributed office systems 
-implement a low-level kernel shell to provide the infrastructure for integrating a number of system services 
-implement linguistic object-oriented support to ensure widespread acceptance of the shell 
-implement a multi-database system 
-implement a multifile server system with a high degree of integration between application sites. 
ELENA is a complete office automation system that follows a modular architecture approach based on INTEL 80286 technology. It has an ETHERNET connection. All the office automation software was written for the Portuguese language but it can be reconfigured.

COMANDOS, on which the administration, operation and network management of open distributed information systems (ADONIS) is based, is directed to the design and implementation of a flexible, reliable and easy to use environment for the development and use of distributed open systems. It comprises a set of tools for the management and administration of distributed environments. ADONIS will prove, whether the COMANDOS approach provides the urgently requested tools and methods for the management of open distributed systems in an actual, Europe wide company environment. This comprises porting and adaptation of selected COMANDOS tools and facilities to the chosen application field and its particular demands.

The objective was the creation of a flexible, reliable and easy to use environment for the development and management of distributed applications in the office. In order to create this type of environment a range of tools had to be designed and implemented. These can be functionally divided into tools supporting the development of distributed applications, the execution of distributed applications, and the user's activities. It was necessary to define an architecture for workable distributed office systems; implement a low level kernel shell to provide the infrastructure for integrating a number of system services; implement linguistic object oriented support to ensure widespread acceptance of the shell; implement a multidatabase system; and to implement a multifile server system with a highdegree of integration between application sites. The global architecture was established using the object oriented approach. The architecture encompasses the operating system and the data management systems as well as an integration approach for preexisting applications. The functional specification of kernel and system services was also established and interfaces and language requirements defined. A prototype was implemented and consolidated, and a prototype of the overall platform delivered.
The global architecture was established using the object-oriented approach. The architecture encompasses the operating system and the data management systems as well as an integration approach for pre-existing applications (the COMANDOS Integration System(CIS)). The functional specification of kernel and system services was also established and interfaces and language requirements defined. A prototype was implemented and consolidated, and a prototype of the overall platform delivered as the final resultof the project. 
Exploitation 
 Short-term exploitation of the results of COMANDOS includes the building of software products and services based on COMANDOS workpackages (performance-modelling tool, event-management logger, and system observation facilities), as well as the acquisition and exploitation of the object-oriented technology for the design of a distributed directory service, a hypermedia system, and document management facilities. In the longer term, the experience and the results of this project have formed the basis of a second development phase aiming to provide a pre-industrial version of the COMANDOS platform (project 2071, COMANDOS-2).";;;;;Ingegneria C. Olivetti and C. SpA;IT;"Siemens Nixdorf Informationssysteme AG;TRINITY COLLEGE DUBLIN;INESC-INSTITUTO DE ENGENHARIA DE SISTEMAS E COMPUTADORES;Institut National Polytechnique de Grenoble;Applied Research Group SpA;NATIONAL RESEARCH COUNCIL OF ITALY;Fraunhofer-Gesellschaft zur Förderungder Angewandten Forschung e.V.;International Computers Ltd (ICL);Bull SA;Universität Stuttgart";"DE;IE;PT;FR;IT;UK";
8422;1501;QUIC;;FP1-ESPRIT 1;;FP1;Design and Experimentation of a KBS Development Tool Kit for Real-Time Process Control Applications;01/03/1986;01/03/1990;;"The aim of the QUIC project was to design, implement and validate a prototype development environment for knowledge-based system applications in the area of industrial process and plant automation. 
The QUIC environment conforms to the paradigm of a tool-kit, in that it comprises a design methodology and a set of task specific tools. The tool-kit approach allows the user to select the tools and configure an application KBS to meet the requirements of the problem at hand. With respect to other tools available on the market, the QUIC tool-kit offers a higher level working environment, suitable for specific domains. The initial objective of addressing on-line real-time applications has been relaxed to a ddress areas where timing issues exist but are less critical. 
In the first phase (2.5 years), the requirements of a basic set of tools, called the kernel tool-kit were identified, and the tool-kit was designed, developed and validated. The design and the construction of the kernel tool-kit was supported in a very concrete way by the design and the experimentation of three demonstrator applications in the area of process monitoring, diagnosis, and control. In the second phase (1.5 years) the results of the experimentation on the demonstrators and of the toolkit validation were assessed, the conclusions were used in a redesign of the toolkit and the range of application was extended. 
The aim of the project was to design, implement and validate a prototype development environment for knowledge based system applications in the area of industrial process and plant automation. The environment conforms to the paradigm of a toolkit, in that it comprises a design methodology and a set of task specific tools. The toolkit approach allows the user to select the tools and configure an application knowledge based system (KBS) to meet the requirements of the problem at hand. With respect to other tools available on the market, the toolkit offers a higher level working environment, suitable for specific domains. The initial objective of addressing online real time applications has been relaxed to address areas where timing issues exist but are less critical. In the first phase, the requirements of a basic set of tools, called the kernel toolkit, were identified, and the toolkit was designed, developed and validated. The design and the construction of the kernel toolkit was supported by the design and the experimentation of three demonstrator applications in the area of process monitoring, diagnosis, and control. In the second phase the results of the experimentation on the demonstrators and of the toolkit validation were assessed, the conclusions were used in a redesign of the toolkit and the range of application was extended. The project produced a complete toolkit and a methodology that should allow the partners to implement KBS techniques in a wide range of large scale industrial applications. The toolkit contains a facility for qualitative simulation, a component based language, a rule based interpreter using fuzzy logic, a production rule system, and a high level procedural language in the form of event graphs.
The project produced a complete tool-kit and a methodology that should allow the partners to implement KBS techniques in a wide range of large-scale industrial applications. 
In summary, the QUIC tool-kit contains a facility for qualitative simulation, a component-based language, a rule-based interpreter using fuzzy logic, a production rule system, and a high-level procedural language in the form of event graphs. 
These facilities have been validated in the following three demonstrator applications: 
-for the diagnosis of a steam condenser of a thermal power plant, by Ansaldo and CISE 
-for supporting operators in the control of the attitude of a geostationary telecommunications satellite, and in the diagnosis of failures in a satellite power supply by Aerospatiale and Framentec 
-for the control of a cement manufacturing plant, by F.L.Smidth, CAP Sogeti Innovation and Heriot-Watt University. 
Exploitation 
The QUIC project was mainly viewed as a way of developing and reviewing a technology, in terms of both methodology and tools. Two of the demonstrator projects have already spun off exploitation projects by the partners concerned. 
The QUIC tool-kit provides a set of KBS tools for automating such tasks as monitoring, fault diagnosis, control, simulation and training. It has now been completed and will be used in the commercial development of process control applications.";;;;;Centro Informazioni Studi ed Esperienze SpA;IT;"Framentec SA;SNIAS;F L SMIDTH;CAP SOGETI LOGICIEL SA;Ansaldo Impianti;Heriot-Watt University";"FR;DK;IT;UK";
8560;962;EVEREST;;FP1-ESPRIT 1;;FP1;Three-Dimensional Algorithms for Robust and Efficient Semiconductor Simulator;10/04/1986;10/04/1990;;"The numerical analysis and prediction of the detailed behaviour of semiconductor devices is an important step in the development of a new process. With the advent of submicron feature sizes, this analysis is becoming increasingly difficult. For certain c alculations one-dimensional or two-dimensional analysis is no longer sufficiently accurate. 3-D analysis is only just becoming available inside certain major industries and is prohibitively expensive in computing time. 
The numerical analysis and prediction of the detailed behaviour of semiconductor devices is an important step in the development of a new process. With the advent of submicron feature sizes, this analysis is becoming increasingly difficult. For certain calculations one-dimensional or 2-dimensional analysis is no longer sufficiently accurate. 3-dimensional analysis is only just becoming available inside certain major industries and is prohibitively expensive in computing time.

The main achievement of this project was to develop, for 3-dimensional devices, a set of fully testesd algorithms, initially for steady state analysis and later for transient and small siganl loading conditions. The interaction with the temperature of the crystal lattice was also taken into account. This implied crossing new research frontiers in nonlinear numerical analysis techniques to solve the problem reliably and within reasonable computing costs. As part of the drive to reduce computing costs, the applicability of computers with advanced architectures was investigated.
The main achievement of this project was to develop, for 3D devices, a set of fully tested algorithms, initially for steadystate analysis and later for transient and small signal loading conditions. The interaction with the temperature of the crystal la ttice was also been taken into account. This implied crossing new research frontiers in nonlinear numerical analysis techniques to solve the problem reliably and within reasonable computing costs. As part of the drive to reduce computing costs, the appli cability of computers with advanced architectures was investigated. Following validation against measurements of real devices, the successful algorithms are being incorporated in computer systems in the industrial partners and in a common project researchcode. 
On the basis of the first year's work, a reappraisal of priorities led to an effort to augment the work-package aiming to produce the project research code. The definition of the plan for this work-package was greatly strengthened. This work culminated inthe delivery of the first release of the code for the solution of the initial target of the offstate 3D problem, demonstrated at the project review in December1987, with further enhancements shown in 1988. The validity of the results were demonstratedusing an agreed set of benchmarks in 1989. 
Fully transient 3D analysis at a reasonable computing cost is an ambitious goal. Even 2D solutions of this problem are only to be found inside large semiconductor companies (predominantly US and Japanese) at present, and it has been claimed that even these programs cannot solve all of the device problems in this category. The availability of such an analysis tool in Europe in 1990 puts Europe in a strongly competitive situation. In addition to the industrial use of the results by the companies in the project, the research project code will be made available to other European research organisations for research purposes.";;;;;Rutherford Appleton Laboratory (RAL);UK;"Swansea University;IMEC VZW;TRINITY COLLEGE DUBLIN;NATIONAL MICROELECTRONICS RESEARCH CENTRE;NEDERLANDSE PHILIPS BEDRIJVEN BV;Thomson Microelectronics Srl (SGS);ANALOG DEVICES BV;Università degli Studi di Bologna;GEC-Marconi Materials Technology Ltd";"UK;BE;IE;NL;IT";
8428;599;EMG;;FP1-ESPRIT 1;;FP1;Knowledge-Based Assistant for Electromyography;01/12/1984;01/02/1989;;"The aim of the EMG project was to develop a knowledge-based assistant to support physicians in all stages of an electromyographical (EMG) examination of patients with neurological diseases. 
The objective was to produce a system sufficiently robust to withstand clinical trials in a neurophysiological laboratory. Particular attention was given to involving users in the definition of requirements and in system acceptance testing, and to bringing medical knowledge-based systems to a fully functional state. 
The aim of the project was to develop a knowledge based assistant to support physicians in all stages of an electromyographical (EMG) examination of patients with neurological diseases. The objective was to produce a system sufficiently robust to withstand clinical trials in a neurophysiological laboratory. Particular attention was given to involving users in the definition of requirements and in system acceptance testing, and to bringing medical knowledge based systems to a fully functional state. The prototype EMG expert system supports the diagnostician in the analysis of EMG signals and advises on the test procedures to be performed. It includes a report generator, and contains a database of case studies. It incorporates a casual probabilistic network model to allow a unified approach to planning, diagnosis, explanation and reporting. The following major features were developed subsequently: robust inference systems; new ways of handling uncertainty by probabilistic methods; and methodologies of general applicability in knowledge representation, blackboard architecture, and user interface specification.
The prototype EMG expert system constructed in Phase I supports the diagnostician in the analysis of EMG signals and advises on the test procedures to be performed. It includes a report generator, and contains a database of case studies. It incorporates acausal-probabilistic network model to allow a unified approach to planning, diagnosis, explanation and reporting. 
Phase II saw a substantial improvement in real-time performance and the development of the following major features: 
-robust inference systems 
-new ways of handling uncertainty by probabilistic methods 
-methodologies of general applicability in knowledge representation, blackboard architecture, and user-interface specification. 
Exploitation 
The integrated EMG knowledge-based assistant will broaden the scope of the use of electrophysiological techniques. 
An expert system shell based on causal-probabilistic reasoning, HUGIN, has been developed and is now available on the market.";;;;;AXION A/S;DK;"Institute of Neurology;JUDEX DATASYSTEMER A/S;RESEARCH AND DEVELOPMENT INSTITUTE (NUC);Logica Ltd";"UK;DK";
8421;1499;ESTEAM;;FP1-ESPRIT 1;;FP1;An Architecture for Interactive Problem Solving by Cooperating Data and Knowledge Bases;01/01/1985;01/01/1990;;"The objective of ESTEAM was to design and implement an expert system architecture for advice-giving systems. 
The function of an automatic adviser is to assist an inquirer with a problem. The problem may be ill-defined and the number of potential solutions may be large. In this situation, the adviser can help the inquirer to provide a statement of his or her goals and a description of the problem sufficient for the generation, by the machine, of trial solutions for consideration. 
The objective of the project was to design and implement an expert system architecture for advice-giving systems. The function of an automatic adviser is to assist and inquirer with a problem. The problem may be ill defined and the number of potential solutions may be large. In this situation, the adviser can help the inquirer to provide a statement of his or her goals and a description of the problem sufficient for the generation, by the machine, of trial solutions for consideration. The architecture was divided into 2 complementary strands: for designing and implementing architectures for heterogeneous distributed advice-giving systems; and methods and tools to model knowledge in advice-giving expert systems. These were a dialogue manager, a problem solver, a cooperative answering agent and a database agent. The main computational problem tackled by the combined cooperative action of the agents was how to manage those complexities of advice-giving that require the integration of knowledge and data from a variety of sources. This was solved by controlling the cooperative functioning of several sources of knowledge by using different representational schemes interpreted by different inference engines. Each knowledge source was considered to be an independent agent, only communicating with other such agents via messages encoding queries and answers. In addition to architectural issues, the dialogue system was provided with the capability for modelling lines of thought of the user, as perceived through the person-machine interaction. A simplified financial investment adviser was constructed to provide a limited example suitable for an application study. Knowledge acquisition was completed, and the capability of pairs of actors to cooperate was tested by processing problems in this domain. A first demonstration showed the integration of the problem solver, the dialogue manager and the database agents. A second demonstration illustrated the integration of the cooperativ e answering agent, the dialogue manager, the rule base management and the database.
The architecture was divided into two complementary strands: 
 -The AGES architecture, dealing with concepts and tools for designing and implementing architectures for heterogeneous distributed advice-giving systems. This architecture has been ported from its development environment (TI Explorer) to a Sun/Unix envir onment. 
-Methods and tools to model knowledge in advice-giving expert systems. These 'cooperative agents', which each take control in turn, were a dialogue manager, a problem solver, a cooperative answering agent and a database agent (to ORACLE). 
 The main computational problem tackled by the combined cooperative action of the agents was how to manage those complexities of advice-giving that require the integration of knowledge and data from a variety of sources. This was solved by controlling the  cooperative functioning of several sources of knowledge by using different representational schemes interpreted by different inference engines. Each knowledge source was considered to be an independent agent, only communicating with other such agents via messages encoding queries and answers. 
In addition to architectural issues, the dialogue system was provided with the capability for modelling lines of thought of the user, as perceived through the person-machine interaction. 
A simplified financial investment adviser was constructed to provide a limited example suitable for an application study. Knowledge acquisition was completed, and the capability of pairs of actors to cooperate was tested by processing problems in this domain. 
 A first demonstration showed the integration of the problem solver, the dialogue manager and the database agents. A second demonstration illustrated the integration of the cooperative answering agent, the dialogue manager, the rule-base management and th e database. 
Exploitation 
The major contribution of ESTEAM was the provision of a prototype architecture for heterogeneous distributed advice-giving systems. The results will be exploited internally by the partners for the development of specific applications.";;;;;CAP GEMINI INNOVATION;FR;"PHILIPS SA;Centro Studi e Laboratori Telecomunicazioni SpA;Politecnico di Milano;Office National d'Études et de Recherches Aérospatiales (ONERA)";"BE;IT;FR";
8483;1560;SKIDS;;FP1-ESPRIT 1;;FP1;Signal and Knowledge Integration with Decisional Control for Multi-Sensory Systems;01/06/1987;01/06/1989;;"Thepurpose of the SKIDS project is to provide a basic generic approach, for both software and hardware, in the area of integration of sensory information and knowledge. 'Sensory information' is understood as information coming from an outside, physical,real world, and 'knowledge' as high-level symbolic representations and models of the external world and of the system's features and abilities. Such models are dynamically updated and partially acquired through learning. 
The ultimate goal of the project is a perception machine represented by the SKIDS demonstrator prototype and realising: 
-a unified perception of the observed world 
-real-time reasoning, planning and adaptation of the whole software and hardware configuration to the actual observations strategy. 
The purpose of the project was to provide a basic generic approach, for both software and hardware, in the area of integration of sensory information and knowledge. Sensory information is understood as information coming from an outside, physical, real world, and knowledge as high level symbolic representations and models of the external world and of the system's features and abilities. Such models are dynamically updated and partially acquired through learning. The demonstration environment where the prototype perception machine will run has been specified, in particular the sensor configuration. The functional architecture has been defined, and consists of 4 parts: the MMI the sensory chain, the interpretative chain, and the control and decisional chain. The last 2 parts are essential: the interpretation processs, which is data driven (continuous surveillance task) or goal driven (object recognition upon request) is segmented into elementary tasks which are driven by the knowledge based control system (KBCS). The KBCS selects the optimal interpretative path and manages the global resources allocation. The basic perception tasks that have been identified fall into 5 categories: detection, characterization, localization, tracking and identification. The sensors consist of fixed and pan and tilt cameras, microphones, optical barriers, a laser range finder, an ultrasonic belt, and an odometer, all mounted on a mobile platform. The hardware has already been specified and consists of a set of nodes linked via a ring bus. Basic tools for the software architecture have already been identified: they include inference engines and a rule compiler for achieving real time performance of the perception system. The objective is to achieve response time of a few seconds for indoors scene surveillance. The fusion of information from multiple cameras has been demonstrated successfully for single event tracking. Various tasks of detection, localization and recognition demonstrated t he soundness of the vision node architecture.
The demonstration environment where the prototype perception machine will run has been specified, in particular the sensor configuration. The functional architecture has been defined, and consists of four parts: 
-the MMI 
-the sensory chain 
-the interpretative chain 
-the control and decisional chain. 
The last two parts are essential: the interpretation process, which is data-driven (continuous surveillance task) or goal-driven (object recognition upon request) is segmented into elementary tasks which are driven by the Knowledge-Based Control System (KBCS). The KBCS selects the optimal interpretative path and manages the global resources allocation. The basic perception tasks that have been identified fall into five categories: detection, characterisation, localisation, tracking and identification.The sensors consist of fixed and pan-and-tilt cameras, microphones, optical barriers, and a laser range finder, an ultrasonic belt, and an odometer, all mounted on a mobile platform. The hardware has already been specified and consists of a set of nodes (VME clusters) linked via a Capitan ring bus. Basic tools for the software architecture have already been identified: they include inference engines and a rule compiler (KHEOPS) for achieving real-time performance of the perception system. The objective isto ach eve response time of a few seconds for indoors scene surveillance. 
The fusion of information from multiple cameras has been demonstrated successfully for single event tracking. Various tasks of detection, localisation and recognition demonstrated the soundness of the vision node architecture, which consists of a Datacubesystem connected to a transputer array and hosted in a SUN3. 
Exploitation 
The approach is basically a generic one, but is driven by two classes of application: 
-mobile robots for public safety applications in nuclear plants, etc 
-surveillance systems for offshore oil fields, nuclear plants, airports, etc.";;;;;MATRA SA;FR;"MAPS INFORMATICA INDUSTRIAL;British Aerospace plc;UNIV POLITECNICA DE CATALUNYA;CHR. F. ROVSING A/S;CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE;THE CHANCELLOR, MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD;Krupp Atlas Elektronik GmbH";"ES;UK;DK;FR;DE";
8348;1556;VITAMIN;;FP1-ESPRIT 1;;FP1;Visualisation Standard Tools in Manufacturing Industry;01/01/1987;01/01/1990;;"The main objective of this project was to develop tools, based on Unix and X-Windows, to help the design and use of user interfaces and graphic subsystems on the shop floor in manufacturing industry. Two application areas were selected with corresponding graphics subsystems: 
-the Active Management Dashboard (AMD), for production systems with a low level of automation 
-the Active Control Dashboard (ACD), for the remote control and supervision of systems with a higher degree of automation, mainly in the mechanics industry. 
For each area an industrial test-bed was defined: 
-for the AMD, it was built around Syseca's ORDO package for real-time production scheduling 
-for the ACD, it was built around Mannesmann Kienzle's KIBIS package for workshop planning and management. 
Development was undertaken in two parallel and complementary ways: 
-a short-term approach based on toolkit design and use 
-a long-term approach based on user interface management system (UIMS) design and use. 
The main objective of this project was to develop tools, based on Unix and X-Windows, to help the design and use of user interfaces and graphic subsystems on the shop floor in manufacturing industry. 2 application areas were selected with corresponding graphics subsystems: the active management dashboard (AMD) for production systems with a low level of automation and the active control dashboard (ACD), for the remote control and supervision of systems with a higher degree of automation, mainly in the mechanics industry. For each area an industrial test bed was defined: for the AMD it was built around the ORDO package for real time production scheduling while for the ACD, it was built around the KIBIS package for workshop planning and management. Development was undertaken in 2 parallel and complementary ways: a short term approach based on toolkit design and use and a long term approach based on user interface management system (UIMS) design and use.
The toolkit approach led to redesigning ORDO and KIBIS. The objective of the UIMS approach was to provide the man machine interface (MMI) engineer with tools that automatically generate the user interface code. In a first step the MMI programmer specifies the builder user interface management builder (UIMB) which generates the source code of the user interface (UI monitor), using the so called skeleton technique. Compilation of this code and linkage with the computer integrated manufacture (CIM) application produces the run time system. 2 sets of tools were developed to implement the approach: the logical model builder tools, consisting of the graphical presentation techniques-dialogue control (PT-DC) and application interface (AI) editor and the UIMB.
The toolkit approach led to redesigning ORDO and KIBIS. Functional analysis of manufacturing production management was performed and the AMD external specifications produced. This allowed the design of a toolkit - a library of user interface objects - and its use for implementing the AMD user interface. The resulting prototype was evaluated on a test-bed in the Bull plant in Belfort (F). After architectural analysis the internal ACD specifications were produced and an X-Window system protocol implemented. A business graphics library, GKS and window managers were then layered onto both Mannesmann and Bull hardware. 
The objective of the UIMS approach was to provide the man-machine interface (MMI) engineer with tools that automatically generate the user interface code. It was based on the Seeheim model, which divides a user interface into three logical components: presentation techniques (PT), dialogue control (DC), and application interface (AI). In a first step the MMI programmer specifies the builder (UIMB) which generates the source code of the user interface (UI monitor), using the so-called skeleton technique. Compilation of this code and linkage with the CIM application produces the run-time system. Two sets of tools were developed to implement the approach: 
-the logical model builder tools, consisting of the graphical PT-DC and AI editor 
-the UIMB. 
The final system builder prototype was demonstrated at the end of the project in October 1989. The results of the project will promote the more efficient utilisation of manufacturing resources by the employment of windowing and graphic display techniques.";;;;;SYSECA SA;FR;"Fraunhofer-Gesellschaft zur Förderung der Angewandten Forschung eV (FhG);Tecnologia Energia Ambiente Materiali Srl;Politecnico di Milano;Université de Valenciennes et du Hainaut-Cambrésis";"DE;IT;FR";
8427;1504;MUST;;FP1-ESPRIT 1;;FP1;Next-Generation Database Management System;13/06/1986;13/03/1988;;"The objective of MUST was to establish the basis for the development of a new generation of database management systems (DBMS) with the following features: 
-treatment of new data types (documents, images, sounds, time) 
-use of inference techniques to ensure data integrity, deduce new data from recorded data, and help the user to set up his queries 
-compatibility with existing DBMS through use of the SQL interface SQL. 
The objective was to establish the basis for the development of a new generation of database management systems (DBMS) with the following features:
treatment of new data types (documents, images, sounds, time);
use of inference techniques to ensure data integrity, deduce new data from recorded data, and help the user to set up queries;
compatibility with existing DBMS through use of the structured query language (SQL) interface. During the first months of the project, a market survey identified the user requirements and the manufacturer perspectives for the next generation of DBMS. The concept of a resource dictionary was derived from work on new data types and on the refinement of a data dictionary. Experience of deductive components was gained by treating this topic separately from the rest of the work. A prototype of a natural language menu interface and a tentative mock up of a graphical interface were demonstrated.
During the first months of the project, a market survey identified the user requirements and the manufacturer perspectives for the next generation of DBMS. 
The concept of a resource dictionary was derived from work on new data types (time, graphics, etc) and on the refinement of a data dictionary. Experience of deductive components was gained by treating this topic separately from the rest of the work. 
A prototype of a natural language menu interface and a tentative mock-up of a graphical interface were demonstrated. 
Exploitation 
The impact of MUST on the compatibility of existing DBMS, the treatment of new data types and the inclusion of a deductive component will be exploited by the main contractor.";;;;;SYSECA SA;FR;"TECHNISCHE UNIVERSITAET KAISERSLAUTERN;ABSY";"DE;BE";
8437;1509;DESCARTES;;FP1-ESPRIT 1;;FP1;Debugging and Specification of Ada Real-Time Embedded Systems;01/03/1986;01/03/1989;;"The DESCARTES project aimed to assist developers of real-time embedded systems in Ada by investigating formal methods and designing software and hardware tools. 
Formal semantics and proof systems for real-time languages, with emphasis on composability, were investigated. A specification language including real-time constraints and correctness-preserving transformations was designed. 
Traceability of transformation decisions in the context of real-time constraints and analysis tools was developed.
The project aimed to assist developers of real time embedded systems in Ada by investigating formal methods and designing software and hardware tools. Formal semantics and proof systems for real time languages, with emphasis on composability, were investigated. A specification language including real time constraints and correctness preserving transformations was designed. Traceability of transformation decisions in the context of real time constraints and analysis tools was developed. Work was undertaken on the formalization of the semantics of an extension of Statelan with temporal logic, and on checking the consistency of combined specifications. Two directions were pursued, concentrating on the incorporation of Me-Too and Statelan specifications in Ada, and a system for tracing and analysing execution histories of Ada programs without disturbing the target machine was specified, and these tools implemented and demonstrated.
Work was undertaken on the formalisation of the semantics of an extension of Statelan with temporal logic, and on checking the consistency of combined specifications. Two directions were pursued, concentrating on the incorporation of Me-Too in the Statemate system, and on the methodology of refinement. Work was started on the translation of Me-Too and Statelan specifications in Ada, and a system for tracing and analysing execution histories of Ada programs without disturbing the target machine was specified, and these tools implemented and demonstrated. 
Exploitation 
An Ada debugger system was developed by ES Dassault, a partner in the aerospace industry, for testing real-time Ada systems through internal use. An immediate impact on the quality and reliability of real-time embedded systems implemented in Ada is expected.";;;;;GSI TECSI Software SA;FR;"TECHNISCHE UNIVERSITEIT EINDHOVEN;SYSTEAM KG;FOXBORO NEDERLAND NV;AVIONS MARCEL DASSAULT-BREGUET AVIATION;University of Stirling";"NL;DE;FR;UK";
8627;1587;MINSTREL;;FP1-ESPRIT 1;;FP1;New Information Models for Office Filing and Retrieval;01/09/1984;01/09/1987;;"The MINSTREL project has identified and developed software techniques for future office filing and retrieval systems. The focal point was the development of an office information model which could be used to describe the properties of and operations used on all forms of office information. 
In MINSTREL, the existence of a large and varied body of information composed of images, sound, graphics, text and numerical data was assumed, together with a demand for greater functionality and a higher degree of integration in computerised office support tools. Consequently, it was felt that future office systems should be built with a more flexible and powerful architecture. The chosen architecture was based on three major principles: modularisation, layering of functions, and a single uniform data representation. 
 The central task was the development of an office information model which could provide a single uniform data representation, and thus play a role similar to a database management system. The other tasks in MINSTREL were aimed at developing techniques to improve the effectiveness with which an office worker can retrieve required information from such a filing system. The ideas developed in the project were validated by integrating them in a prototype implementation of an office filing system incorporatingfeatures, including a graphic-based user interface and efficient storage structures. 

The following results were achieved: 
-a complete formal specification of a comprehensive office information model 
-a prototype implementation of a subset of this office information model, including a specially developed storage management system for efficient access 
-a prototype implementation of a dialogue manager providing a uniform user interface to all office applications 
-the use of graphics to construct a user-friendly interface employing various presentation forms to clearly manifest the underlying organisation and structure of the stored data 
-a formal specification and prototype of a query language that allows convenient querying of both structured data and text, and which can also handle imprecision, both in query criteria and in the stored data values 
-a text retrieval algorithm which uses syntactical analysis to achieve a more accurate match of queries and documents 
-the specification of an access control system, within the office information model, which provides a pseudo-mandatory as well as a discretionary security policy 
 -a prototype implementation of a data entry subsystem that can input paper documents using a scanner in an adaptive manner, in that it can separate images from text and recognise characters despite poor-quality copies, font changes and other irregulariti es. 
Exploitation 
 Some of the results, such as the graphic user interface, the handling of imprecision, the content retrieval mechanism, the access control system and the data-entry subsystem, can be applied to present-day office information systems. Some of these will be exploited by the industrial partners. The system architecture and the office information models are very relevant for future office information systems with major requirements for multimedia data and the integration of application programs. In particular,the office information model is ideally suited for representing structured documents, as in the Office Document Architecture (ODA) standard, and for integrating them into a general filing and retrieval system.";;;;;ESPRIT INFORMATION DESK;BE;"UNIV COLLEGE DUBLIN;DENMARK CLEANING OCODE;GN-GREAT NORDIC LTD;NATIONAL SOFTWARE CENTRE LTD";"IE;DK";
8453;1521;PRACTITIONER;;FP1-ESPRIT 1;;FP1;Support System for Pragmatic Reuse of Software Concepts;01/12/1986;01/12/1991;;"The objective of practitioner was to develop methods and tools for the pragmatic re-use of software at the design stage. The task was to enable the user to identify, isolate, document, store, retrieve and re-use program concepts (or more generally, software concepts). Techniques from linguistics and from the fields of indexing and information retrieval have been used to analyse existing material. Substantial effort has been spent in carrying out domain analysis work and in developing an appropriate methodology. A number of successive prototype systems have been built, tried out and improved over the duration of the project. 
PROGRESS AND RESULTS 
A meta-model for the re-use scenario has been agreed by the partners. In dealing with specific application domains such as process control software for metal working or basic systems software for graphical user interfaces, a questionnaire for the collection and later retrieval of concepts has proved its utility, and the development of tools and methods for the preparation of very specific thesauri for the respective domains has turned out to be very useful. The prototype systems developed for retrieval and re-use (code-named 'PRESSTO' and 'PRESSTIGE') are based on standard relational database systems and on widespread user interfaces for Unix such as XView and OSF motif. 
EXPLOITATION 
PRACTIONER has been combining advanced theoretical research results with pragmatic prototyping and early hands-on experiments, in order to serve its test users at the earliest possible stage. Within the different partners' organisations, exploitation willfollow somewhat different paths. 
One partner will focus on the utilisation of the domain analysis techniques and on the use of the PRACTITIONER tools within its own organisation: the two other industrial partners will exploit the results within their product developments tasks. 
The objective was to develop methods and tools for the pragmatic reuse of software at the design stage. The task was to enable the user to identify, isolate, document, store, retrieve and reuse program concepts (or more generally, software concepts). Techniques from linguistics and from the fields of indexing and information retrieval have been used to analyse existing material. Substantial effort has been spent in carrying out domain analysis work and in developing an appropriate methodology. A number of successive prototype systems have been built, tried out and improved over the duration of the project. A metamodel for the reuse scenario has been agreed by the partners. In dealing with specific application domains such as process control software for metal working or basic systems software for graphical user interfaces, a questionnaire for the collection and later retrieval of concepts has proved its utility, and the development of tools and methods for the preparation of very specific thesauri for the respective domains has turned out to be very useful. The prototype systems developed for retrieval and reuse are based on standard relational database systems and on widespread user interfaces for Unix such as XView and OSF motif.";;;;;PCS Computersysteme GmbH;DE;"CRI-COMPUTER RESOURCES INTL. A/S;University of Liverpool;Asea Brown Boveri AG;Brunel University";"DK;UK;DE";
8339;1477;ACCORD;;FP1-ESPRIT 1;;FP1;Computer-Aided Engineering Software for Advanced Workstations in the CIM Environment;01/07/1986;01/07/1990;;"The objective of this project was to develop an enhanced CAD environment (ACCORD) for performing design analyses for CIM in the electronics industry. 
Three research paths have been explored in particular: 
-integration of a range of design and analysis tools into a coherent computer environment 
-computerisation of engineering expertise, thereby aiding the analyst to work faster, more reliable and comprehensive 
-computational speed-up aiming at truly interactive analysis. 
The work concentrated on the development and implementation of: 
 -APPEAL (ACCORD Parallel Processing Engineering Analysis Library): a software development that provides improved performance on vector computers for the computationally intensive linear algebra that arises when solving large unstructured sparse matrix eq uations. This has been achieved by designing a new data structure which is suitable for vector computers and restructuring the code to benefit from the architecture of the computer. 
 -ASSET (ACCORD Suite of Software Engineering Tools): a software package integrating three engineering disciplines - reliability, cost and thermal analysis - under a common management system to perform analyses to evaluate ranges of design options for imp roving functionalities and reducing costs. ASSET's objective was to improve computer-aided engineering by making design assurance an integral part of the design process. 
The objective of this project was to develop an enhanced computer aided design (CAD) environment (ACCORD) for performing design analyses for computer integrated manufacture (CIM) in the electronics industry. 3 research paths have been explored in particular: integration of a range of design and analysis tools into a coherent computer environment, computerisation of engineering expertise, thereby aiding the analyst to work faster, more reliably and comprehensively and computational speed up aiming at truly interactive analysis.
The work concentrated on the development and implementation of APPEAL (ACCORD parallel processing engineering analysis library) and ASSET (ACCORD suite of software engineering tools). The APPEAL library contains 4 categories of routines: matrix, vector and scalar operations, performing the normal matrix and vector operations; linear solvers, which are all gradient style solvers; matrix assembly, aggregating contributions to form the final matrix equation for solution; and utilities, which intialize the library constants and handle data conversions and errors. The APPEAL library has a reference code that has been tested on a number of vector computers and, in particular, has been customized for the FPS M64 and the IBM 3090. The reference code contains the newly designed data structure and all the coding nuances that aid vector computations.
ASSET aimed to achieve its objectives through the encapsulation of engineering expertise and the integration of design assurance tools. Its main elements are: an executive manager, domain managers, libraries of technical knowledge and data, a set of analysis tools, a major knowledge based reliability component (ADVISE) and a product analysis database. All the software packages within ASSET can be used as separated tools or in any one of a number of combinations.
The APPEAL library contains four categories of routines: 
-matrix, vector and scalar operations, performing the normal matrix and vector operations 
-linear solvers, which are all gradient-style solvers 
-matrix assembly, aggregating contributions  to form the final matrix equation for solution 
-utilities, which intialise the library constants and handle data conversions and errors. 
The APPEAL library has a reference code that has been tested on a number of vector computers and, in particular, has been customised for the FPS M64 and the IBM 3090. The reference code contains the newly designed data structure and all the coding nuancesthat aid vector computations; however, further improvements are possible for a given architecture by additional coding changes and implementing the fast assembler code provided by the computer vendor. 
ASSET aimed to achieve its objectives through the encapsulation of engineering expertise and the integration of design assurance tools. Its main elements are: 
-an executive manager 
-domain managers 
-libraries of technical knowledge and data 
-a set of analysis tools 
-a major knowledge-based reliability component (ADVISE) 
-a product analysis database. 
All the software packages within ASSET can be used as separate tools or in any one of a number of combinations. 
Demonstration prototypes for both APPEAL and ASSET are running successfully. Some improvements of the demonstrations have also been made. 
This project will strongly promote the use of advanced analysis tools and methods within the designer and analyst community in the electronics industry.";;;;;Bertin & Cie;FR;"Università degli Studi di Genova;TRINITY COLLEGE DUBLIN;PHILIPS DUPONT OPTICAL;GEC Marconi Research Centre;VECTOR FIELDS LTD;ATHENS SCHOOL OF ECONOMICS;SOCIETE GENERALE DE TECHNIQUES ET D'ETUDES";"IT;IE;NL;UK;EL;FR";
8667;1533;MIS;;FP1-ESPRIT 1;;FP1;Multilingual Information System;01/01/1987;01/07/1988;;"Intelligent dialogue is fundamental for the use of any natural language product operated by persons not fully aware of the system's capabilities or of the data it contains. It strengthens the overall system and enables mastery of the complex task of manipulating the natural language analysis components. 
The MIS project addressed semantic representations of natural language sentences that could be effectively used to query and manipulate a multilingual structured document database. The project examined the feasibility of designing a core system for handling information retrieval requests to data and document bases in five of the major European languages. 
The project addressed semantic representations of natural language sentences that could be effectively used to query and manipulate a multilingual structured document database. The project examined the feasibility of designing a core system for handling information retrieval requests to data and document bases in five of the major European languages.

The state of the art was investigated in those domains where advanced products could be developed which would only be marketed after a period of four to seven years. These included natural language analysis and generation, dialogue and planning, and knowledge representation and engineering, together with machine translation and information and information retrieval in a multilingual context. A market study was also undertaken to gain an appreciation of the economic viability of such products and the manner in which they should be exploited. Proposals were made concerning the underlying architecture of such a system based on the current state of the art, progress made and the competence of the partners. These propositions took into account the requirements of multilingualism and the types of knowledge involved. Investigations were carried out into the technical aspects of each language studied. It was recognised that full dialogues should be supported between the user and the system. The risk of constructing an architecture of a multilingual information system entirely around the concept of a dialogue planner was considered to be high. However, an acceptable paradigm for handling dialogue was nevertheless considered.
The state of the art was investigated in those domains where advanced products could be developed which would only be marketed after a period of four to seven years. These included natural language analysis and generation, dialogue and planning, and knowledge representation and engineering, together with machine translation and information and information retrieval in a multilingual context. A market study was also undertaken to gain an appreciation of the economic viability of such products and the manner in which they should be exploited. 
 Proposals were made concerning the underlying architecture of such a system based on the current state of the art, progress made and the competence of the partners. These propositions took into account the requirements of multilingualism and the types of knowledge involved. 
Investigations were carried out into the technical aspects of each language studied. It was recognised that full dialogues should be supported between the user and the system. The risk of constructing an architecture of a multilingual information system entirely around the concept of a dialogue planner was considered to be high. However, an acceptable paradigm for handling dialogue was nevertheless considered. 
Exploitation 
The project resulted in a proposal for future collaborative development to provide a series of prototypes for architectural validation, as multilingual information is complex to design, and distinct architectural options are not yet evident.";;;;;BULL SA;FR;"Ingegneria C. Olivetti and C. SpA;SIEMENS-NIXDORF INFORMATIONSSYSTEME AG;International Computers Ltd (ICL)";"IT;DE;UK";
8631;1591;SPIN;;FP1-ESPRIT 1;;FP1;Speech Interface at Office Workstation;01/07/1984;01/07/1989;;"The overall aims of the SPIN project were to: 
-make significant advances in speech input/output algorithms 
-study ergonomic aspects in relation to the integration of speech input/output facilities in the office environment 
-build a demonstrator illustrating the main results of the project, consisting of a prototype of a workstation with speech facilities. 
The aims of the project were to make significant advances in speech input/output algorithms, study ergonomic aspects in relation to the integration of speech input/output facilities and build a demonstrator.

The MPLPC algorithm was the coding method chosen and a simulation of refined versions and a real time breadboard implementation of the algorithm are available.
Work concentrated on algorithm studies. The results were embodied in an experimental demonstrator, MARIPA, which was a low cost recognizer based on a personal computer (PC) board. The demonstration of the first stage of the continuous speech recognizer, producing a lattice of demisyllables for continuous speech recognition, was achieved. Speech input/output assessment methodology was refined and used to improve the quality of the developed algorithm.

Text to speech synthesis systems for French, Italian and Greek were developed, with emphasis on phonetic components, prosody, development of a speech rule compiler and quality evaluations of the French and Italian diphone sets.

Automatic test software for the simulation of speaker verification was produced, running on a large speech database and a final real time automatic speaker verification system was implemented.

A 3 digital signal processing (DSP) based modular hardware for speech processing was designed and developed, and each speech algorithm implemented. An experimental final system, made up a PC and of a speech interface was built to present the results of the project.
Experiments were completed and results and guidelines delivered with regard to:
integration of speech input/output facilities in a multimedia person machine interface;
use of speech in specific office applications;
definition of the best positions for a microphone on a workstation for speech input;
definition of a measuring technique for determining the noise sensitivity of speech recognizers;
behaviour of test subjects when using a multimedia user interface.
The main results of the SPIN project were as follows: 
Speech Algorithms 
-Coding 
 Three coding methods (MPLPC, TDHS, and RELP) have been studied in detail and simulated versions of these algorithms produced. Evaluation of their intelligibility showed that the MPLPC algorithm was the best one at the chosen bit rate (9.6 Kbit/s); a simu lation of refined versions and a real-time breadboard implementation of the MPLPC algorithm are currently available. 
-Speech recognition 
 Work was concentrated on algorithm studies. The results were embodied in an experimental demonstrator, MARIPA, which was a low-cost recogniser based on a PC board. The demonstration of the first stage of the continuous speech recogniser, producing a latt ice of demi-syllables for continuous speech recognition, was also achieved. Speech input/output assessment methodology was refined and used to improve the quality of the developed algorithm. 
-Text-to-speech synthesis 
Text-to-speech synthesis systems for French, Italian and Greek were developed, with emphasis on: 
.phonetic components: full diphone dictionaries are available for the three languages dealt with in the project 
.prosody: many rules of duration and intonation were defined 
.development of a speech rule compiler 
.quality evaluations of the French and Italian diphone sets. 
-Speaker verification 
 Automatic test software for the simulation of speaker verification was produced, running on a large speech database. A final real-time automatic speaker verification system was implemented and used to control access to protected areas of the R&D laborato ries. 
Hardware Implementation and Integration 
A three DSP-based modular hardware for speech processing was designed and developed, and each speech algorithm (coding, speech recognition, speaker verification, text-to-speech synthesis) implemented. 
An experimental final system, made up a PC and of a speech interface (built in a VME environment and connected to the PC via a serial line) was built to present the results of the project. The office application chosen was agenda planning. 
Ergonomic aspects were also carefully studied. Several experiments were completed and significant results and guidelines delivered with regard to: 
-integration of speech input/output facilities in a multimedia person-machine interface 
-use of speech in specific office applications 
-definition of the best positions for a microphone on a workstation for speech input 
-definition of a measuring technique for determining the noise sensitivity of speech recognisers 
-behaviour of test subjects when using a multimedia user interface. 
Exploitation 
The results of this project were used in project 954, IKAROS.";;;;;SOCIETE ETUDES SYSTEMS AUTOMATIONS (SESA);FR;"UNIV VAN AMSTERDAM;CMSU-COMMUNICATION & MANAGEMENT SYSTEMS UNIT.;Alcatel Alsthom Recherche;SIEMENS-NIXDORF INFORMATIONSSYSTEME AG;Daimler-Benz AG;Centro Studi e Laboratori Telecomunicazioni SpA;Scuola Normale Superiore di Pisa;COMMISSARIAT A L'ENERGIE ATOMIQUE;Oros SA";"NL;EL;FR;DE;IT";
8449;1518;FORMAST;;FP1-ESPRIT 1;;FP1;Formal Methods for Asynchronous System Technology;19/05/1986;19/05/1988;;"FORMAST aimed to provide a formal framework and a suitable toolset for the development of asynchronous embedded micro and distributed systems. 
The toolset was to include presentation language and tools such as a design database, formal design provers based on theorem-proving techniques, designer's assistants and simulators, and was to be linked to an asynchronous system development environment compatible with PCTE. 
The project aimed to provide a formal framework and a suitable toolset for the development of asynchronous embedded microsystems and distributed systems. The toolset included presentation language and tools such as a design database, formal design provers based on theorem proving techniques, designer's assistants and simulators, and was linked to an asynchronous system development environment compatible with a portable common tool environment (PCTE). Progress was made in developing a compositional method for asynchronous system design. Work advanced in proof methods and in defining a case study based on an aerospace system. The specification method was defined, thecase study completed and prototype tool support developed. Considerable progress was made in theorem providing.
Progress was made in developing a compositional method for asynchronous system design. Work advanced in proof methods and in defining a case-study based on an aerospace system. The specification method was defined, the case study completed and prototype tool support developed. Considerable progress was made in theorem-proving. 
Exploitation 
Consideration is being given to further development of the toolset and also to placing the results of the project, including tools, in the public domain.";;;;;Advanced System Architectures;UK;"TECHNISCHE UNIVERSITAET KAISERSLAUTERN;Centre for Renewable Energy Systems Technology;ERNO Raumfahrttechnik GmbH;IMPERIAL COLLEGE OF SCIENCE, TECHNOLOGY AND MEDICINE";"DE;UK";
8486;1588;SPAN;;FP1-ESPRIT 1;;FP1;Parallel Computer Systems for Integrated Numeric and Symbolic Processing;05/01/1987;05/01/1990;;"The objective of SPAN was to investigate programming languages and parallel architectures for the integration of symbolic and numeric processing, and to develop a common virtual machine. The project was organised into distinct layers: application softwarepackages; high-level languages and tools; the 'virtual machine' kernel system; and parallel architectures. 
The kernel system comprises an intermediate representation, currently implemented by a target machine language (TML) and its associated virtual machine code (VMC), through which all high-level languages were to be compiled onto a range of architectures for execution. It formed a focal point of the project. Two high-level language compilers were to be produced, together with an object-oriented framework for language integration. Three types of parallel architecture were to be evaluated, and an investigation was to be conducted into novel VLSI architectures for efficient execution of the VMC. To demonstrate the utility of these techniques, a range of applications software was to be developed. 
The development work is divided into 3 areas:
 a 1800 x 2400 high resolution graphics board compatible with an IBM XT/AT bus;
 a system for digitising, storing and visualisation of images with 512 x 512 pixel resolution, 8-bit quantified;
 a system which makes an analysis of linear discrete systems taking the graph as an input and drawing frequency response curves (with the possibility of generating code for the signal processor TMS 320).

The objective was to investigate programming languages and parallel architectures for the integration of symbolic and numeric processing, and to develop a common virtual machine. The project was organized into distinct layers: application software packages; high level languages and tools; the virtual machine kernel system; and parallel architectures. The kernel system comprises an intermediate representation, currently implemented by a target machine language (TML) and its associated virtual machine code (VMC), through which all high level languages were compiled onto a range of architectures for execution. It formed a focal point of the project. Two high level lanaguage compilers were produced, together with an object oriented framework for language integration. Three types of parallel architecture were evaluated, and an investigation was conducted into novel very large scale integration VLSI architectures for efficient execution of the VMC. To demonstrate the utility of these techniques, a range of applications software was developed. Work was undertaken in parallel lanaguage definition and architectures, and in the 4 application areas of image interpretation, real time expert systems, partial differential equation solvers, and parallel relational database management systems DBMS. Evaluation of the applications on Supernode and other architectures was performed.
Work was undertaken in parallel language definition and architectures, and in the four application areas of image interpretation, real-time expert systems, partial differential equation solvers, and parallel relational DBMS. Evaluation of the applicationson Supernode and other architectures was performed. 
Exploitations 
The project has achieved significant results in the area of virtual machine definition, compilers for parallel systems, object-oriented frameworks and investigations into several architectures. Hardware implementations have also been produced.";;;;;Central Research Laboratories plc;UK;"COMPUTER TECHNOLOGY INSTITUTE;INESC-INSTITUTO DE ENGENHARIA DE SISTEMAS E COMPUTADORES;THOMSON CSF;PCS Computersysteme GmbH;Birkbeck College, University of London";"EL;PT;FR;DE;UK";
6341;RI1B0200;MACPOP;;FP1-BRITE;;FP1;MODELLING AND AUTOMATIC CONTROL OF THE POLISHING PROCESS;01/05/1988;30/04/1991;;"A general model of the polishing process has been developed, a simulation code to determine tool path kinematics and optimal strategies has been determined, and control of the reproducibility of polishing experiments, has been established.
The architecture and the specifications of a robot for automatic polishing are being defined. The programme defined to reach these objectives included 7 tasks and several key parts such as model identification from experimental data and the use of modern control theory together with experienced polishers know how in the controller.
HIGH PRECISION POLISHING OF OPTICAL SURFACES IS AN EXPENSIVE PROCESS WHICH REQUIRES MANY WORKING HOURS OF EXPERIENCED POLISHERS. IT APPEARS THAT A SUBSTANTIAL REDUCTION OF THE MANUFACTURING COST OF OPTICAL COMPONENTS COULD BE OBTAINED WITH AUTOMATIC POLISHING. AUTOMATIC POLISHING CAN BE PERFORMED WITH A ROBOT ABLE TO GENERATE POLISHING STRATEGIES FROM THE SPECIFICATIONS OF THE DESIRED PIECE AND THE MEASUREMENT OF THE SURFACE TOPOLOGY, AND TO IMPLEMENT THESE STRATEGIES THROUGH APPROPRIATE ACTIONS ON THE INFLUENTIAL PARAMETERS OF THE PROCESS.
SUCH A ROBOT DOES NOT EXIST NOW AND IT IS PROPOSED TO EXAMINE THE VARIOUS ASPECTS AND REQUIREMENTS FOR ITS DESIGN, USING AN ORIGINAL APPROACH BASED ON A SYNERGY BETWEEN SEVERAL FIELDS: MECHANICS, OPTICS, ELECTRONICS, AUTOMATIC CONTROL, ARTIFICIAL INTELLIGENCE. THIS PROJECT CONCERNS THE BASIC RESEARCH TO BE PERFORMED PRIOR TO THE DEVELOPMENT OF A POLISHING ROBOT, ITS OBJECTIVE ARE TO:
1. OBTAIN A GENERAL MODEL OF THE POLISHING PROCESS.
2. DESIGN A CONTROLLER ABLE TO DERIVE AUTOMATICALLY AND TO IMPLEMENT OPTIMAL POLISHING STRATEGIES.
3. DEMONSTRATE THE FEASIBILITY OF AUTOMATIC POLISHING.
4. DEFINE THE ARCHITECTURE AND THE SPECIFICATIONS OF A ROBOT FOR AUTOMATIC POLISHING. THE PROGRAMME DEFINED TO REACH THESE OBJECTIVES INCLUDES SEVEN TASKS AND SEVERAL KEY PARTS SUCH AS MODEL IDENTIFICATION FROM EXPERIMENTAL DATA AND THE USE OF MODERN CONTROL THEORY TOGETHER WITH EXPERIENCED POLISHERS KNOW-HOW IN THE CONTROLLER.";;;;CSC;Bertin et Cie S.A.;FR;"Institut International de Robotique et d'Intelligence Artificielle de Marseille;Leico Maschinenbau;Taighdeclar Genesis Teoranta";"FR;DE;IE";
6383;RI1B0094;ADENG;;FP1-BRITE;;FP1;ADHESIVE BONDING TECHNOLOGY FOR ENGINEERING APPLICATIONS;01/02/1986;31/01/1990;;"The designer can now use design software with a procedure manual which enables him to select the correct joint type and size. There are also databases which enable him to select and source the correct adhesive and the best surface preparation for optimum joint life and reliability. The engineer can now design structures with adhesively bonded joints, confident that they will be of known strength and reliability.

Novel test methods have been developed to provide quantitative information on joint behaviour in aggressive environments.
A computer database on adhesive bonding has been developed.
Results have helped provide increased information on zinc coated materials.
Polymer surface treatment has led to increased joint strength.
THE PROJECT AIMS AT DEVELOPING AND DEMONSTRATING THE BASIC TECHNOLOGY NECESSARY TO IMPLEMENT ADHESIVE BONDING TECHNOLOGY IN THE ENGINEERING INDUSTRY, MAINLY IN VEHICLE CONSTRUCTION AND IN MECHANICAL ENGINEERING.

ADHESIVE BONDING ENABLES STIFF JOINTS WHICH, WHEN SUBJECTED TO APPLIED LOADS, PRODUCE STRESSES IN THE COMPONENTS WHICH ARE LOWER THAN FOR JOINTS MADE BY OTHER JOINING TECHNIQUES. THERE IS POTENTIAL WEIGHT SAVING IN MATERIALS, BUT THE APPLICATIONS OF THIS TECHNOLOGY HAVE BEEN UNTIL NOW LARGELY LIMITED TO AIRCRAFT CONSTRUCTION.

A COMPUTER SELECTION PROGRAMME OF THE ADHESIVES AND OF THEIR INCORPORATION IN THE BONDING JOINT DESIGN PROCEDURE IS TO BE ACHIEVED. BASIC CONFIGURATIONS ARE TO BE ESTABLISHED SO AS TO PRODUCE METHODS FOR THE DESIGN OF JOINTS BOTH WITHIN AND BEYOND THE ELASTIC LIMIT OF THE MATERIALS USED.

THE PRACTICAL PART OF THE PROJECT CONCERNS THE SURFACE PRETREATMENT PROCESS, ASSESSMENT OF THE MANUFACTURING TECHNOLOGY, ADHESIVE APPLICATION TECHNIQUES, COMPONENT ASSEMBLY METHODS AND QUALITY CONTROL. THIS IS TO BE FOLLOWED BY THE APPLICATION AND PROVING OF THE TECHNOLOGY, BOTH IN SERVICE AND THROUGH BENCH TESTING.";;;;CSC;PRODUCTION ENGINEERING RESEARCH ASSOCIATION - PERA;UK;"Oxford Brookes University;Centre Technique des Industries Mécaniques (CETIM)";"UK;FR";
6330;RI1B0172;OFELIA;;FP1-BRITE;;FP1;OPTICAL FIBRES FOR ELECTRICAL INDUSTRY APPLICATIONS / DEVELOPMENT OF PASSIVE OPTO-ELECTRONIC SENSORS FOR MEASUREMENTS AND DIAGNOSTICS IN ELECTRICAL POWER SYSTEMS;01/05/1988;30/04/1991;;"An optical sensor which measures electrical current, voltage and temperature has been developed by researchers in this project. The sensors creates a new generation of safer, automatic measuring and diagnostic equipment for high voltage electrical power stations, but problems with the lasers mean that some modifications are needed before the technology can be used industrially.
THE RESEARCH FORESEES THE DEVELOPMENT OF OPTO-ELECTRONIC DEVICES FOR MEASUREMENT OF THE FOLLOWING QUANTITIES IN ELECTRICAL SYSTEMS:
- HIGH VOLTAGES, STEADY STATE AND TRANSIENTS, UP TO SOME MV;- HIGH CURRENTS, STEADY STATE AND TRANSIENTS, UP TO 100 KAP;- TEMPERATURES IN ELECTRICAL MACHINES AND COMPONENTS.

THE DEVICES ARE BASED ON THE USE OF PASSIVE OPTICAL FIBRE SENSORS: THE TRANSDUCERS, IN FIELD, CONSIST OF A PASSIVE OPTICAL ELEMENT (OPTICAL FIBRE, CRYSTAL), WHILE THE ACTIVE OPTICAL COMPONENTS (LIGHT EMITTER AND DETECTOR) AND THE ELECTRONICS FOR LIGHT CONTROL AND SIGNAL PROCESSING ARE PLACED, OUT OF FIELD, AT THE 'RECEIVING' END. THE SIGNAL TRANSMISSION, TO AND FROM THE FIELD, IS MADE BY OPTICAL FIBRES. MAIN TECHNICAL FEATURES ARE: HIGH ACCURACY, HIGH IMMUNITY FROM EMI; MINIMUM INVASIVENESS; FULL ELECTRICAL INSULATION; HIGH RESISTANCE TO ENVIRONMENTAL STRESSES; INTRINSIC SAFETY. THE MAIN ECONOMICAL ISSUE IS THE INDEPEDENCY OF THE COST OF THE APPLIED VOLTAGE. THE DEVICES CAN BE USED FOR MEASUREMENT, PROTECTION AND CONTROL, AS WELL FOR ON-LINE DIAGNOSTIC MONITORING.";;;;CSC;CESI CENTRO ELETTROTECNICO SPERIMENTALE ITALIANO GIACINTO MOTTA SPA;IT;"Pirelli SpA;Sistemas e Instrumentación SA;Fuerzas Eléctricas de Catalunya SA;UNIVERSITAT POLITECNICA DE CATALUNYA";"IT;ES";
8450;1085;SUPERNODE;;FP1-ESPRIT 1;;FP1;Development and Application of a Low-Cost, High-Performance, Multiprocessor Machine;09/12/1985;09/12/1988;;"The objective of SUPERNODE was to develop a high-performance, multiprocessor, prototype computer with a flexible architecture, suitable for a wide range of scientific and engineering problems. 
The objective was to develop a high performance, multiprocessor, prototype computer with a flexible architecture, suitable for a wide range of scientific and engineering problems. The basic component (the T800 version of the transputer with a floating point multiplier facility) and the Supernode computer developed in the project are representative of the present state of the art. A 1000 transputer machine was implemented as an array of supernodes. The machine architecture is expandable, and the interconnection of nodes is reconfigurable, as are the transputers at the node level. A high speed input/output interface (100 Mbit/s) was developed for real time vision applications. The basis for software development is OCCAM and the INMOS transputer development system. The software development host is either MSDOS or Unix using the transputer development system with extensions. The target code is downloaded to Supernode over a transputer communications connection. Important applications in signal processing and logic simulation benefiting directly from the parallel processing environment have been successfully developed. Other studies have been made of the user software environments in the following areas: image processing, scientific applications, computer aided design (CAD), ray tracing, computer aided manufacture (CAM), and in the provision of a numerical algorithms library.
Results were as follows: 
-Hardware 
 The basic component (the T800 version of the transputer with a floating-point multiplier facility) and the Supernode computer developed in the project are representative of the present state of the art. A 1000-transputer machine was implemented as an arr ay of supernodes. The machine architecture is expandable, and the interconnection of nodes is reconfigurable, as are the transputers at the node level. A high-speed input/output interface (100 Mbit/s) was developed for real-time vision applications. Further multi-node machines are currently under test prior to delivery. 
-Base-level software 
 The basis for software development is OCCAM and the INMOS transputer development system. The software development host is either MSDOS or Unix using the Transputer Development System with extensions. The target code is downloaded to Supernode over a tran sputer communications connection. 
-User software 
 Important applications in signal processing and logic simulation benefiting directly from the parallel processing environment have been successfully developed. Other studies have been made of the user software environments in the following areas: image p rocessing, scientific applications, CAD, ray tracing, CAM, and in the provision of a numerical algorithms library. 
Exploitation 
The T800 transputer is a significant industrial result from INMOS and is now manufactured for industrial use. Five hundred designs worldwide are based on the T800 and its spin-offs. Single and multiple node Supernode-based machines are being marketed.Among the applications and products that have resulted from the work packages of this project are the following: the LUCKY-LOG logic simulator in the CAD for VLSI area, now presented as an add-on card for PCs; several image-processing applications; digital signal processing applications; applications of image generation by the ray-tracing method; multi-transputer architecture studies in CAM; the provision of diagnostics and debuggers; and Occam and Fortran libraries. 
The Supernode computer has been further developed to the product level by Telmat and Thorn-EMI. A new subsidiary of Thorn-EMI, PARSYS, has been set up to handle the product. Manufacturing of components is shared between the companies to encourage economies of scale. 
The project has attracted wide interest in the architectures community, particularly through several international presentations. 
The availability of parallel processing hardware, based around systems such as T800, has demonstrated the poor level of software to support such systems. Efforts are in progress to address the shortcomings in both skills and products.";;;;;Defence Research Agency (DRA);UK;"University of Southampton;Central Research Laboratories plc;Inmos Ltd;Institut National Polytechnique de Grenoble;APSIS;Telmat Informatique SA";"UK;FR";
12574;EN3S0111;EUFRAT;;FP1-ENNONUC 3C;;FP1;SIMPLIFIED METHODS FOR THE SIZING OF ACTIVE SOLAR SYSTEMS.;01/07/1987;31/12/1989;;"A handbook has been developed to provide climatological data which can be used as an input for the design of passive solar buildings and solar systems. Solar radiation data for 37 typical European locations are presented, including: monthly average global and direct solar irradiation for several surfaces (types of receiver, orientation and inclination); and cumulative frequency and utilisability curves of solar irradiance. Ambient temperature data are presented for 186 European locations as monthly average ambient temperatures and monthly degree days at several base temperatures. A set of methods and algorithms are also given for the reconstitution of these parameters at places where little information is available, and examples of design tools are included.
WITHIN THE GENERAL OBJECTIVES OF OPSYS (GATHERING OF ALL THEORETICAL AND EXPERIMENTAL EVIDENCE ABOUT THE PERFORMANCE OF ACTIVE SOLAR SYSTEMS), IT IS PARTICULARLY IMPORTANT TO HAVE WELL-CALIBRATED SIMPLIFIED METHODS SUITABLE FOR ENGINEERING OF THE SYSTEMS. THE METHOD FOR INDIVIDUAL SYSTEMS (ESM1) ELABORATED IN THE PREVIOUS R&D PROGRAM (81-83) HAS BEEN TRANSFORMED INTO A CONVENIENT SOFTWARE READY FOR PUBLIC RELEASE (ESM1-4). THE METHOD FOR COLLECTIVE SYSTEMS, NAMELY MEDIUM SIZED WATER HEATERS (ESM2) HAS BEEN ESTABLISHED AND IS BEING VALIDATED AGAINST EMGP2, OUR EUROPEAN REFERENCE. A HANDBOOK HAS BEEN WRITTEN, MEANT AS A REFERENCE BOOK IN ENGINEERING OF ACTIVE SYSTEMS. 

THE METHODS ESM1 AND ESM2 ARE BASED UPON ORIGINAL MATHEMATICAL DERIVATIONS OF THE AVERAGE BEHAVIOUR OF ACTIVE SYSTEMS. THEY USE CLOSED FORM REPRESENTATIONS OF STRATIFICATION AND OF THE UTILISABILITY OF THE INCIDENT SOLAR RADIATION. THIS SOUND BASIS ALLOWS VERY ACCURATE OPTIMIZATION OF DESIGN PARAMETERS LIKE HEAT EXCHANGER PARAMETERS AND LEAD TO A GOOD ACCURACY WHEN ESM2 IS COMPARED WITH EMGP2, OUR EUROPEAN REFERENCE. 

THE FINAL PRODUCTS OF THE STUDY CONSIST OF: 

- SCIENTIFIC RESULTS FOR THE UNDERSTANDING OF ACTIVE SOLAR SYSTEMS (DESIGN PARAMETERS, SENSITIVITIES,...) AND OTHER SYSTEMS WITH A STORAGE (STRATIFICATION, CONTROL,...) 

- TWO PIECES OF SOFTWARE AVAILABLE ON THE MARKET AT LOW COST: ESM1 (INDIVIDUAL SYSTEMS) AND ESM2 (MEDIUM SIZED WATER HEATERS) WITH THE CONVENIENT METEOROLOGICAL DATA (PROVIDED BY EUFRAT) 

- DOCUMENTATION ON THE VALIDITY OF THE METHODS, FOR SPECIALISTS, INCLUDING A SYSTEMATIC CHECK OF CONSISTENCY WITH EURSOL AND EMGP2 

- A HANDBOOK PUBLISHED BY A WELL KNOWN PUBLISHING HOUSE EXPLAINING THE DESIGN AND ENGINEERING OF ACTIVE SOLAR SYSTEMS, AND SERVING AS BASIS FOR FUTURE DEVELOPMENT OF DESIGN AIDS.";;;;CSC;ASSOCIATION POUR LA RECHERCHE ET LE DEVELOPPEMENT DES METHODES ET PROCESSUS INDUSTRIELS;FR;"LNETI;NATIONAL OBSERVATORY OF ATHENS;ESCUELA SUPERIOR DE INGENIEROS INDUSTRIALES;FACULDAD DE CIENCIAS FISICAS";"PT;EL;ES";
12573;EN3S0110;MONITOR;;FP1-ENNONUC 3C;;FP1;MONITORING OF TWO PASSIVE SOLAR HOUSES.;01/06/1987;30/11/1989;;"THE MONITORING OF TWO PASSIVE SOLAR HOUSES OF DIFFERENT TYPE, LATITUDE, CLIMATIC CONDITIONS, URBAN ENVIRONMENT AND BUILDING REGULATIONS IS THE CONCERN OF THIS PROJECT. 

THE FIRST HOUSE IN ATHENS IS A FOUR-STOREY HOUSE OF 210 M2 TOTAL AREA, INCORPORATING A SUNSPACE, TWO TROMBE WALLS AND DIRECT GAIN PASSIVE ELEMENTS. THE SECOND HOUSE IN THERMI, A SUBURB OF THESSALONIKI, IS A TWO STOREY HOUSE OF 200 M2 TOTAL AREA, INCORPORATING A SUNSPACE, TROMBE WALLS AND DIRECT GAIN PASSIVE ELEMENTS. 
WORK ON THE PROJECT HAS STARTED RECENTLY. THE MAIN PREOCCUPATION OF THE INITIAL STAGE WAS THE DESIGN OF THE MONITORING SYSTEM FOR BOTH HOUSES AND THE SELECTION OF THE APPROPRIATE MEASURING EQUIPMENT. THE AVAILABLE BUDGET ALLOWS FOR THE MEASUREMENT OF THE FOLLOWING PHYSICAL QUANTITIES: SOLAR RADIATION, WIND VELOCITY AND DIRECTION, EXTERNAL AND INTERNAL AIR TEMPERATURE AND HUMIDITY, AUXILIARY HEATING, HOT WATER AND ELECTRICITY CONSUMPTION AND HEAT FLUX TO ADJACENT BUILDINGS AND TO GROUND. THE MEASURED DATA WILL BE COLLECTED AND PROCESSED BY A DATA LOGGER. SPOT HEAT FLUX AND THERMOGRAPHIC MEASUREMENTS, (WHICH WILL BE PERFOMED IN THESE HOUSES IN THE FRAMEWORK OF ANOTHER PROJECT) WILL ENHANCE THE DATA AND THE ASSOCIATED QUALITY OF RESULTS. DUE TO THE LIMITED BUDGET, THE MEASURING EQUIPMENT WILL BE USED SUCCESSIVELY FOR BOTH HOUSES. 
THIS POSES THE CHALLENGE TO PRODUCE SUFFICIENT RESULTS IN THE AVAILABLE TIME OF THE PROJECT (ABOUT TWO YEARS) BY USING ESSENTIALLY THE SAME MEASURING EQUIPMENT IN HOUSES OF DIFFERENT TYPE AND CHARACTER. IT IS BELIEVED THAT THIS EFFORT WILL ALSO CONTRIBUTE TO THE DISCUSSION FOR DEVELOPING THE HIGHLY NEEDED TRAVELING LABORATORY FOR RAPID THERMAL CALIBRATION OF HOUSES. 
THE PAPER DISCUSSES THE MERITS AND DRAWBACKS OF THREE METHODS, 'SUBSTRACTIVE METHOD', 'REGRESSION ANALYSIS METHOD' AND 'SIMULATION ANALYSIS METHOD', IN RELATION TO THE SPECIFIC CHARACTER OF THE HOUSES, THE TIME REQUIREMENTS AND THE SELECTED MONITORING SYSTEM. THE METHODS WILL BE USED FOR THE ANALYSIS OF THE ABOVE MENTIONED PHYSICAL QUANTITIES IN ORDER TO GET ANSWERS ON THE THERMAL PERFORMANCE AND COMFORT. NO MATTER OF THE METHOD OF ANALYSIS, GOOD AIR INFILTRATION MEASUREMENTS SEEM TO BE A MAJOR REQUIREMENT IN ORDER TO GET GOOD ANSWERS.";;;;CSC;ARISTOTLE UNIVERSITY OF THESSALONIKI;EL;;;
12628;EN3S0046;OPSYS;;FP1-ENNONUC 3C;;FP1;CONCERTED ACTION FOR SOLAR SYSTEM MODEL DEVELOPMENT AND VALIDATION.;01/06/1986;31/12/1990;;"THE MAIN OBJECTIVES OF THE CONCERTED ACTION INCLUDE TWO MAJOR PARTS: 
- VALIDATION OF SIMULATION MODELS, BASED ON EXPERIMENTAL DATA SEQUENCES OBTAINED FROM AN EARLIER CEC CONCERTED ACTION, THE SOLAR PILOT TEST FACILITIES. 
- DEVELOPMENT OF USER FRIENDLY SOFTWARE PACKAGES FOR PERSONAL COMPUTERS, APPLICABLE TO A VARIETY OF ACTIVE THERMAL SOLAR SYSTEMS FOR THE DESIGN AND PERFORMANCE CALCULATIONS. 

THE VALIDATION OF SIMULATION MODELS IS MAINLY CONCERNED WITH THE SYSTEM ENERGY BALANCES AS AN OVERALL MODEL APPLICABILITY CRITERION FOR ENGINEERING CALCULATIONS. RESULTS OBTAINED, SHOW A SATISFACTORY AGREEMENT BETWEEN SIMULATED AND MEASURED ENERGY FLOWS, FOR SIMULATED SYSTEM CONFIGURATIONS BASED ON USUAL ENGINEERING APPROXIMATIONS AND WHICH HAVE BEEN IMPLEMENTED IN THE SIMULATION PROGRAMS EMGP2 AND EURSOL. 
BESIDES THE SIMULATION PROGRAMS, ALSO SIMPLIFIED CORRELATION METHODS FOR SOLAR WATER HEATERS AND SPACE HEATING ARE DEVELOPED AND A HANDBOOK ON THE USE OF SUCH SIMPLIFIED CORRELATIONS IN SOLAR SYSTEM DESIGN IS PREPARED. THE ILLUSTRATIONS HEREAFTER, GIVE AN IMPRESSION OF SOME FEATURES OF THE INTERACTIVE PROGRAM EURSOL, SHOWING SOME SCREEN DISPLAYS WITH SYSTEM SCHEMES, PART OF THE SYSTEM SELECTION PROCEDURE AND GRAPHICAL OUTPUT OF THE STORAGE TEMPERATURE TIME SEQUENCE DURING THE SIMULATION. THE PROGRAMS ARE SUPPORTED WITH APPROPRIATELY FORMATTED METEOROLOGICAL DATA FILES FOR VARIOUS LOCATIONS IN CEC COUNTRIES, FILES FOR ON-LINE HELP AND DETAILED MANUALS.";;;;CSC;KATHOLIEKE UNIVERSITEIT LEUVEN;BE;"TECHNICAL UNIVERSITY OF DENMARK;TECHNISCH PHYSISCHE DIENST;ASSOCIATION POUR LA RECHERCHE ET LE DEVELOPPEMENT DES METHODES ET PROCESSUS INDUSTRIELS";"DK;NL;FR";
12575;EN3S0112;SUNSAT;;FP1-ENNONUC 3C;;FP1;STATISTICS OF GLOBAL RADIATION OVER EUROPE AND AFRICA COMPUTED FROM DATA OF SATELLITE METEOSAT 2;01/07/1987;30/06/1990;;"Accurate time series on available solar radiation at ground level and its diffuse component are required worldwide for industrial, as well as for scientific, purposes. However, the sparse sampling of the worldwide distribution of ground based measurements does not meet the requirements of the different user groups. The SUNSAT project was initiated to calculate the global radiation and its diffuse component, as well as to handle the statistics from the METEOSAT B2-ISCCP satellite data set. These observations cover the continents of Africa and Europe, the Middle East and wide regions of the Atlantic and Indian Oceans.

An atlas has been produced with results for the time period (1985 to 1986) presented as coloured images, with a spatial resolution of 0.5 degrees by 0.5 degrees, and in the form of tables. The tables contain averages over areas of 2.5 degrees by 2.5 degrees longitude and latitude. To ensure the accuracy of these retrieved solar radiation fields at ground level, a comparison with all available ground based pyranometer measurements was made. The results of the surface measurements and the satellite estimates presented in this atlas coincide well.
DUE TO THE FACT, THAT THE TRANSMITTANCE OF THE ATMOSPHERE AND ITS CLOUDS ARE INVERSELY RELATED TO THE REFLECTANCE FOR SOLAR RADIATION, VALUES OF THE GLOBAL RADIATION AT GROUND CAN BE DETERMINED FROM DIGITAL SATELLITE IMAGES MEASURED IN THE SPECTRAL RANGE OF SOLAR RADIATION. FIRST ESTIMATES HAVE SHOWN THAT MONTHLY AVERAGES OF GLOBAL RADIATION ARE ACCURATE WITHIN 8 TO 9%. 

WITHIN THE PROJECT SUNSAT, THE GLOBAL RADIATION REACHING EUROPE AND AFRICA WILL BE DETERMINED FOR A PERIOD OF 2 COMPLETE YEARS (JAN.1985 - DEC.1986) FROM THE ROUTINELY COLLECTED 3-HOURLY LOW SPATIAL RESOLUTION (30-50 KM) METEOSAT 2 ISCCP DATA SET. THE 1/2-HOURLY HIGH RESOLUTION (2.5-5.0 KM) METEOSAT 2 DATA WILL BE USED TO DETERMINE THE GLOBAL RADIATION OVER THE RESTRICTED AREA OF THE SAHEL ZONE FOR JUNE AND DECEMBER 1985 AND 1986. ADDITIONALLY, FOR GROUND TRUTH COMPARISON, AS MANY AS POSSIBLE PYRANOMETER MEASUREMENTS MADE OVER THE AFRICAN CONTINENT DURING 1985 TO 1986 WILL BE COLLECTED. 
THE FIRST YEAR OF DATA IS NOW PROCESSED AND PRELIMINARY ESTIMATES OF THE GLOBAL RADIATION ARE DISTRIBUTED AMONG THE SUNSAT MEMBERS. AFTER FINAL QUALITY CONTROL MAPS OF GLOBAL RADIATION WRITTEN ON 1600 BPI CCTS WILL BE AVAILABLE ON REQUEST AT THE UNIVERSITY OF KOLN.";;;;CSC;Universität Köln;DE;"Wageningen Agricultural University;INSTITUTO DE ENERGIAS RENOVABLES;SODETEC;École Nationale Supérieure des Mines de Paris";"NL;ES;FR";
8566;1581;ADVICE;;FP1-ESPRIT 1;;FP1;Automatic Design Validation of Integrated Circuits Using E-Beam;01/12/1984;01/12/1989;;"The objective of ADVICE was to produce a prototype system capable of automatic error diagnosis of VLSI devices. 
The chosen approach was based on using the observability facilities of Ebeam equipment. 
The objective of ADVICE was to produce a prototype system capable of automatic error diagnosis of very large scale integration (VLSI) devices. The chosen approach was based on using the observability facilities of electron beam equipment. In order to achieve the above, the following was carried out:
interfacing to computer aided design (CAD) software;
pattern recognition for automatically positioning the electron beam;
development of a global methodology to define the diagnostic strategy;
development of new hardware for enhancement of electron beam performance.

The following problems were solved:
computer control of the electron beam system;
identification of circuit elements;
test pattern generation for electron beam debugging;
design for electron beam testability;
electron beam equipment development.
In order to achieve the above, the following was carried out: 
-interfacing to CAD software 
-pattern recognition for automatically positioning the Ebeam 
-development of a global methodology to define the diagnostic strategy 
-development of new hardware for enhancement of Ebeam performance. 
The following problems were solved: 
-computer control of the Ebeam system 
-identification of circuit elements 
-test-pattern generation for electron beam debugging 
-design for electron beam testability 
-electron beam equipment development. 
Exploitation 
 Following the completion of the project, which included the definition and investigation of all aspects for the design and implementation of a fully computer-controlled Ebeam testing system, the three industrial partners have installed systems that are n ow fully operational on their premises. 
Some of the key features already included in the systems are: 
-interfaces between CAD and Ebeam systems 
-pattern recognition 
-hardware and software for computer control. 
The results satisfy all the realistic goals set at the beginning and following the first phase. These results are at least state of the art as exemplified at the various presentations and demonstrations given by the partners. 
The Ebeam design validation and testing technique is a new and very promising one. Its impact and the time horizon for industrial applications depends strongly on the refinement of this or other competing techniques (egscandesign) that may emerge. British Telecom are selling waveform averaging equipment based on one of the results of the project.";;;;;Centro Studi e Laboratori Telecomunicazioni SpA;IT;"TRINITY COLLEGE DUBLIN;Institut National Polytechnique de Grenoble;British Telecom plc (BT);Centre National d'Études des Télécommunications (CNET)";"IE;FR;UK";
6352;RI1B0254;ECOPAVE;;FP1-BRITE;;FP1;THE DEVELOPMENT OF A MULTI-PURPOSE COMPOSITE PAVEMENT SYSTEM;01/10/1988;31/12/1992;;"This project succeeded in developing an economical pavement composite, called Ecopave, and a paving system which incorporates industrial by-products such as fly-ash, products from de-sulphurizing, incinerator residue, recycled building debris, concrete and asphalt. The goals of this research were to reduce the consumption of gravel/stone resources and to protect the environment. The partners report they have met all primary project objectives.
A VARIETY OF CONCRETES AS WELL AS CEMENT TREATED AND BITUMINOUS MATERIALS ARE USED FOR THE CONSTRUCTION OF RIGID OR FLEXIBLE PAVEMENT STRUCTURES. EACH MATERIAL DEMANDS SPECIALIZED TECHNOLOGIES, RESEARCH, EXPERIENCE AND A WIDE RANGE OF PAVING EQUIPMENT. THE OBJECTIVE OF THIS RESEARCH IS TO EXPLOIT THE MOST ADVANTAGEOUS FEATURES OF CONVENTIONAL CONCRETE AND FLEXIBLE PAVING AND TO INTEGRATE THEM INTO A NEW MULTI-PURPOSE COMPOSITE PAVEMENT SYSTEM TO BE CONSTRUCTED WITH PLANTS COMMONLY USED FOR THE CONSTRUCTION OF FLEXIBLE BITUMINOUS PAVEMENTS.
THE ECOPAVE PROJECT AIMS AT BREAKING ACROSS ESTABLISHED DISCIPLINES AND INDUSTRIAL BOUNDARIES TO EXAMINE THE INTEGRATION OF SELECTED MATERIAL CHARACTERISTICS AND CONSTRUCTION METHODS FROM DIFFERENT BACKGROUNDS TO CREATE AN IMPROVED PAVEMENT PRODUCT.

THE POSSIBILITY OF USING SELECTED INDUSTRIAL BY-PRODUCTS SUCH AS FLY ASH, PRODUCTS FROM DE-SULPHURIZING, INCINERATOR RESIDUE, RECYCLED BUILDING DEBRIS, CONCRETE AND ASPHALT WILL BE EXPLORED TO PROTECT THE ENVIRONMENT AND REDUCE THE CONSUMPTION OF GRAVEL/STONE RESOURCES.

ONE SPECIFIC TARGET INVOLVES A WIDENED APPLICATION FOR THE EXISTING CAPITAL INVESTMENT IN RAW MATERIAL PROCESSING PLANT AND PAVING EQUIPMENT. OTHER TARGETS INVOLVE THE IDENTIFICATION OF FURTHER WORK TO REDUCE THE COST OF CONSTRUCTION PLANT AND IMPROVE CONSTRUCTION STANDARDS.

THE ECOPAVE SYSTEM IS EXPECTED TO DEVELOP INTO AN ECONOMICALLY VIABLE ALTERNATIVE TO TRADITIONAL PAVEMENTS OF ROADS AND AIRPORTS, THEREBY REDUCING CONSTRUCTION COSTS BY 20-40 %.";;;;CSC;National Road Laboratory;DK;"Ålborg Portland A/S;Cementation Research Ltd;DANSK BETON TEKNIK A/S;University of Twente";"DK;UK;NL";
8654;1626;PICA;;FP1-ESPRIT 1;;FP1;A High-Compression Picture-Coding Algorithm for Photographic Videotex;01/01/1985;01/01/1988;;"The objective of the PICA project was to produce an efficient compression scheme for photographic images. The algorithm had to be capable of compressing a colour picture to 1 bit/pel or less while retaining good quality, allowing a full-frame videotex picture to be stored in only 32 Kbytes of memory and to be transmitted in 4 seconds on the Integrated Services Digital Network (ISDN). The final goal of the project was to gain acceptance of the algorithm as a standard. 
The objective of the project was to produce an efficient compression scheme for photographic images. The algorithm had to be capable of compressing a colour picture to 1 bit/pixel or less while retaining good quality, allowing a full frame videotex picture to be stored in only 32 Kbytes of memory and to be transmitted in 4 s on the integrated services digital network (ISDN). The final goal of the project was to gain acceptance of the algorithm as a standard.

Innovative compression algorithms were developed and tested and then compared with known ones. Good results were achieved, with compression values meeting, and in some cases exceeding, the target of 1 bit/pel. Following the first year's work, a patent application was made for a new technique for vector quantization. British Telecommunications has been developing a new technique, known as recursive binary nesting, and a patent was filed during the second year.
Innovative compression algorithms were developed and tested and then compared with known ones. Good results were achieved, with compression values meeting, and in some cases exceeding, the target of 1 bit/pel. Following the first year's work, a patent application was made for a new technique for vector quantisation by CSELT. BT has been developing a new technique, known as Recursive Binary Nesting, and a patent was filed during the second year. 
Exploitation 
PICA submitted two compression algorithms to the ISO/CCITT Joint Photographic Experts Group (JPEG) for standardisation and one of them, the ADCT, was ranked first out of 12 during the first evaluation exercise. Early in 1988, the PICA project achieved itsgoal when ISO selected the PICA-ADCT algorithm for development into a standard. 
Excellent results in terms of image quality were achieved using compression ratios of 21:1, and at 16:1 the decoded image is indistinguishable from the original except to the trained eye. At 64:1 the image can still be recognised and could be used, for example, for the quick scanning of photographic archives. The agreed high-compression technique should stimulate the market for photovideotex services in the 1990s.";;;;;British Telecom plc (BT);UK;"SIEMENS-NIXDORF INFORMATIONSSYSTEME AG;PTT RESEARCH TELEMATICA LABORATORIUM;KTAS-KOBENHAVNS TELEFON AKTIESELSKAB;Centre Commun d'Études de Télécommunications et de Télédiffusion (CCETT);Independent Broadcasting Authority (IBA);Centro Studi e Laboratori Telecomunicazioni SpA";"DE;NL;DK;FR;UK;IT";
8464;1133;ISIDE;;FP1-ESPRIT 1;;FP1;Advanced Model for Integration of DB and KB Management Systems;12/05/1986;12/05/1989;;"The objective of ISIDE was to develop an advanced model for integration of data- and knowledge-based management systems. 
The ISIDE team worked on three main tasks: 
-the specification of a knowledge representation formalism 
-the specification of a logical inference formalism 
-the definition of the architecture of an efficient storage and access layer using specialised VLSI hardware (Database machine). 
The objective was to develop an advanced model for integration of database and knowledge based management systems. The project included the specification of a knowledge representation formalism, the specification of a logical inference formalism, and the definition of the architecture of an efficient storage and access layer using specialised very large scale integration (VLSI) hardware. From practical observations, it was concluded that no single universal paradigm would resolve the database programming problems. Instead, both a rule based approach and an object oriented approach, with capabilities to switch from one to the other, were advocated. Both approaches were intensively experimented upon, and prototype support systems demonstrated. An object server, GEODE, with sufficient flexibility to interface with rule based, object oriented and structured query (SQL) lanuguages, was built. On the architecture side, a consolidated draft was developed, emphasising future needs for large capacity core memories, to allow all the information needed during a transaction to be stored in the main memory. MALG, a theoretical algebraic machine, was built over GEODE.
From practical observations of the ARS/AGUSTA Helicopter Maintenance Training System (ITS) and CRIL's Software Engineering Documentation System (CACAO), ISIDE reached the conclusion that no single universal paradigm would resolve the database programming problems. Instead, both a rule-based approach (RDL1) and an object-oriented approach (ODL1/LDR2), with capabilities to switch from one to the other, were advocated. 
Both approaches were intensively experimented upon, and prototype support systems demonstrated. The more mature, RDL1, already has a computational model (Predicate Transition Networks). An object server, GEODE, with sufficient flexibility to interface with rule-based, object-oriented and SQL languages, was built. 
On the architecture side, a consolidated draft was developed, emphasising future needs for large-capacity core memories, to allow all the information needed during a transaction to be stored in the main memory. MALG, a theoretical algebraic machine, was built over GEODE. 
Following performance evaluation studies for the different component systems, demonstrations were given of ITS with RDL1, Performance Evaluation, GEODE, and of ITS alone. 
Exploitation 
Some partners are looking into the possibility of developing a knowledge-based training product within the next two years, based on the RDL1 formalism. 
The results of the ISIDE project constitute the basis forESPRIT II project STRETCH (number 2443).";;;;;Sagem SA;FR;"ARS SpA;Agusta SpA;Conception et Réalisation Industrielle de Logiciel (CRIL);Simulog SA;Institut National de Recherche en Informatique et en Automatique - INRIA";"IT;FR";
8457;1074;KBS-SHIP;;FP1-ESPRIT 1;;FP1;Shipboard Installation of Knowledge-Based Systems;20/03/1986;20/03/1989;;"The objective of KBS-SHIP was to develop design concepts for the implementation of advanced IT systems in ships. 
The project aimed to provide the stimulus for engaging the support of the marine industry for the introduction of KBSs, expected in the early 1990s. It also aimed to assist bridge and engine-room officers in duties ranging from voyage planning to alarm handling, by providing: 
-a framework for the integration of information in ships 
-a decision-support system for the efficient operation of a complex ship by a small crew. 
The viability of the concepts was ensured by building a prototype KBS-SHIP system incorporating a limited number of expert systems. 
The objective was to develop design concepts for the implementation of advanced information technology (IT) systems in ships. The project aimed to provide the stimulus for engaging the support of the marine industry for the introduction of knowledge based systems (KBS). It also aimed to assist bridge and engine room offices in duties ranging from voyage planning to alarm handling, by providing a framework for the integration of information in ships, and a decision support system for the efficient operation of a complex ship by a small crew. The viability of the concepts was ensured by building a prototype system incorporating a limited number of expert systems. The work was structured round four themes. Firstly, the development of the expert voyage pilot EVP in regard both to voyage planning and to route planning. Secondly, the development of a comprehensive design specification for the architecture. Thirdly, the delineation of the scope of the final system in terms of the number and scope of individual subsystems. The maintenance expert system was defined as a causal model and includes the checking and monitoring of sensors. Cost functions were introduced for optimization calculations, and numerical algorithms were combined with rules. Lastly, the preparation of requirement specifications and outline design specifications for a number of expert systems for use on later work.
In the first project definition phase, the onboard information flow was described and a limited bench model of an expert subsystem - the Expert Voyage Pilot (EVP) - was built. 
In the second phase, the status of the work, which was structured round four themes, was as follows: 
 -The development of the EVP in regard both to voyage planning and to route planning. An Atlantic crossing scenario was prepared, and a change from Prolog to LISP for later inclusion in the THOR shell of STL (a product resulting from project 96) was made. -The development of a comprehensive design specification for the KBS-SHIP architecture; specification prototyping was finished in October 1988. 
 -The delineation of the scope of the final KBS-SHIP system in terms of the number and scope of individual subsystems - the maintenance expert system was defined as a causal model and includes the checking and monitoring of sensors. Cost functions were in troduced for optimisation calculations, and numerical algorithms were combined with rules. 
-The preparation of requirement specifications and outline design specifications for a number of expert systems within the KBS-SHIP for use in later work. 
Exploitation 
 The work provided the basis for two products: an expert system for navigation - the Voyage Pilot Expert System - is to be developed into a product by Krupp-Atlas Electronik, and an expert system for machinery operation is to be developed by Sren T. Lyngs . 
The study of the development of an acceptance procedure for expert systems onboard ship being made by Lloyd's Register is one of the several ways in which the project is encouraging the acceptance of AI technology by the European marine industry. The project is also expected to influence international standards for local area networks onboard ship as well as the design of maritime surveillance and control equipment. 
The results of KBS-SHIP have been incorporated in ESPRIT II project 2163.";;;;;DANISH MARITIME INSTITUTE;DK;"NATIONAL TECHNICAL UNIVERSITY ATHENS;THE EAST ASIATIC COMPANY LTD;SOREN T.LYNGSOE A/S;SOFT INTERNATIONAL BV;Lloyds Register of Shipping;Krupp Atlas Elektronik GmbH";"EL;DK;NL;UK;DE";
8470;1262;SFINX;;FP1-ESPRIT 1;;FP1;Software Factory Integration and Experimentation;01/09/1986;01/09/1991;;"The main objective of the SFINX project was to contribute to the emergence of an advanced software engineering environment identified as PCTE-based software factories. It intends to provide the software factory builders with the appropriate support in terms of methodology, mechanisms and tools for selecting and integrating software factory components according to the specific needs and characteristics of their organisations. 
Specific objectives were to: 
-verify and promote the usability and availability of PCTE as basis for software factory implementation 
-derive, from practical experimentation, mechanisms allowing the integration of already existing tools in a software factory 
-establish a basis for tool analysis and characterisation. 
The main objective of the project was to contribute to the emergence of an advanced software engineering environment identified as portable common tool environment (PCTE) based software factories. it intended to provide the software factory builders with the appropriate support in terms of methodology, mechanisms and tools for selecting and integrating software factory components according to the specific needs and characteristics of their organizations. A reference model of a software factory was defined, and contacts established with other organizations working in the same software factory field. During the second phase, the project has worked on the technical aspects of a PCTE based software factory and on the corresponding activities of the software factory building process, namely tool characterization and integration, and PCTE evaluation and promotion. It has developed a tool questionnaire, tool classification schemes and a parser/tracer supporting the analysis and the evaluation of the use that a tool makes of its environment. It has also developed and experimented integration techniques and mechanisms focusing on the data integration aspect. Documents and training courses have been produced to ensure the promotion and dissemination of the software factory and PCTE concepts. During the third and final phase, more emphasis was given to the organizational aspects of a software factory and to the design phase of the software factory building process. The project has developed a guide for designing a software factory and has identified mechanisms and tools which should supply the software factory builder with the appropriate and necessary support. These include at the strategic planning level, a decision map; at the modelling level, predefined process models, rules and tools for selecting and customising them and to support the definition of the software factory meta base; and at the tool selection level, a qualification system.
The one-year definition phase aimed to demonstrate the feasibility of SFINX's objectives and to establish the technical basis necessary to achieve them. A reference model of a software factory was defined, and contacts established with other organisationsworking in the same software factory field (ISF of Alvey, and EAST and ESF of EUREKA). 
During the second (two-year) phase, the project has worked on the technical aspects of a PCTE-based software factory and on the corresponding activities of the software factory building process, namely tool characterisation and integration, and PCTE evaluation and promotion. It has developed a tool questionnaire, tool classification schemes and a parser/tracer supporting the analysis and the evaluation of the use that a tool makes of its environment. It has also developed and experimented integration techniques and mechanisms focusing on the data integration aspect. Documents and training courses have been produced to ensure the promotion and dissemination of the software factory and PCTE concepts. 
During the third and final phase, more emphasis was given to the organisational aspects of a software factory and to the design phase of the software factory building process. The project has developed a guide for designing a software factory and has identified mechanisms and tools which should supply the software factory builder with the appropriate and necessary support: 
-at the strategic planning level: a decision map 
-at the modelling level: predefined process models, rules and tools for selecting and customising them and to support the definition of the software factory meta base 
-at the tool selection level: a qualification system. 
Exploitation 
The SFINX project played an important part in the PCTE initiative. It has contributed to the enforcement of the PCTE concept as a European standard for tool development and as a backbone of integrated software engineering environments. SFINX has completed its contribution to the dissemination of European integrated environments by concentrating on the problem of software factory design and Installation whose complexity has appeared as a difficult barrier to overcome for non-expert users and as slowing dow n the acceptance of PCTE-based environments.";;;;;Société Française de Génie Logiciel SA;FR;"Tecnopolis Csata Novus Ortus;ERITEL S.A.;CRI A/S;Sema Group plc";"IT;ES;DK;UK";
8660;1630;OSSAD;;FP1-ESPRIT 1;;FP1;Office Support Systems Analysis and Design;01/01/1985;01/05/1989;;"The overall aim of OSSAD was to develop, implement and validate a problem-oriented office system analysis and design methodology using a formal office language to help users and manufacturers to specify and implement a computer-based Office Support System(OSS) and to meet the needs of end-users and organisations. More specific objectives were to: 
-obtain a formal and unambiguous description of office work, comprehensible not only to analysts and designers but also to office managers, so that they could validate it and suggest modifications and solutions 
-relate office descriptions to relevant organisation performance criteria and help evaluate office work 
-validate this description in real office environments by evaluating and improving it on the basis of field studies 
-specify requirements of office support systems with respect to the user, the organisation and the technical solution, based on empirical findings in existing offices. 
The overall aim of office support systems analysis and design (OSSAD) was to develop, implement and validate a problem oriented office system analysis and design methodology using a formal office language to help users and manufacturers to specify and implement a computer based office support system (OSS) and to meet the needs of end users organizations.

The achievements of the project were as follows:
development of different methods for office analysis (eg, office functions analysis) based on the OSSAD model, which included abstract, descriptive and specification layers;
development of a glossary of terms to describe office work and development of a graphical mapping of formal office language;
validation of the abstract and descriptive model and the related data collection instruments;
which production of and OSSAD manual which consists of a description of the models and a presentation of the language, and covers the whole process of reorganizing an office support system involving contract setting, situation analysis, system design, implement changes and monitor system performance (this manual supports the project management process and can be used to tailor data collection instruments to the needs of specific users and organizations);
testing of the design methodology in field studies (the findings are included in the final OSSAD manual).
The achievements of the OSSAD project were as follows: 
-Development of different methods for office analysis (eg office functions analysis) based on the OSSAD model, which includes abstract, descriptive and specification layers. 
-A glossary of terms to describe office work was developed, and a graphical mapping of formal office language specified. 
-The abstract and descriptive model and the related data collection instruments were validated in field studies in banks in France, Italy and Germany. 
 -An OSSAD manual is available. It consists of a description of the models and a presentation of the language, and covers the whole process of reorganising an office support system (set contract, analyse situation, design system, implement changes, monito r system performance). This manual supports the project management process and can be used to tailor data collection instruments to the needs of specific users and organisations. 
-The design methodology was tested in field studies and the findings included in the final OSSAD manual and in the field test report. 
Exploitation 
 The OSSAD methodology has been sold to over 10 projects and used to solve particular problems or implement overall methodologies in organisations needing a framework for future investigations into and improvements of office work. OSSAD is also being used in university training courses. A spin-off product, OrgSolution, is also available. This tool supports the OSSAD methodology in helping the analysis and restructuring of office work.";;;;;Institut für Organisationsforschung und Technologieanwendung;DE;"Università degli Studi di Milano;Ipachi Istituto per l'Automazione delle Casse di Risparmio;CENTRE D'ETUDES DU MANAGEMENT";"IT;FR";
8312;1456;PAQO;;FP1-ESPRIT 1;;FP1;Plant Availability and Quality Optimisation;01/01/1985;01/01/1989;;"The objective of this project was to develop technology for the efficient integration of process and machine monitoring and diagnostics with the control of discrete parts manufacturing plants at the machine and cell level. It aimed to provide such plants with a degree of fault tolerance through improved control during abnormal or fault conditions, thus maximising plant availability, product quality and operational safety.
The objective of this project was to develop technology for the efficient integration of process and machine monitoring and diagnostics with the control of discrete parts manufacturing plants at the machine and cell level. It aimed to provide such plants with a degree of fault tolerance through improved control during abnormal or fault conditions, thus maximizing plant availability, product quality and operational safety.
An early demonstration of the methodology was made during 1986 using a stand alone milling machine. This was fitted with various sensors, including a unique tactile machine spindle which was designed and built by the consortium. Real time model based diagnostics of the cutting process, as well as of the machine drives, was demonstrated, together with a net based software tool permitting the application of expert knowledge to machine surveillance and action planning. A full scale demonstration of an integrated fault tolerant control system operating with a flexible machining cell was achieved to conclude to project in December 1988. This included the use of a prototype modular data acquisition and analysis computer which has now been commercially exploited. The system operated through a local area network. Cell control was coordinated by an expert cell controller operating on a personal computer (PC).
An early demonstration of the methodology was made during 1986 using a stand-alone milling machine. This was fitted with various sensors, including a unique 'tactile' machine spindle which was designed and built by the consortium. Real-time model-based diagnostics of the cutting process, as well as of the machine drives, was demonstrated, together with a net-based software tool permitting the application of expert knowledge to machine surveillance and action planning. 
A full-scale demonstration of an integrated fault-tolerant control system operating with a flexible machining cell based in Spain was achieved to conclude the project in December 1988. This included the use of a prototype modular data acquisition and anal ysis computer, designed and built by the consortium, which has now been commercially exploited at other sites. The system operated through a local area network developed by the Spanish partners; cell control was coordinated by an 'Expert' cell controller operating on a PC. 
Exploitation 
Automated monitoring and diagnostics integrated with machine or cell control offers financial benefits due to the reduction in waste, lesser machine damage, and increased productivity through higher machine availability and more efficient rescheduling.Commercial exploitation of the computer hardware and software in the area of real-time process surveillance and diagnostics, and also of the system integration tools, is well advanced.";;;;;Stewart Hughes Ltd;UK;"Technische Hochschule Darmstadt;Ikerlan;Advanced Manufacturing Technology Research Institute (AMTRI);DANOBAT SA COOP;Gesellschaft für Anlagen- und Reaktorsicherheit mbH;Battelle-Institut eV;Association pour le Développement de l'Enseignement et de la Recherche en Système Appliqué";"DE;ES;UK;FR";
8634;878;PROMINAND;;FP1-ESPRIT 1;;FP1;Extended Office Process Migration with Interactive Panel Displays;20/12/1985;20/12/1990;;"PROMINAND is an integrated approach for supporting cooperative office work. The approach was based on a concept of office worker-influenced migration of office processes and a novel panel display device. A supportive human factors analysis and evaluation to optimise office worker satisfaction was also carried out. 
The extended office process migration with interactive panel displays' (PROMINAND) migration system (MS) supports cooperation between office workers by controlling the migration of office processes through an organization. A typical office process consists of steps which are performed in parallel or sequentially. It is represented by an electronic circulation folder (ECF), which can be opened and closed, onto which a folder slip can be put, into which appendices can be added, and so on. The MS controls ECF circulation to office workers playing office roles by taking into account both organizational structures and organizational rules for dealing with office tasks. Control covers both the formally described circulation of ECFs and the handling of exceptions.

The flow of work is the one aspect of office tasks; the other side is the intrinsic work to be performed, divided into steps. The MS supports this work by the automatic invocation of appropriate application dependent programs which are referred to in a migration sepcification. PROMINAND's interactive panel device (IPD) is a computer controlled novel electronic device which consists of a set of building blocks comprising intelligent display and feedback elements. At any time these elements can be manually placed on and removed from a modular board of any size. The panel device can be used for the entry of a range of different kinds of plans or their modification by a computer as well as for the representation of computer generated or controlled plans. PROMINAND's evaluation, covering the 2 new technologies, was developed as part of the project's design phase. Concepts for a help and training facility were developed as part of the work.
PROMINAND's Migration System (MS) supports cooperation between office workers by controlling the migration of office processes through an organisation. A typical office process consists of steps which are performed in parallel or sequentially. It is represented by an Electronic Circulation Folder (ECF), which can be opened and closed, onto which a folder slip can be put, into which appendices can be added, and so on. The MS controls ECF circulation to office workers playing office roles by taking into account both organisational structures and organisational rules for dealing with office tasks. Control covers both the formally described circulation of ECFs and the handling of exceptions, which come into play because of non-deterministic human behaviour an d individual working styles. The flow of work is the one aspect of office tasks; the other side is the intrinsic work to be performed, divided into steps. The MS supports this work by the automatic invocation of appropriate application-dependent programs w ich are referred to in a migration specification. 
PROMINAND's Interactive Panel Device (IPD) is a novel electronic device. It is computer-controlled, and consists of a set of building blocks comprising intelligent display and feedback elements. At any time these elements can be manually placed on and removed from a modular board of any size. The panel device can be used for the entry of a range of different kinds of plans or their modification by a computer as well as for the representation of computer-generated or controlled plans. 
PROMINAND's evaluation, covering the two new technologies, was developed as part of the project's design phase. Concepts for a help and training facility were developed as part of the work. 
 PROMINAND was demonstrated for the first time at the 1988 ESPRIT Conference. Further demonstrations at the 1989 ESPRIT Conference and Systems'89, and presentations at conferences on office systems, have proven that the MS addresses the real needs of offi ce workers. The full system was developed and implemented as a demonstrator in 1990. It can be ported to systems which offer multi-tasking and windows.";;;;;IABG Industrieanlagen Betriebsgesellschaft mbH;DE;"RISO NATIONAL LABORATORY;MODULEX A/S;SCAITECH A/S;Technische Universitaet Muenchen";"DK;DE";
8549;802;CVS;;FP1-ESPRIT 1;;FP1;CAD for VLSI Systems;01/03/1986;01/03/1991;;"The objective of the CVS project was to implement an integrated CAD system capable of coping with the needs of the 1990s, where improvements in semiconductor technology will allow the production of chips with about 1million transistors. Such a CAD system must lead to a factor of 10improvement in design time, based on novel tools for the automatic construction of designs at the level of system architecture, achieved by interconnecting cells representing parts of the total system which have themselves been constructed automatically from a set of given parameters. 
The areas of work included architecture synthesis, digital cell building, analogue cell design, integration of tools and design of demonstration chips. 
The objective of the CVS project was to implement an integrated computer aided design (CAD) system capable of coping with the needs of the 1990s, where improvements in semiconductor technology will allow the production of chips with about 1 million transistors. Such a CAD system must lead to a factor of 10 improvement in design time, based on novel tools for the automatic construction of designs at the level of system architecture, achieved by interconnecting cells representing parts of the total system which have themselves been constructed automatically from a set of given parameters. The areas of work included architecture synthesis, digital cell building, analogue cell design, integration of tools and design of demonstration chips. During the first 30 months of the project the design and first implementation of the tools were completed, and final prototype tools were available. In order to demonstrate the effectiveness of the tools developed in the project, an ambitious demonstrator chip has been selected. This is an advanced signal processing very large scale integrated (VLSI) forming part of a new mobile telephone receiver. The overall system design of this chip has now been completed, and its implementation and test using the CVS system is currently in hand.
The operating environment is as follows :
Computer aided design (CAD) and design methodologies
The first prototypes of tools were delivered at the end of 1989. 
 During the first 30months of the project the design and first implementation of the tools were completed, and final prototype tools were available in March 1990. In order to demonstrate the effectiveness of the tools developed in the project, an ambitiou s demonstrator chip has been selected. This is an advanced signal-processing VLSI forming part of a new mobile telephone receiver. The overall system design of this chip has now been completed, and its implementation and test using the CVS system is currently in hand. 
Exploitation 
 Such a CAD system is expected to lead to the required factor of 10improvement in design time. For chips which will not be sold in very large numbers, rapid and accurate design is of the utmost importance. The techniques of automatic construction of the d esigns, both at the architectural level and for analogue cell design, should be important elements in achieving this aim. 
 In order to have maximum impact on industry in general, in addition to internal use by the partners, it was agreed that the resulting software will be made available to third parties (eg software houses) for the marketing of the results. Several European SME CAD vendor companies are offering products arising from the CVS project aimed at various niche markets.";;;;;Centro Studi e Laboratori Telecomunicazioni SpA;IT;"MATRA-MHS;Gesellschaft für Mathematik und Datenverarbeitung mbH;Thomson Microelectronics Srl (SGS);Alcatel TITN;Italtel Società Italiana Telecomunicazioni SpA;British Telecom plc (BT);Daimler-Benz AG;Centre National d'Études des Télécommunications (CNET)";"FR;DE;IT;UK";
8635;870;TALON;;FP1-ESPRIT 1;;FP1;Testing and Analysis of Local Area Optical Networks;01/07/1986;01/07/1989;;"Many of the established methods known at the beginning of the project for testing point-to-point optical fibre links were ineffective when applied to complex topologies. The objectives of TALON were to improve this situation by investigating methods and, if possible, specifying instruments. 
Many of the established methods known at the beginning of the project for testing point to point optical fibre links were ineffective when applied to complex topologies. The objectives of testing and analysis of local area optical networks (TALON) were to improve this situation by investigating methods and, if possible, specifying instruments.

A multifunction tester, based on optical fibre domain reflectometry (OFDR) techniques, was successfully designed, built and tested. The principle was proven and the applicability of this technique to local area networks (LAN) with complex topologies was evaluated.
A multi-function tester, based on OFDR techniques, was successfully designed, built and tested. The principle was proven and the applicability of this technique to LANs with complex topologies was evaluated.";;;;;Cossor Electronics Ltd;UK;NKT ELEKTRONIK;DK;
11778;FI1W0041;PACOMA;;FP1-RADWASTOM 3C;;FP1;PERFORMANCE ASSESSMENT OF CONFINEMENTS FOR MLW AND ALPHA WASTE;01/10/1986;31/12/1989;;"THE OVERALL OBJECTIVES OF THE UK CONTRIBUTION TO THE PACOMA PROJECT ARE TO DEVELOP AND DEMONSTRATE PROCEDURES FOR ASSESSING THE RADIOLOGICAL IMPACT OF DISPOSAL OF INTERMEDIATE LEVEL WASTE IN A DEEP REPOSITORY LOCATED IN A CLAY FORMATION. THE HYPOTHETICAL REPOSITORY CONSIDERED IS ASSUMMED TO BE AT HARWELL IN OXFORDSHIRE. THE RESEARCH IS CO-ORDINATED BY THE UK DEPARTMENT OF ENVIRONMENT AND CEC AND IS BEING CARRIED OUT BY FOUR ORGANISATIONS :  
NATIONAL RADIOLOGICAL PROTECTION BOARD (NRPB) 
THEORETICAL PHYSICS DIVISION, UKAEA HARWELL LABORATORY 
ELECTROWATT ENGINEERING LTD 
PRINCIPIA MECHANICA 
THE NRPB WORK IS IN TWO PHASES. THE OBJECTIVES IS PHASE I ARE TO ESTABLISH A DETAILED METHODOLOGY FOR THE ASSESSMENT, TO COLLECT DATA FOR BIOSPHERE MODELLING AND TO CARRY OUT PRELIMNINARY CALCULATIONS. IN PHASE II THE AIM IS TO CARRY OUT THE ASSESSMENT, USING INFORMATION PROVIDED BY OTHER UK CONTRACTORS AND IN CONSULTATION WITH OTHER PARTICIPANTS IN PACOMA, PARTICULARLY CEN/SCK. 

B.1. ADAPTATION OF PAGIS METHODOLOGY FOR USE IN THE ASSESSMENT OF INTERMEDIATE LEVEL WASTE DISPOSAL, IDENTIFICATION OF RADIONUCLIDE RELEASE SCENARIOS. 
B.2. REVIEW OF AVAILABLE BIOSPHERE DATA, AND PRELIMINARY CALCULATIONS FOR TYPICAL RELEASES. 
B.3. DETAILED PLANNING OF CALCULATIONS TO BE CARRIED OUT IN THE FULL ASSESSMENT, FINALISING BIOSPHERE DATA AND ASSUMPTIONS FOR EACH SCENARIO. 
B.4. BEST ESTIMATES OF DOSES AND RISKS TO INDIVIDUALS AND POPULATIONS FOR EACH SCENARIO.  
B.5. SENSITIVITY AND UNCERTAINTY CALCULATIONS. 
B.6. CO-ORDINATION OF FINAL JOINT REPORT OF THE ASSESSMENT.";;;;CSC;NATIONAL RADIOLOGICAL PROTECTION BOARD;UK;;;
8476;1526;PAVE;;FP1-ESPRIT 1;;FP1;PCTE and VMS Environment;03/11/1986;03/11/1989;;"The aim of the PAVE project was to encourage existing VAX/VMS users to use the PCTE, thereby increasing the acceptance of the PCTE as a standard in Europe. 
The main objective is to develop a number of software components, each completing a usable system, with the following functions: 
-to give access to a PCTE workstation from industry-standard DEC-compatible terminals 
-to allow remote usage of VAX/VMS disk storage by a PCTE workstation 
-to give efficient access to PCTE OMS objects stored on VAX/VMS-disks 
-to provide direct access to PCTE tools for users of VAX/VMS-based systems 
-to port the PCTE/PACT tools into a VAX/VMS environment. 
This project was associated with projects 1252 (AMADEUS), 1262 (SFINX) and 1283 (VIP).
The aim of the project was to encourage existing VAX/VMS users to use the portable common tool environment (PCTE), thereby increasing the acceptance of the PCTE as a standard in Europe. The main objective was to develop a number of software components, each completing a usable system, with the following functions: to give access to a PCTE workstation from industry standard DEC compatible terminals; to allow remote usage of VAX/VMS disk storage by a PCTE workstation; to give efficient access to PCTE object modelling system (OMS) objects stored on VAX/VMS disks; to provide direct access to PCTE tools for users of VAX/VMS based systems; to port the PCTE/PACT tools into a VAX/VMS environment. The project studied how VAX storage could be used in the PCTE environment, and this was done by dedicating a VAX virtual volume to a nonVAX PCTE workstation. Access was implemented to this virtual volume. An implementation of PCTE on a VAX station was made. This enabled cross access of information between VMS and PCTE.
The project team studied how VAX storage could be used in the PCTE environment, and chose to do this by dedicating a VAX virtual volume to a non-VAX PCTE workstation. The team implemented access to this virtual volume. 
An implementation of PCTE on a VAX station was made. This enables cross access of information between VMS and PCTE. 
Exploitation 
This project will pave the way to the PCTE for VAX/VMS users and allow PCTE workstations to interwork with a VAX/VMS environment, enlarging the domain of application of PCTE in the information technology community.";;;;;GEC Software Ltd;UK;SYSECA SA;FR;
8439;951;PACT;;FP1-ESPRIT 1;;FP1;PCTE-Added Common Tools;17/02/1986;17/02/1989;;"The objective of PACT was the development and documentation of a toolset for PCTE (project 32). This implementation of a layer of functionalities above PCTE's basic mechanisms will provide the tool developer with a higher level interface to PCTE. The project was conducted in close collaboration with the PCTE project. 
The prototype version was to include: 
-tools for data definition and data query 
-tools for environment administration 
-document preparation tools 
-communication facilities (user/user and gateways) 
-support for C, Pascal, Lisp and Prolog 
-configuration management tools. 
The objective was the development and documentation of a toolset for the portable common tool environment (PCTE). This implementation of a layer of functionalities above PCTE's basic mechanisms will provide the tool developer with a higher level interface to PCTE. The toolset consists mainly of the following tools which have been adapted or ported: shell; basic object management system tools; data definition language interpreter; general text editor; Pascal and C compliers; linkers and debuggers; general text formatter; system administration tools; and basic archiving and backup tools. More basic work on the design and development of tools supporting advanced features was undertaken, especially in the following critical areas: object management system (design of advanced data definition, query and manipulation tools); dialogue management (definition of a model and an accompanying formalism to describe the interactions between any tool and a user); and common services (construction of a functional level offering well defined language interfaces exploitable by tools).
The initial toolset is now available on top of PCTE. It consists mainly of the following tools which have been adapted or ported: shell; basic object management system tools; data definition language interpreter; general text editor; Pascal and C compiler, linker and debugger; general text formatter; system administration tools; and basic archiving and back-up tools. 
More basic work on the design and development of tools supporting advanced features was undertaken, especially in the following critical areas: 
-object management system: design of advanced data definition, query and manipulation tools 
-dialogue management: definition of a model and an accompanying formalism to describe the interactions between any tool and a user 
-common services: construction of a functional level offering well-defined language interfaces exploitable by tools; this will form the basic layer for the integration of future tools. 
Exploitation 
PACT has a range of tools running on Bull and Sun computers, and a PACT toolset contributes to the EUREKA EAST development of PACT-based products. 
The partners provided a complete general-purpose environment in 1989. This environment will support tools developed by other projects and widen the use and acceptance of PCTE.";;;;;Bull SA;FR;"Ingegneria C. Olivetti and C. SpA;International Computers Ltd (ICL);EUROSOFT SYSTEMS SA;S & M Advanced Technologies;SYSECA SA;Siemens Nixdorf Informationssysteme AG";"IT;UK;FR;DE";
8398;1485;SEDOS;;FP1-ESPRIT 1;;FP1;Software Environment for the Design of Open Distributed Systems;01/11/1984;01/11/1987;;"The objective of the SEDOS project was to define formal description techniques and support tools for the development and implementation of OSI protocols and services and, more generally, of open distributed systems. 
Two formal languages were defined: ESTELLE (based on a machine-state model), and LOTOS, which combines the algebraic specification language ACT-ONE and the CCS calculus. 
The objective of the project was to define formal description techniques and support tools for the development and implementation of open system interconnection (OSI) protocols and services and, more generally, of open distributed systems. Two formal languages were defined: ESTELLE (based on a machine-state model), and LOTOS, which combines the algebraic specification language ACT-ONE and the calculus of communicating systems (CCS). Prototypes of syntax directed editors, compilers, simulators, debugging tools, and verification (proof) tools for both ESTELLE and LOTOS were produced. Formal descriptions of a large number of OSI protocols and services were presented. Work in International Standards Organization (ISO) on standardisation of the formal description techniques (FDT) resulted in both languages attaining draft international standard. New theories for verification of protocol specifications were presented.
The results were: 
-Prototypes of syntax-directed editors, compilers, simulators, debugging tools, and verification (proof) tools for both ESTELLE and LOTOS. 
-Formal descriptions of a large number of OSI protocols and services. 
-Work in ISO on standardisation of the FDT (Formal Description Techniques), resulting in both languages attaining draft international standard. This resulted in an international standard in 1988. 
-New theories for verification of protocol specifications. 
A follow-up project (1265) has developed an ESTELLE workstation, and will use some real life projects in an industrial environment to demonstrate the benefit of the SEDOS approach towards protocol development. 
Exploitation 
There is a strong commitment to exploit the results of the LOTOS part of the project. Through the contribution of this project, formalisation of the development of protocols and communication software is becoming one of the most important approaches for industry to develop the increasingly complex distributed systems of tomorrow.";;;;;CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE;FR;"Agence de l'Informatique;UNIVERSITEIT VAN TWENTE;Politecnico di Milano;Bull SA";"FR;NL;IT";
12642;EN3S0034;PASSYS;;FP1-ENNONUC 3C;;FP1;COORDINATION PROJECT PASSYS;01/04/1986;30/06/1989;;"THE PROJECT PASSYS IS A EUROPEAN CONCERTED ACTION IN THE FIELD OF PASSIVE SOLAR COMPONENT AND SYSTEM TESTING. IT HAS BEEN INITIATED BY THE CEC IN THE FRAME OF ITS SOLAR ENERGY R&D PROGRAMME. THE GENERAL OBJECTIVES OF PASSYS ARE THE FOLLOWING: 
. INCREASE CONFIDENCE IN PASSIVE SOLAR SIMULATION MODELS AND DESIGN TOOLS 
. DEVELOP RELIABLE AND AFFORDABLE TEST PROCEDURES FOR PASSIVE SOLAR COMPONENTS AND SYSTEMS. 
SEVEN EUROPEAN TEAMS AND THE JRC ISPRA WILL ERECT NATIONAL TEST CENTRES COMPOSED OF A NUMBER OF HIGHLY STANDARDIZED OUTDOOR PASSIVE SOLAR TEST CELLS DESIGNED BY DFVLR (GERMANY) TO PROVIDE A REALISTIC AND CLEARLY DEFINABLE TEST ENVIRONMENT. 
THE ESP SIMULATION CODE DEVELOPED BY ABACUS (UK) WILL BE USED AS A REFERENCE BY ALL TEAMS. 
DIFFERENT METHODOLOGIES WILL BE DEFINED AND COMPARED, RANGING FROM COMPARATIVE PERFORMANCE INDECES METHODS TO IDENTIFICATION TECHNIQUES.";;;;CSC;ASSOCIATION POUR LA RECHERCHE ET LE DEVELOPPEMENT DES METHODES ET PROCESSUS INDUSTRIELS;FR;"University of Strathclyde;Deutsche Forschungsanstalt für Luft- und Raumfahrt eV (DLR)";"UK;DE";
8411;1493;GENEDIS;;FP1-ESPRIT 1;;FP1;Real-Time Generation and Display of 2.5-D Sketches for Moving Scenes;01/02/1985;01/02/1988;;"The GENEDIS project aimed to develop and implement a demonstrator prototype of an imaging system which is capable of producing a form of 2.5-D sketch directly. This sketch, in which image intensity was to be related to range, was intended to be in one-to-one pixel correspondence with an illumination intensity representation generated simultaneously. Statistical operations performed on successive range estimates were expected to show a marked improvement over the single measure resolution. 
The project aimed to develop and implement a demonstrator prototype of an imaging system capable of producing a form of 2.5 dimensional sketch directly. At the conclusion of the project conception phase, it was decided that the system should be composed of 4 parts: 2 cameras arranged to deliver 2 images of the same scene; 2 feature extractors for extraction of relevant features in both images (an edge-based stereopsis approach based on the Moravec operator was chosen); a correlator, based on dynamic programming, which detected the corresponding features in both images and computed the range of the imaged point in the viewfield from their disparity; and an interpolator, which interpolated range from the ranges delivered by the correlator, and allowed determination of the range of all the points in the viewfield. A successful demonstration of the integrated system (except the interpolator) was presented. The 3 main components, the aligned twin cameras, the real time edge extractors, and the pipeline real time correlator could be reused in a variety of systems for pattern recognition purposes. A breakthrough in the speed of measurement of scene depth matched the pace of interpretation to changes in the scene from stereo images. Real time applications, such as the identification of grasp points for robots, are now possible.
At the conclusion of the project conception phase, it was decided that the system should be composed of four parts: 
-two cameras arranged to deliver two images of the same scene 
-two feature extractors for extraction of relevant features in both images (an edge-based stereopsis approach based on the Moravec operator was chosen) 
-a correlator, based on dynamic programming, which detected the corresponding features in both images and computed the range of the imaged point in the viewfield from their disparity 
-an interpolator, which interpolated range from the ranges delivered by the correlator, and allowed determination of the range of all the points in the viewfield. 
As the result of the first phase of the project, a successful demonstration of the integrated system (except the interpolator) was presented. The three main components, the aligned twin cameras, the real-time edge extractors, and the pipeline real-time correlator are attractive features that might be reused in a variety of systems for pattern recognition purposes. 
A breakthrough in the speed of measurement of scene depth matched the pace of interpretation to changes in the scene from stereo images. Real-time applications, such as the identification of grasp points for robots, are now possible. 
Exploitation 
A prototype of a low-priced system to deliver range images for industrial scenes is under development. The expected performances are 2 mm error at 1 metre for a 512 x 512 pixels image for a system working at video rate and 1.3 mm of lateral resolution. Atthe moment no similar low-priced system exists on the market. Further developments to upgrade the system for image processing will be necessary prior to industrialisation.";;;;;University of Strathclyde;UK;"Barr and Stroud Ltd;Zeltron SpA";"UK;IT";
8409;867;ARTS-IP;;FP1-ESPRIT 1;;FP1;Adapting Real-Time Strategies for Image Processing: a Case for Satellite Data;01/02/1986;01/11/1986;;"The ARTS-IP project was a definition study for the development of new architectures for processing satellite Synthetic Aperture Radar (SAR) images. 
The project was a definition study for the development of new architectures for processing satellite synthetic aperture radar (SAR) images. An implementation work plan was prepared, covering aspects of real time signal processing both onboard and onground, image interpretation through expert systems, and the related hardware and software. The design of end-to-end remote sensing systems for crop monitoring and maritime surveillance was formulated in conceptual terms. This work included an initial feasibility study, with Landsat SAR images taken from different orbits. A comparative review of several texture analysis algorithms was carried out.
An implementation work-plan was prepared, covering aspects of real-time signal processing both on-board and on-ground, image interpretation through expert systems, and the related hardware and software. 
The design of end-to-end remote sensing systems for crop monitoring and maritime surveillance was formulated in conceptual terms. This work included an initial feasibility study, with Landsat SAR images taken from different orbits. A comparative review ofseveral texture analysis algorithms was carried out. 
Exploitation 
The feasibility study revealed the European interest in this technical domain. Advances are foreseen in the signal processing area through the study of new algorithms for the production of custom high-speed integrated circuits, and the application of knowledge-based techniques for automated image interpretation. 
However, the definition phase has also shown that many basic technological problems remain to be solved, and that the project goals need reformulating vis--vis the objectives of ESPRIT.";;;;;Selenia SpA - Industrie Electroniche Associate;IT;"Thomson CSF;University of Westminster;GEC Marconi Research Centre;Hunting Technical Services Ltd;École Supérieure d'Ingénieurs en Électronique et Électrotechnique;Dornier System GmbH;Politecnico di Milano";"FR;UK;DE;IT";
8317;496;PAPILLON;;FP1-ESPRIT 1;;FP1;Design and Specification of Configurable Graphics Subsystems for CIM;01/12/1984;01/12/1987;;"The objective of the project was to develop a software environment to enable the configuration of graphics software to fulfil the varying application-dependent requirements of CIM graphics subsystems. The programme of work consisted of: 
-identification and classification of the differing requirements for graphics in the various areas of CIM 
-overall design and specification 
-design, specification and implementation of kernel software modules 
-design, specification and implementation of utility functions, man-machine interface and CIM applications 
-assembly and testing of a prototype graphics system satisfying the requirements of a CIM applications area. 
An object-oriented approach to the design was adopted to ensure configurability. An Ada implementation of GKS was developed with a skeleton device driver to increase subsystem portability. 
The objective of the project was to develop a software environment to enable the configuration of graphics software to fulfil the varying application dependent requirements of computer integrated manufacture (CIM) graphics subsystems. The programme of work consisted of: identification and classification of the differing requirements for graphics in the various areas of CIM, overall design and specification, design, specificationa and implementation of kernel software modules, design, specification and implementation of utility functions, man machine interface and CIM applications and finally assembly and testing of a prototype graphics system satisfying the requirements of a CIM applications area.
An object oriented approach to the design was adopted to ensure configurability. An Ada implementation of a graphics kernel system (GKS) was developed with a skeleton device driver to increase subsystem portability.
The ability to configure graphics hardware and software modules to specific requirements within CIM should provide the basis for a range of products with wide application. A software tool enabling software engineers to build Ada applications by coupling object-oriented design with sophisticated graphical interfacing techniques was announced by Generics Software in January 1988.";;;;;GENERICS SOFTWARE LTD;IE;"GTS GmbH;TRINITY COLLEGE DUBLIN";"DE;IE";
12644;EN3S0031;PASSYS;;FP1-ENNONUC 3C;;FP1;PASSIVE SOLAR SYSTEM DEVELOPMENT IN CLOSE COLLABORATION WITH ARMINES (PARIS) AND CEA (CADARACHE).;01/04/1986;31/12/1989;;"THE PROJECT PASSYS IS A EUROPEAN CONCERTED ACTION IN THE FIELD OF PASSIVE SOLAR COMPONENT AND SYSTEM TESTING. THE PASSYS GROUP IS COMPOSED OF THOSE TEAMS WHICH WERE SELECTED AMONG APPLICANTS TO THE R&D CALL FOR PROPOSALS NUMBER C69 OF 16 MARCH 1985. 

THE GENERAL OBJECTIVES OF PASSYS ARE THE FOLLOWING: 
- TO INCREASE CONFIDENCE IN PASSIVE SOLAR SIMULATION MODELS AND DESIGN TOOLS WHICH HAVE TO BE FURTHER DEVELOPED AND VALIDATED 
- TO DEVELOP RELIABLE AND AFFORDABLE TEST PROCEDURES FOR PASSIVE SOLAR COMPONENTS AND SYSTEMS. 

THE PROJECT PASSYS IS A EUROPEAN CONCERTED ACTION IN THE FIELD OF PASSIVE SOLAR COMPONENT AND SYSTEM TESTING. THREE FRENCH LABORATORIES PARTICIPATE TO THE PROJECT: THE CENTRE SCIENTIFIQUE ET TECHNIQUE DU BATIMENT, WHICH IS THE LEADER LABORATORY, THE ECOLE NATIONALE SUPERIEURE DES MINES DE PARIS AND THE CENTRE D'ETUDES NUCLEAIRES DE CADARACHE. THESE LABORATORIES ARE INVOLVED IN THE METHODOLOGIES-, VALIDATION- AND SIMPLIFIED DESIGN TOOLS ACTIVITIES OF PASSYS. 
TWO ORIGINAL COMPONENT TESTING METHODOLOGIES ARE PROPOSED AND STUDIED BY THE FRENCH TEAM. THESE METHODOLOGIES ARE BASED ON THE APPLICATION OF MODEL IDENTIFICATION TECHNIQUES ALLOWING THE DETERMINATION OF THE VALUES OF MODEL PARAMETERS FROM THE MEASURED INPUT AND OUTPUT DATA. ONE OF THE METHODS INTRODUCES A 9-PARAMETER DYNAMIC MODEL, THE OTHER ONE A STATE-VARIABLE MODEL. THESE TWO METHODOLOGIES, TOGETHER WITH THE MORE CLASSICAL INTEGRATED SUBSTRACTIVE METHODOLOGY, ARE CURRENTLY TESTED ON THE THREE PASSYS TEST-CELLS AVAILABLE IN FRANCE IN ORDER TO PRECISE THEIR ABILITY TO PROVIDE STEADY-STATE AND/OR TRANSIENT-STATE COMPONENT CHARACTERISTICS. 
CONCERNING THE VALIDATION AND DEVELOPMENT OF THE ESP SIMULATION CODE CHOSEN BY PASSYS AS A REFERENCE FOR ITS WORKS, THE FRENCH TEAM IS PARTICULARLY WORKING ON THREE TOPICS: AIR MOVEMENTS, PASSIVE COMPONENTS AND THERMAL MASS. ABOUT AIR MOVEMENTS, ALGORITHM ANALYSES AND COMPARISONS WITH OTHER CODES HAVE NOT SHOWN PARTICULAR PROBLEMS, EXCEPTED THE LARGE COMPUTING TIME NEEDED FOR PERFORMING SIMULATIONS WITH THE AIR-FLOW DETAILED MODEL. A SIMPLIFIED MODEL OF HEAT TRANSFERS DUE TO VENTILATION IS UNDER DEVELOPMENT. SIMULATION EXERCISES CARRIED OUT ON COMPONENTS HAVE REVEALED SOME QUESTIONS AND POSSIBLE IMPROVEMENTS NEEDED ON SEVERAL POINTS. 
THE OBJECTIVE OF THE SDT SUBGROUP (LED BY THE CSTB) IS TO DEVELOP WORKS IN ORDER TO INCREASE CONFIDENCE IN PASSIVE SOLAR SIMPLIFIED DESIGN TOOLS. BESIDE SIMPLIFIED SIMULATION TOOLS OBTAINED BY MODEL OR DATA REDUCTION TECHNIQUES AND WHICH MAY CONSTITUTE A SOLUTION FOR DEVELOPING FUTURE MORE SOPHISTICATED SIMPLIFIED CALCULATION TOOL, CORRELATION BASED TOOLS APPEARED AS A PERTINENT PRODUCT TO BE DEVELOPED FIRST IN THE FRAME OF PASSYS. AS A MATTER OF FACT, SUCH TOOLS ARE CURRENTLY USED IN THE BUILDING WORLD QUITE WIDELY EITHER FOR REGULATORY OR PERFORMANCE ASSESSMENT PURPOSES. HOWEVER A LARGE NEED OF VALIDATION AND IMPROVEMENT HAS BEEN IDENTIFIED FOR THESE CALCULATION TOOLS. IT IS WHY PASSYS IS PRESENTLY CARRYING OUT WORKS IN ORDER TO BE ABLE TO PROPOSE AT THE END OF THE CURRENT CEC PROGRAM (MID 1989) A PRELIMINARY VERSION OF A VALIDATED (THROUGH ESP SIMULATIONS) CORRELATION BASED CALCULATION TOOL ALLOWING BUILDING HEAT REQUIREMENT AND PSC PERFORMANCE-ASSESSMENT, TOGETHER WITH AN APPRAISAL OF COMFORT DURING THE HEATING SEASON. SPECIFIC INVESTIGATIONS ARE PERFORMED IN ORDER TO DEFINE A PERTINENT CORRELATION PRINCIPLE AND TO IMPROVE SOME TOPICS NOT YET WELL TAKEN INTO ACOUNT IN THE METHODS AVAILABLE UP TO NOW: MULTIZONE EFFECTS, INTERMITTENT HEATING, PASSIVE COMPONENTS, BUILDING THERMAL MASS, TIME STEP, INSIDE TEMPERATURE REGIME, CLIMATE.";;;;CSC;CENTRE SCIENTIFIQUE ET TECHNIQUE DU BATIMENT - CSTB;FR;"Commissariat à l'Energie Atomique (CEA);ECOLE NATIONALE SUPERIEURE DES MINES DE PARIS (ENSM);École Nationale Supérieure des Mines de Paris";FR;
8478;1520;ALF;;FP1-ESPRIT 1;;FP1;Advanced Software Engineering Environment Logistics Framework/Accueil de Logiciel Futur;13/10/1987;13/10/1991;;"The objective of ALF is to create an operating framework for third generation, integrated project support environments by developing the required software infrastructure. 
ALF can be seen as a continuation of the PCTE and PACT projects. It is based on the ECMA standard platform for software engineering environments. 
The project will integrate knowledge-based systems and information system techniques into process model based software engineering environments. Thus it will provide the basis for a rationalised approach to building initiative-taking project-support environments. 
The provision of an initiative engine by the incorporation of rule-based mechanisms into the underlying framework of the common integrated environments demonstrates a novel approach to software engineering. 
The objective was to create an operating framework for third generation, integrated project support environments by developing the required software infrastructure. The system is based on the European Computer Manufacturers' Association (ECMA) standard platform for software engineering environments. Knowledge based systems and information system techniques were integrated into process model based software engineering environments, thus providing the basis for a rationalized approach to building initiative taking project support environments. The provision of an initiative engine by the incorporation of rule based mechanisms into the underlying framework of the common integrated environments demonstrated a novel approach to software engineering. The model for assisted software processes (MASP) has been used intensively to model software processes such as configuration managment. It has also been used to provide facilities for observation, history generation and feedback. A MASP interpreter (MINT) has been specified, designed and is being implemented on top of the portable common tool environment (PCTE), using the expert system generator ALFRete. A MASP compiler has been specified, designed and implemented to convert the raw MASP language into schemas and input suitable for the MINT. The information system, a MASP editing tool, a MASP syntax checker and inconsistency tracker and the user interface have been implemented.
The Model for Assisted Software Processes (MASP) has been used intensively to model software processes such as Configuration Management, ACOMO and an example defined for the 6th International Software process Workshop (ISPW6). The latter example was developed to get a common basis for comparison of the different process modeling approach that have been developed. It has also been used to provide facilities for Observation, History Generation and Feedback. 
A MASP interpreter (MINT) has been specified, designed and is being implemented on top of PCTE, using the expert system generator ALFRete. 
A MASP compiler has been specified, designed and implemented to convert the raw MASP language into schemas and input suitable for the MINT. 
The information system, a MASP editing tool, a MASP syntax checker and inconsistency tracker and the user interface have been implemented. 
Exploitation 
The production of software systems will be facilitated by the adoption of the disciplined software and systems engineering approach of which ALF is part. It is expected that it will constitute the progression from the PCTE to the next generation of software engineering environments. The project has started the process of contacting potential users, and individual partners have plans to exploit the potential of ALF in the future.";;;;;GIE-EMERAUDE;FR;"CRIN;COMPUTER TECHNOLOGY CO. LTD.;UNIV CATHOLIQUE DE LOUVAIN;SA;GRUPO DE MECANICA DEL VUELO SA;International Computers Ltd (ICL);CERILOR;Universität Dortmund";"FR;EL;BE;ES;UK;DE";
8664;1632;HERODE;;FP1-ESPRIT 1;;FP1;Handling Mixed Text/Image/Voice Documents Based on a Standardised Office Document Architecture;01/11/1984;01/11/1987;;"HERODE dealt with the design, prototype development and demonstration of cooperative tools for the handling of mixed text/image/voice documents in future office systems. The work was based on the Office Document Architecture (ODA), which supports both the logical and the layout structure of documents. The ODA definition allowed the tools to be easily adapted to the actual type of document. This reduced the time taken by a user carrying out routine tasks and allowed the automatic checking of document input . 
The project dealt with design, prototype development and demonstration of cooperative tools for the handling of mixed text/image/voice documents in future office systems. The work was based on the office document architecture (ODA), which supports both the logical and the layout structure of documents.

A prototype of the document handler was developed and integrated. It comprises:
a logical structure editor for creating and modifying the logical structure of a document;
a character content editor for editing text;
a geometric content editor for handling lines, curves and graphics;
a photographic content editor for editing picture information;
a layour structure editor for the automatic update of the document layout after each editing step.

A prototype of the common user inteface and the document editor shell was also developed and integrated. It provided a unified functional appearance for the user when employing the different editors. The prototype of the automated document entry tool was produced. It supports the function of transferring a document with text, drawings and pictures into an electronic form. The following functional modules are available: preprocessing, area segmentation, geometrics recognition and coding, and photographic recognition and coding.
A prototype of the Document Handler was developed and integrated. It comprises: 
-a Logical Structure Editor for creating and modifying the logical structure of a document 
-a Character Content Editor for editing text 
-a Geometric Content Editor for handling lines, curves and graphics 
-a Photographic Content Editor for editing picture information 
-a Layout Structure Editor for the automatic update of the document layout after each editing step. 
A prototype of the Common User Interface and the Document Editor Shell was also developed and integrated. It provides a unified functional appearance for the user when employing the different editors. 
The prototype of the Automated Document Entry Tool was produced. It supports the function of transferring a document with text, drawings and pictures into an electronic form. The following functional modules are available: preprocessing, area segmentation, geometrics recognition and coding, and photographic recognition and coding. The prototypes were demonstrated during the 1986 and 1987 ESPRIT Conference Weeks and have been described in several published papers. The project has also had a major impact onthe ECMA and ISO standardisation of ODA, and the results have been used in the project 1024, PODA. 
Exploitation 
The HERODE project, which has formed a basis for the standardisation of electronic documents, has been of major importance for information systems in business and administration. It allows office documents incorporating graphics and pictures to be transferred, stored and manipulated on and between different systems, from different vendors, based on the ODA standard. It supports the development of the market for document-based information systems, and improves the market potential of a large number of vendors' products.";;;;;Siemens Nixdorf Informationssysteme AG;DE;"CRIN;Alcatel TITN";FR;
8490;1613;ITS;;FP1-ESPRIT 1;;FP1;Evaluation of an Intelligent Tutoring System Shell for Industrial and Office Training;01/03/1987;28/02/1989;;"This project evaluated an ITS (Intelligent Tutoring System) shell on the basis of data gathered from commercial, scholastic and industrial field trials. The field trials were on office automation procedures, scholastic skills and maintenance procedures. This project aimed to identify how to use intelligent tutoring systems to cut training costs and increase training effectiveness. A new prototype (DOMINIE) was designed and implemented. 

The system shell and the trainer interface were respecified from an analysis of the results of the first field trials. Design modifications were made with regard to the teacher's help in choosing tutorial material and in refining the tutorial control loopand tutorial strategies. Simple applications demonstrations were given of their implementation. 
A second field trials phase evaluated the implementation of the enhanced prototype. The final building loop iteration, covering field trials, redesign and implementation, was completed. 
An enhanced prototype version of the trainer interface was successfully demonstrated. 
Exploitation 
This project has a strong commercial potential, as the rapidly growing shortage of advanced tools to provide training in new disciplines is well known. 
The use of DOMINIE within other divisions of Alcatel is planned, thereby providing continuing feedback to the consortium. 
DATAMAT has planned to add to any package software application they will provide in the future a tutorial package based on DOMINIE. The Open University will develop a spreadsheet tutorial based on DOMINIE for its students and will carry on cognitive research in this area.";;;;;Standard Elektrik Lorenz AG (SEL);DE;"Dei Sistemi SpA;Open University;Datamat Ingegneria dei Sistemi SpA";"IT;UK";
8459;1522;LOKI;;FP1-ESPRIT 1;;FP1;A Logic-Oriented Approach to Knowledge and Data Bases Supporting Natural User Interaction;01/08/1984;01/08/1989;;"LOKI aimed to provide the technology for the development of knowledge representation, knowledge use, knowledge consultation systems and other aids to the development of knowledge and database systems. User-friendly graphics and natural language were to becombined in a single interface. 
LOKI applied logic programming in a number of novel ways to systems software and to knowledge-based applications. The systems software work was based on a new Prolog and on special tools allowing access to databases at source level by a variety of Prolog-type languages. These tools formed the implementation language for a high-level knowledge representation formalism. A conceptual modelling language (CML) was developed for general real-world application, based on frames definable within predicate calculus. Two application domains were considered: project management and aircraft design. 
LOKI aimed to provide the technology for the development of knowledge representation, knowledge use, knowledge consultation systems and other aids to the development of knowledge and databases systems. User friendly graphics and natural language were to be combined in a single interface. LOKI applied logic programming in a number of novel ways to systems software and to knowledge based applications. The systems software work was based on a new Prolog and on special tools allowing access to databases at source level by a variety of Prolog type languages. These tools formed the implementation language for a high level knowledge representation formalism. A conceptual modelling language (CML) was developed for general real world application based on frames definable within predicate calculus. 2 application domains were considered: project management the aircraft design.
The following results were achieved: knowledge representation with the development of 3 formalisms (LOLA and CML to support natural language interfaces and STRUDEL to support a computer aided design (CAD) system for aircraft design); knowledge use with the development of parser generator pair (LOQUI) for English and German to support access to databases in natural language, and of a constraint propagator mechanism used for the aircraft design application (ADROIT). The natural language interface is loosely coupled with graphics interface facilities; knowledge consultation with the development of tools to support inspection of knowledge structures suitable for the project management application and to support explanation facilities in ADROIT. A first prototype of the aircraft design system, restricted to wing design, was completed.
The following results were achieved: 
-Knowledge Representation: development of three formalisms (LOLA and CML to support natural language interfaces and STRUDEL to support a CAD system for aircraft design). 
 -Knowledge Use: development of a parser-generator pair (LOQUI) for English and German to support access to databases in natural language, and of a constraint propagator mechanism used for the aircraft design application (ADROIT). The natural language int erface is loosely coupled with graphics interface facilities. 
-Knowledge Consultation: development of tools to support inspection of knowledge structures suitable for the project management application and to support explanation facilities in ADROIT. 
A first prototype of the aircraft design system, restricted to wing design, was completed. 
Exploitation 
The partners are lining up concrete prospects for the exploitation of the work done. BIM-Prolog is already on the market and benefiting from the comprehensive testing afforded by the project. LOQUI will lend itself as an immediate enhancement of the SCS project management materials, and independent developments are already in train within Scicon International Ltd. 
The technology developed has been embedded in CARMEN, an MMI tool generator which is being commercially distributed by BIM. 
The constraint propagation tools being developed for aircraft design are being evaluated for use in other contexts.";;;;;BIM SA;BE;"Scicon Ltd;CRETAN COMPUTER INSTITUTE;Scientific Control Systems Informationstechnik Gmbh;Fraunhofer-Gesellschaft zur Förderung der Angewandten Forschung eV (FhG)";"UK;EL;DE";
8468;1252;AMADEUS;;FP1-ESPRIT 1;;FP1;A Multi-Method Approach for Developing Universal Specifications;08/04/1986;08/04/1987;;"The objective of AMADEUS was to define a unified conceptual model semantically rich enough to describe specifications derived from any of the leading development methods. This would provide a basis for the integration of the wide range of existing and well-understood tools and techniques currently used. This project aimed to provide for the harmonisation of system development environments by introducing an approach which permitted the use of multiple methods, but with a common and unified system specification as the outcome of its use. This was intended to be achieved by the availability of a unified representation scheme which could be accessed through appropriate interfaces, by tools and techniques relating to a method. 
This project was associated with projects 1262 (SFINX), 1277 (SAPPHIRE), 1282 (PAVE) and 1283 (VIP). 
The objective was to define a unified conceptual model semantically rich enough to describe specifications derived from any of the leading development methods. This would provide a basis for the integration of the wide range of existing and well understood tools and techniques currently used. This project aimed to provide for the harmonization of system development environments by introducing an approach which permitted the use of multiple methods, but with a common and unified system specification as the outcome of its use. This was achieved by providing a unified representation scheme which could be accessed through appropriate interfaces, by tools and techniques relating to a method. The project team surveyed a number of different software development method comparison studies and classified the development methods, mapping the model of development against the approach used. A range of application and support system types, such as office communications systems, control systems and robotic systems, were examined to identify the real world objects dealt with. These objects were grouped under headings such as objects manipulated, relationships, and activities. A model was developed on the basis of the analyses performed. Whilst the model has some value in judging the completeness of the methods, much of the sematic information was lost in the transformation.
The project team surveyed a number of different software development method comparison studies and classified the development methods, mapping the model of development against the approach used. Methods included SSADM, SADT, JSD and NIAM. 
A range of application and support system types, such as office communications systems, control systems and robotic systems, were examined to identify the real-world objects dealt with. These objects were grouped under headings such as objects manipulated, relationships, and activities. 
A model was developed on the basis of the analyses performed. Whilst the model had some value in judging the completeness of the methods, much of the semantic information was lost in the transformation. 
Exploitation 
Reviewers recommended publication of the 'Analysis of Methods' document. The results of the feasibility study were not sufficiently convincing to continue the work.";;;;;INTERPROGRAM BV;NL;"HITEC LTD;TELEFONICA INVESTIGACION Y DESARROLLO;BIM SA;UNIVERSITY OF MANCHESTER INSTITUTE OF SCIENCE AND TECHNOLOGY";"EL;ES;BE;UK";
8456;125;GRASPIN;;FP1-ESPRIT 1;;FP1;Personal Workstation for Incremental Graphical Specification and Formal Implementation of Non-Sequential Systems;01/09/1984;01/09/1989;;"As one of the first ESPRIT projects in the area of software technology, the GRASPIN project was concerned with the topic of formal specification and systematic program development. 
The overall goal of GRASPIN was to improve current software development approaches in order to encourage their use on a wider industrial scale. From this overall objective two secondary R&D objectives were derived: to develop a coherent software development methodology, and to develop automated support tools, covering the full software life cycle (except for management activities). 
Emphasis was to be placed on the following issues: 
-First, the methodology should be particularly suited for the incremental development of distributed non-sequential systems. 
-As concerns the life-cycle coverage, the project concentrated on the most critical areas of the so-called life-cycle, which are the early phases of software development - the Requirements Analysis and the Specification phases - as well as on Validationand Verification. 
-Significant methodological improvements were expected from combining Petri-net theory with algebraic specification, and from integrating informal and formal methods. 
-Technical improvements were expected from applying syntax-directed editing and object-oriented programming techniques. 
To demonstrate the feasibility of the GRASPIN methodology, the consortium aimed at a prototype of an open-ended and customisable software development environment, suitable for supporting software engineers in the construction of reliable software systems. 
The graphical specification (GRASPIN) project was concerned with the topic of formal specification and systematic program development. The overall goal of GRASPIN was to improve current software development approaches in order to encourage their use on a wider industrial scale. From this overall objective 2 secondary research and development objectives were derived: to develop a coherent software development methodology and to develop automated support tools covering the full software life cycle (except for management activities).
The project developed 2 customizable prototypes of a personal software engineering environment to support the construction and verification of distributed and nonsequential software systems.
The GRASPIN environment supports a methodology which covers a wide range of cycle activities. Methods and tools cover all technical activities, except documentation, and reflect the cyclic nature of software construction. Major methodological achievements of the project concern the development of: a novel specification language, SEGRA (semigraphical specification language) which is particularly suitable for writing, testing and analyzing distributed software systems; a declarative metalanguage, ASDL (abstract syntax definition language) which provides for extending the environment by new methods and tools and for customizing the GRASPIN kernel system for particular applications; and improved validation and verification methods, most of them making use of rewriting techniques.
The project developed two customisable prototypes of a personal software engineering environment to support the construction and verification of distributed and non-sequential software systems. 
The Unix/PCTE-based prototypes developed by the Italian partners Olivetti and Tecsiel run on Sun (3 and 4) workstations and on LSX30 and M380 Olivetti machines, all under Unix 4.2 BSD, and are implemented in the C language. These prototypes are particularly dedicated to requirements engineering, supporting subsets of Structured Analysis (SA) and Entity Relationship (ER) languages, and to programming and testing. 
The Lisp prototypes developed by the German partners, together with their sub-contractors, primarily support formal specifications and verification. They are implemented in Common Lisp and run on Symbolics 36 (with Genera 7.2 & 8.0), on Sun workstations with the UX400 board, and on Macintosh II Ivory (with Genera 7.4i). Interlisp-D versions are available on Siemens AI and Xerox 1186 machines (with LOOPS). 
The GRASPIN environment supports a methodology which covers a wide range of life-cycle activities. Methods and tools cover all technical activities, except documentation, and reflect the cyclic nature of software construction. 
Major methodological achievements of the project concern the development of: 
-A novel specification language, SEGRAS (SEmi-GRAphical Specification language). This language is particularly suitable for writing, testing and analysing distributed software systems. 
-A declarative meta-language,ASDL (Abstract Syntax Definition Language), which provides for extending the environment by new methods and tools and for customising the GRASPIN kernel system for particular applications. 
-Improved validation and verification methods, most of them making use of rewriting techniques. 
For all the methods related to the construction and validation activities in the software life-cycle, powerful tools provide a systematic tool support. This applies not only to the formal methods, but also to the informal ones, such as Structured Analysis. 
 System integration has been reached on an integration level typical for current second-generation CASE environments. The GRASPIN environment integrates the tools into a smoothly functioning environment through common graphical interfaces and object bases providing a common communication medium among the tools. All the tools are accessible via a uniform graphical user interface with multiple windows, menus and graphical objects, so that graphical representations can be clearly visualised and directly manipulated. User interaction with the system is supported via commands, function keys, menus or mouse. 
The object base is completely encapsulated by object manipulation primitives generated from a declarative specification of object types. Complex structure-driven computations and object transformations can also be specified in ASDL as syntax-directed tran slation rules. These features allow easy modifications to the environment to incorporate new tools and techniques without sacrificing the uniformity of system-user interaction. First field trials showed the suitability of the GRASPIN methodology for both distributed applications as well as for generating specific CASE tools and dedicated CASE environments. 
Exploitation 
Industrial experience gained so far suggests that from a methodological point of view the GRASPIN environment can be seen as a significant step towards the next generation of CASE environments. Exploitation on a wider industrial scale, however, still requires additional technical consolidation of the results in order to adapt the underlying formal methods to specific industrial needs and to integrate the GRASPIN methods and tools with current industrial technology and standards. Whereas the Lisp-based prototypes are mostly used for further research, the Unix-based prototypes are on the way to being introduced into the software industry.";;;;;Gesellschaft für Mathematik und Datenverarbeitung mbH;DE;"Ingegneria C. Olivetti and C. SpA;Siemens Nixdorf Informationssysteme AG;Tecsiel SpA";"IT;DE";
8489;1609;SMART;;FP1-ESPRIT 1;;FP1;System Measurement and Architectures Techniques;07/05/1987;07/11/1989;;"The aim of the SMART project was to support the efficient production of cost-effective fault-tolerant information systems to stated design specifications. Its objective was to define techniques and to provide tools to support the design and development ofsuch systems throughout their life-cycle. This involved: 
-identifying the parameters to be measured and processed 
-formalising and modelling performance within the reference systems for single components and for structured fault-tolerant systems 
-validating the models on existing projects. 
The aim of the system measurement and architectures techniques (SMART) project was to support the efficient production of cost effective fault tolerant information systems to stated design specifications. Its objective was to define techniques and to provide tools to support the design and development of such systems throughout their life cycle.

The results were as follows:
A survey of 3 metrics reference systems concerning product, project and process was achieved. The Tools Directory, the Metrics Directory and the Data Directory for the support of the design and development of fault tolerant systems were finished.
A characterisation of fault tolerant architectures (eg in regard to hardware dependability, software design, hardware/software physical description, etc) was made, based on studies of existing information systems for a space shuttle, a nuclear power plant and an airbus.
Performance modelling and quantification were examined.
3 tools were inplemented and are included in the SMART environment, which is a frame server that provides the infrastructure. The frame concept provides a method of describing objects and classes. It manages a set of independent context of clients applications, and its use minimises access to the disk. The tools are:
dependability evaluation tool (MetFac \);
Petri net simulators of real time system functionalities;
fault tree analysis.
The toolkit is open and extensible so that other tools can be added to the SMART environment. Tools and user documents are currently available within the consortium.
The results were as follows: 
 -A survey of three metrics reference systems concerning product, project and process was achieved. The Tools Directory, the Metrics Directory and the Data Directory for the support of the design and development of fault-tolerant systems were finished. Th e Tools Directory describes currently available reliability and cost estimation tools. The Metrics Directory lists metrics of fault-tolerant architectures with their definitions. The Data Directory defines the entities and relationships which constitute the data model. 
 -A characterisation of fault-tolerant architectures (e.g. in regard to hardware dependability, software design, hardware/software physical description etc.) was made, based on studies of existing information systems for a space shuttle, a nuclear power-p lant and an airbus. 
-Performance modelling and quantification were examined. 
-Three tools were implemented, and are included in the SMART environment, which is a frame server that provides the infrastructure. The frame concept provides a method of describing objects and classes. It manages a set of independent context of clientsapplications, and its use minimises access to the disk. The tools are: 
.dependability evaluation tool (MetFac \) 
.Petri-Net simulators of real time system functionalities 
.fault-tree analysis. 
The tool-kit is open and extensible so that other tools can be added to the SMART environment. Tools and user documents are currently available within the consortium. 
The demonstrators shown (on dependability safety simulation, fault-trees and Petri-nets), were sufficiently convincing to envisage further industrial cooperation for further tests and dissemination within industry. 
Exploitation 
The validation of the proposed approach is promoting architecture techniques and associated performance recommendations for the next generation of fault-tolerant systems. 
The application of the models and tools that the project is providing has led to increased efficiency in the European fault-tolerant data-processing industry by strengthening project monitoring processes. Improvements in other industries using fault-tolerant software will follow. 
Several partners are making internal use of the SMART environment after the end of the project.";;;;;CCS;ES;"CRI A/S;MATRA SA;University of Paisley;COMMISSARIAT A L'ENERGIE ATOMIQUE";"DK;FR;UK";
8533;888;AIDA;;FP1-ESPRIT 1;;FP1;Advanced Integrated Circuit Design Aids;15/11/1985;15/11/1989;;"The objective of the AIDAproject was to master the complexity of VLSI chips (more than onemillion transistors within the next few years) by obtaining a drastic improvement in design methods. CAD tools, new methods and concepts were defined, proved on ex perimental software, and finally developed into industrial tools integrated into the existing CAD environments of the partners. AIDA explored the application of modern programming techniques and knowledgebased engineering to CAD tool development. It cons titutes a design assistant that proposes solutions rather than merely records and validates the designer's ideas. This allows the designer to apply his creativity where it is most efficient, leading to improved design quality. Modern programming techniques were applied, such asthose developed for expert systems to VLSICAD tools. The potential contribution of these techniques is twofold: 
-the basic techniques can be used to make new tools much more efficient than classical ones 
-the basic integrated circuit design knowledge can be recorded on the machine and used by 'expert' modules under the control of a system designer. 
The sevenwork packages undertaken show the full span of problems tackled by the project: Data Management, Specification, Synthesis, Layout, Testing, Man-Machine Interface and Evaluation. 
The objective of the AIDA project was to master the complexity of very large scale integration (VLSI) chips (more than one million transistors) by obtaining a drastic improvement in design methods. Computer aided design (CAD) tools, new methods and concepts were defined, proved on experimental software and finally developed into industrial tools integrated into the existing CAD environments. AIDA explored the application of modern programming techniques and knowledge based engineering to CAD tool development.
Modern programming techniques were applied, such as those developed for expert systems, to VLSI-CAD tools. The potential contribution of these techniques is 2-fold:
the basic techniques can be used to make new tools much more efficient than classical ones;
the basic integrated circuit design knowledge can be recorded on the machine and used by expert modules under the control of a system designer.
The 7 work packages undertaken show the full span of problems tackled by the project:
data management;
specification;
synthesis;
layout;
testing;
man machine interface;
evaluation.
The operating environment is as follows :
Computer aided design (CAD) and design methodologies
The project started with an indepth study and refinement of the requirements catalogues in each work area and the establishment of priorities in the different approaches towards implementation. In data management, particularly, the large volume and compl ex structure of the design data, together with the extensive range of necessary design tools and all their varied interactions, means that the requirements of CAD systems for VLSI design are probably among the most challenging of all database applications. Here the partners concentrated on aspects of portability, exchange formats and interfaces and data security concepts, especially for CAD systems distributed over a range of interconnected computers. 
During its second year the project entered the implementation phase. During the third year most of the first prototype tools were produced. Many of these were demonstrated at the exhibition during the 1989ESPRITConference. 
The final year of the project saw the completion of the implementation and integration of the tools. Early exploitation in industrial designs were exhibited at the 1990 ESPRIT Conference. 
Prompted by the need to share design data and tools between the three corporate databases, the project evolved an internal standard for the presentation of conceptual data models. This development has been taken into account in the work on conceptual models in the ECIP project. In the last year of the project the software bridges between the three CAD systems were implemented. 
Exploitation 
All three partners have a large existing investment in CAD systems in-house. The project has already had a significant impact on the ability of these companies to design complex chips with several million transistors. Furthermore, the partners are committed to marketing the results both as standalone tools and as integrated systems, thus making the results available to a much wider community. AIDA should also prove a useful test-bed for the proposed standards emerging from the ECIPproject (number 2072).Siemens-Nixdorf-Informations Systems is now marketing the CALANY floorplanner tool and the SMILE digital simulator resulting from AIDA as part of its SIGRAPH-EL CAD system. CALANY gives cost improvements resulting from a reduction of 50% in total block area and performance improvements of up to 35% in total wire length.";;;;;Siemens Nixdorf Informationssysteme AG;DE;"International Computers Ltd (ICL);SGS Thomson Microelectronics SA";"UK;FR";
8322;1459;CAD*I;;FP1-ESPRIT 1;;FP1;CAD Interfaces;01/11/1984;01/11/1989;;"The objective of this project is to develop a family of consistent, compatible standardised interfaces for CAD, allowing: 
-representation of 2-D and 3-D geometrical models of CAD design objects 
-archiving and retrieval of these models by various CAD/CAM systems 
-exchange of such models over networks 
-storage of parametrised part libraries in databases connected to networks 
-access to such libraries from various CAD/CAM systems 
-use of advanced modelling techniques for model generation 
-standardised application of different finite element model analysis programs 
-comparison of experimental and analytical dynamic analysis results 
-dynamic model optimisation resulting from experimental and analytical analysis. 
The availability of a standard interface will facilitate the free flow of geometrical design data between different CAD systems without expensive conversion and data restructuring. It will also permit CAD systems to be interfaced with Computer-aided Engineering systems, such as those used for the static and dynamic analysis of structures. 
The objective of this project was to develop a family of consistent, compatible standardised interfaces for computer aided design (CAD), allowing the representation of 2-dimensional and 3-dimensional geometrical models of CAD design objects, the archiving and retrieval of these models by various CAD/CAM systems, the exchange of such models over networks, storage of parametrised part libraries in databases connected to networks, access to such libraries from various CAD/CAM systems, the use of advanced modelling techniques for model generation, the standardized application of different finite element model analysis programs, the comparison of experimental and analytical dynamic analysis results, and dynamic model optimization resulting from experimental and analytical analysis. The availability of a standard interface will facilitate the free flow of geometrical design data between different CAD systems without expensive conversion and data restructuring. It will also permit CAD systems to be interfaced with computer aided engineering systems, such as those used for the static and dynamic analysis of structures. The project's contributions include the neutral file for CAD geometry (covering solids, wireframes and free-form surfaces), a high-level data specification language (HDSL), and an interface to finite element analysis systems. A wide range of CAD interface pre- and post-processors and dynamic analysis systems developed within the project are available.
The project has produced the main portions of the projected international STEP standard, adopted as a draft proposal by ISO TC184 SC4 in December 1988. CAD*I contributions include the neutral file for CAD geometry (covering solids, wireframes and free-form surfaces), a high-level data specification language (HDSL), and an interface to finite element analysis systems. Many partners have incorporated the interface into commercial products, such as Leuven Measurement and Systems (CADA LINK, CADA TEST and CADA MODAL), which has implemented the interface in a product for the experimental testing of dynamic behaviour in the development of machine-tools, cars and aircraft. BMW has implemented the standard interface internally. 
A wide range of CAD interface pre- and post-processors and dynamic analysis systems developed within the project are available. KfK is providing CAD geometry interface software to a German CAD vendor for incorporation in marketable products. 
Programs to perform syntactical and semantic checks (SYNTAX) and statistical analyses (STATISTIC) of IGES files have been licensed by BMW.";;;;;Forschungszentrum Karlsruhe Technik und Umwelt GmbH;DE;"Gesellschaft für Strukturanalyse mbH;DANMARKS TEKNISKE HOJSKOLE;LEUVEN MEASUREMENT & SYSTEMS INTERNATIONAL;NEH TECHNOLOGY A/S;DISEL-DISENO E INGENIERIA DE SISTEMAS ELECTRONICOS SA;BAYERISCHE MOTOREN WERKE AG (BMW);KATHOLIEKE UNIVERSITEIT LEUVEN;Cisigraph SA;Cranfield University;Rutherford Appleton Laboratory (RAL);Universität Fridericana Karlsruhe (Technische Hochschule)";"DE;DK;BE;ES;FR;UK";
8817;1643;CARLOS;;FP1-ESPRIT 1;;FP1;Communications Architecture For Layered Open Systems;01/02/1985;01/02/1990;;"The goal of the CARLOS project was to allow users of PCs and terminals to access X.25 and X.75 data networks and to provide them with value-added services conforming to Open Systems Interconnection (OSI) standards. The services involved were file transfer(FTAM), X.400 message-handling, virtual terminal (VT) emulation and network management. 
The goal of the communications architecture for layered open systems (CARLOS) project was to allow users of personal computers (PC) and terminals to access X.25 and X.75 data networks and to provide them with value added services conforming to open systems interconnection (OSI) standards. The services involved were file transfer (FTAM), X.400 message handling, virtual terminal (VT) emulation and network management.
Various OSI components were developed during the project: the OSI-PAD and the OSI-BOX (later combined in the extended OSI-PAD), allowing nonOSI terminals to access (using the VT protocols) OSI conformant applications over X.25 networks; and the OSI-PC, implementing all 7 layers of the OSI model and giving PC users access to both the VT and FTAM services. The network management centre (implemented on a Unix based system) provides a comprehensive network management service for control, monitoring, fault detection and correction of heterogeneous distributed OSI network resources. This control centre is enriched with a set of generalized tools for the presentation of the information in a graphical way, providing a flexible and user friendly means for network operation and management.
There have been 2 extensions to the project: CACTUS (CARLOS addition for clustered terminal user agents) which allows a low cost connection of PC to the X.400 world and SESTA (standard European strategic programme for research and development in information technology (ESPRIT) system transfer adaptor), which adds OSI support to the industry standard PC-AT.
Various OSI components were developed during the project: the OSI-PAD and the OSI-BOX (later combined in the extended OSI-PAD), allowing non-OSI terminals to access (using the VT protocols) OSI conformant applications over X.25 networks; and the OSI-PC, implementing all 7 layers of the OSI model and giving PC users access to both the VT and FTAM services. The Network Management Centre (implemented on a Unix-based system) provides a comprehensive network management service for control, monitoring, fault detection and correction of heterogeneous distributed OSI network resources. This control centre is enriched with a set of generalised tools for the presentation of the information in a graphical way, providing a flexible and user-friendly means for networkoperation and management. 
There have been two extensions to the project: 
CACTUS (CARLOS Addition for Clustered Terminal USer agents), which has developed CCITT X.400 message-handling software for a cluster of PCs around a central server. The central server contains the message transfer agent (MTA) which communicates to other MTAs via the P1 and P2 protocols and the user mailboxes. The PC contains a user interface, a mailbox client and the underlying communication software needed to connect to the central server (using the P7 protocol). This method of working allows a low cos t connection of PCs to the X.400 world. 
SESTA (Standard ESPRIT System Transfer Adaptor), which adds OSI support to the industry-standard PC-AT. Whereas during the CARLOS project the OSI-PC was implemented on an RC750 Partner microcomputer running concurrent Dos, SESTA wanted to provide the same functionality on an AT-bus compatible adaptor board. This OSI board can connect any AT-compatible PC to an X.25 WAN. FTAM and VT were implemented as value-added services. The PC user can access these services via an easy-to-use window-driven interface.Exploitation 
Case Communications has already used know-how acquired during the CARLOS project to provide X.25 PAD facilities to their DCX product range, and is now planning to use the CACTUS work as the basis for the addition of an X.400 message server. RC International is planning commercial products based on the SESTA work. INESC and the Universidad Politecnica de Madrid and Barcelona are heavily involved in work related to the research networks in Portugal and Spain, as well as in the Eureka COSINE project (which is building a pan-European OSI-conformant research network). Knowledge acquired during the CACTUS and SESTA projects is part of the basis for such work, and many of the components developed during the CARLOS project will be reused.";;;;;PMC;BE;"PMC APS;UNIVERSIDAD POLITECNICA DE CATALUNA;RC INTERNATIONAL A/S;FISCHER MADSEN & LORENZ PETERSEN A/S;INESC;UNIVERSIDAD POLITÉCNICA DE MADRID;Case Communications Ltd";"DK;ES;PT;UK";
8538;1549;HYETI;;FP1-ESPRIT 1;;FP1;High Yield and High Reliability ULSI System;01/10/1984;01/10/1985;;"The objective of the HYETI project was to develop the design methodology, design tools and architecture necessary to achieve high yields on ULSI (Ultra Large Scale Integration) and WSI (Wafer Scale Integration) integrated circuits. The yield models, specialised architectures and focused CAD tools required for reconfiguration at the end of manufacture were to be studied in this project. Because defect densities in modern process technology are such that working wafer scale circuits can only be manufacturedby introducing redundancy into a chip, enabling the defects to be avoided by reconfiguration during production, this work was of high value. 
The need to produce a demonstrator to focus the many multi-discipline, interrelated facets of the WSI design problem was an important consideration from the start of the project. 
The objective of the project was to develop the design methodology, design tools and architecture necessary to achieve high yields on ultra large scale integration (ULSI) and wafer scale integration (WSI) integrated circuits. The yield models, specialised architectures and focused computer aided design (CAD) tools required for reconfiguration at the end of manufacture were to be studied in this project.

As a conclusion to the work on yield analyses, the project found that the most satisfactory way to handle yield prediction for a specific topology is by graphic simulation. 2 architectures were selected for WSI implementation after a wide investigation: a 2-dimensional fast Fourier transform (FFT) processor and a processor array. After extensive investigation, the decision was taken during this preproject study to design and manufacture, in the follow up project, a 4 Mbit static random access memory (RAM), a systolic array and a reconfigurable 16-bit microprocessor.
As a conclusion to the work on yield analyses, the project found that the most satisfactory way to handle yield prediction for a specific topology is by graphic simulation. 
Two architectures were selected for WSI implementation after a wide investigation: a 2-D Fast Fourier Transform (FFT) processor, and a processor array. After extensive investigation, the decision was taken during this pre-project study to design and manufacture, in the follow-up project, a 4 Mbit static RAM, a systolic array and a reconfigurable 16-bit microprocessor. 
As this was just a one-year pre-project to investigate the feasibility of WSI, only limited results were achieved. The work, with an adjusted workplan and modification in the partnership, has been continued under project 824.";;;;;SGS Thomson Microelectronics SA;FR;"Technische Hochschule Darmstadt;Commissariat à l'Energie Atomique (CEA);BULL SA;Institut National Polytechnique de Grenoble;Cirrus Computer Ltd;British Telecom plc (BT);Brunel University";"DE;FR;UK";
13950;FI1W0209;X-CORE;;FP1-RADWASTOM 3C;;FP1;DEVELOPMENT AND EVALUATION OF AN X-RAY-ANALYTICAL TECHNIQUE FOR CORES FROM EXPLORATION HOLES DRILLED ON A WASTE-DISPOSAL SITE.;01/01/1989;30/06/1990;;"THE EXPLORATION OF SITES FOR THE DISPOSAL OF RADIOACTIVE WASTE IN VARIOUS TYPES OF DEEP GEOLOGICAL FORMATIONS, AND OF POSSIBLE LOCATIONS FOR UNDERGROUND LABORATORIES, IS MAINLY BASED ON THE USE OF CORED BOREHOLE. IT IS DESIRABLE TO STUDY THE RESULTING CORES IN A NON-DESTRUCTIVE MANNER. 
X-RAY PHOTOGRAPHY IS WIDELY USED IN MECHANICAL AND METALLURGICAL INDUSTRY. 
IN GEOLOGY, ONLY A FEW STATIONARY X-RAY MACHINES ARE USED FOR LIMITED APPLICATIONS. 
THE AIM OF THE RESEARCH IS THUS, FOR DIFFERENT ENVIRONMENTS : 
- TO ADAPT RADIOSCOPIC TECHNIQUES TO THE STUDY OF GEOLOGICAL MATERIALS THAT ARE AVAILABLE AS DRILL CORE; 
- TO CREATE A MOBILE UNIT THAT CAN BE TRANSPORTED TO THE SITES WHERE CORES ARE AVAILABLE AND MUST BE STUDIED, SUCH AS A DRILL SITE, AN UNDERGROUND LABORATORY OR A VESSEL ENGAGED IN SEDIMENT STUDIES; 
- TO ALLOW NON-DESTRUCTIVE TESTING AND STUDY OF THE CORES THAT ARE TAKEN WITHIN A SLEEVE AND REQUIRE IMMEDIATE CONFINEMENT AFTER BEING PULLED FROM THE HOLE, SUCH AS IS THE CASE FOR CLAYEY AND SALT-BEARING MATERIALS THAT ARE DESTINED FOR MECHANICAL AND GEOCHEMICAL TESTS; 
- TO HAVE ACCESS, BEFORE ANY DESTRUCTIVE OPERATIONS, TO THE INTERNAL STRUCTURE OF CORES, AS A FURTHER AID TO MECHANICAL TESTS, AND TO GEOLOGICAL AND GEOCHEMICAL STUDY; 
- TO ADAPT AND DEVELOP IMAGE-PROCESSING SOFTWARE FOR THE GEOLOGICAL STUDY OF RADIOSCOPIE IMAGES. 
An X-ray radioscopy mobile unit, adapted to the study of geological cores, has been developed and constructed. The main components of the XCORE device fall into 3 groups. Firstly, the X-ray part, which includes the high voltage generator, the X-ray transmitter tube, the receiver or brightness amplifying tube and all the acquisition, visualization and recording system for the video images, and the X-ray control rack. Secondly, the mechanical part, composed of the core handling system and the mechanism that controls the core's motions. Thirdly, the microcomputer and its peripherals, complete with digitizing and image processing card.

The equipment is mounted in a container transportable by lorry and weighs about 9T.

An important part of the work has been devoted to the development and adaptation of the digitized image processing software. Noise has been reduced, and contrast enhanced. The main functions of the software are described. This technique has been applied to a wide range of geological materials including clay, salt, granite, and shale. In each case, data have been collected that could not been obtained by other methods: decompression cracks and erosion figures of the core sides in clay; small inclusions; lithological variations; grain joints. This nondestructive analysis is a great help for the sampling, and it contributes displays of some specific phenomena, such as a prefential positioning of minerals in the rock matrix.
THE EQUIPMENT THAT IS THE SUBJECT OF RESEARCH DIFFERES FROM EXISTING X-RAY APPARATUS IN THE FOLLOWING POINTS: 
- AN IMAGE-ANALYSER WILL BE FITTED IN ORDER TO BE ABLE TO DISPOSE OF VIDEO IMAGES;IMAGE QUALITY COULD BE CONTROLLED AND ADAPTED TO THE GEOLOGICAL MATERIAL BEING STUDIED, THIS BY VARYING THE FEED VOLTAGE OF THE EMITTING TUBE; 
- A DIAPHRAGM WILL ALLOW ADAPTATION TO THE SIZE AND SHAPE OF THE SAMPLES TO BE ANALYSED; 
- THE VIDEO IMAGE WILL ALLOW REAL-TIME OBSERVATION, AS OPPOSED TO CLASSICAL RADIOGRAPHY WHERE STATIC IMAGES ARE OBTAINED AFTER AN EXPOSURE OF LONG DURATION. IT WILL THUS BE POSSIBLE TO GIVE A MOVEMENT TO THE CORE AND TO OBTAIN AN ANALOG-TYPE LOG THAT CAN BE CORRELATED WITH LOGS OBTAINED BY OTHER TECHNIQUES; 
- THE VIDEO IMAGES CAN BE DIGITALLY PROCESSED, FOR GRAPHIC RESTITUTION AND THE RECOGNITION OF GEOLOGICAL SUBJECTS. 

THE CONTRACT WILL COMPRISE THE FOLLOWING STAGES; 
A.DRAWING UP A DETAILED PILOT STUDY OF THE APPARATUS (CONSULTING OF SUPPLIERS OF COMPONENTS, ACCURATE DEFINITION OF THE APPARATUS AND ITS OPERATING ENVIRONMENT). 
B.CONSTRUCTION OF THE APPARATUS WITH THE ASSISTANCE OF SPECIALIZED SUPPLIERS. 
C.TESTING THE APPARATUS ON VARIOUS CORES OF GEOLOGICAL MATERIALS THAT CAN BE ENVISAGED FOR THE DISPOSAL OF RADIOACTIVE WASTE, SUCH A CLAY (IN A SLEEVE), SALT, GRANIT AND SCHIST/SHALE. 
D.ADAPTING AND DEVELOPING IMAGE-PROCESSING SOFTWARE WITH THE FOLLOWING OBJECTIVES : 
- GEOLOGICAL EXPLORATION AND IDENTIFICATION (LITHOLOGY, STRUCTURE, TEXTURE) WITHOUT DAMAGE TO THE STRUCTURAL INTEGRITY OF THE SAMPLE; 
- TESTING THE SUITABILITY OF THIS TECHNIQUE FOR IDENTIFICATION OF AN HOMOGENEOUS ZONE AND FOR LOCALIZING MECHANICAL AND GEOCHEMICAL TESTS, IN PARTICULAR IN THE CASE OF SAMPLES COVERED BY A SLEEVE; 
- IMPROVING THE LEGIBILITY AND USE OF THE IMAGES/USE OF IMAGE-PROCESSING SOFTWARE DEVELOPED FOR REMOTE-SENSING PURPOSES; 
- CORRELATING THE X-RAY LOGS WITH OTHER BOREHOLE OR GEOLOGICAL LOGS. 
E.PREPARING DOCUMENTS THAT PRESENT THE RESULTS OBTAINED FOR VARIOUS TYPES OF GEOLOGICAL MATERIALS, AND FOR DIFFERENT STRUCTURES AND TEXTURES BEING STUDIED.";;;;CSC;Bureau de Recherches Géologiques et Minières (BRGM);FR;;;
8674;1573;IBASS;;FP1-ESPRIT 1;;FP1;Intelligent Business Application Support System;01/01/1987;01/04/1988;;"The IBASS project aimed to develop tools and techniques to allow the end-user to create and maintain an office application without the need for direct help from a professional systems analyst or designer. It was also intended to develop a system in which the user would be supported by knowledge-based help systems (both individual and organisational). A further objective was that the system to be developed should work in an object-oriented (real world) environment by means of adaptable human-machine and machine-machine interfaces. 
The feasibility study, which was undertaken to specify prototype demonstrator systems, was based on a four-component model: a user interface, an organisation modelling system, a design manager, and an object-oriented environment. 
Specific applications (budgeting, order processing, loan application) were studied with the intention of identifying common characteristics needing support. The communications required for networking, based on the ISO standards and their interfaces with the organisational tools to be developed, were investigated from the point of view of supplying services and utilities for supporting fully integrated applications both at company and intercompany levels. 
The project aimed to develop tools and techniques to allow the end user to create and maintain an office application without the need for direct help from a professional systems analyst or designer. It was also intended to develop a system in which the user would be supported by knowledge based help systems (both individual and organisational). A further objective was that the system to be developed should work in an object oriented (real world) environment by means of adaptable human machine and machine machine interfaces. The feasibility study, which was undertaken to specify prototype demonstrator systems, was based on a 4 component model: a user interface, an organisation modelling system, a design manager, and an object oriented environment. Specific applications (budgeting, order processing, loan application) were studied with the intention of identifying common characteristics needing support. The communications required for networking, based on the international standardization organisation (ISO) standards and their interfaces with the organisational tools to be developed, were investigated from the point of view of supplying services and utilities for supporting fully integrated applications both at company and intercompany levels.

The project described the problem and presented the results of a study on organisational and technical requirements. There is a need for a sound methodology to guide the design of applications software, and for a set of tools to aid in the effective implementation of new information technology (IT) technologies for any organisation.
The IBASS scenario presented at the end of the project described the problem and presented the results of a study on organisational and technical requirements. 
Summarising the achievements, it was clearly apparent that there is a need for a sound methodology to guide the design of applications software, and for a set of tools to aid in the effective implementation of new IT technologies for any organisation. Onepartner therefore decided to use object-oriented programming as the foundation for future work. 
Further investigation and developments of powerful sets of tools and designs, to be tested in various business and organisations, will be proposed for a future project within ESPRIT. These tools and designs are intended to provide systems in an integratedenvironment that are much more flexible and user-friendly in an than those currently available. The integration of the tools should lead to a faster development of new types of more user-friendly applications by manufacturers and software houses.";;;;;Siemens Nixdorf Informationssysteme AG;DE;"BULL SA;Datamont Feruzzi Group SpA;Langton Ltd;South Bank University";"FR;IT;UK";
8668;1634;MIAC;;FP1-ESPRIT 1;;FP1;Multipoint Interactive Audiovisual Communication;07/01/1986;07/04/1988;;"The objective of this project was to develop a system for the simultaneous communication of speech, images and data between persons at two or more widely separated locations, using ISDN and other 64 Kbit/s networks. 
The objective of this project was to develop a system for the simultaneous communication of speech, images and data between persons at two or more widely separated locations, using integrated services digital network (ISDN) and other 64 Kbit per second networks. A demonstrator was developed in a real environment, made up of a multipoint international audioconference system with visual and office system aids, interconnected using terrestrial and satellite links. The signal and protocol structure developed is applicable to a wide range of other audiovisual services, and has been adopted as part of the CEPT audiographic teleconference recommendation (T/N31-02). The conferencing system was successfully demonstrated in multipoint mode between 8 European locations in April 1988. The demonstration included high quality speech, chairman's control and meeting aids.
A demonstrator was developed in a real environment, made up of a multipoint international audioconference system with visual and office system aids, interconnected using terrestrial and satellite links. The signal and protocol structure developed is appli cable to a wide range of other audiovisual services, and has been adopted as part of the CEPT audiographic teleconference recommendation (T/N31-02). The conferencing system was successfully demonstrated in multipoint mode between eight European locations  in April 1988. The demonstration included high-quality speech, chairman's control and meeting aids (facsimile, SPTV, telewriter). A follow-on project in this area, MIAS (project 2684), is further developing this system in the areas of ISDN and multimedia facilities.";;;;;British Telecom plc (BT);UK;"CNET France Télécom;TELEFONICA INVESTIGACION Y DESARROLLO;PTT RESEARCH TELEMATICA LABORATORIUM;Alcatel Face Standard SpA;THOMSON TRT DEFENSE;Centro Studi e Laboratori Telecomunicazioni SpA";"FR;ES;NL;IT";
8480;1535;APHRODITE;;FP1-ESPRIT 1;;FP1;A PCTE Host-Target Distributed Testing Environment;14/01/1987;14/01/1989;;"The objective of APHRODITE was to provide an initial basis for a PCTE host-target distributed testing environment. 
The project's aims were to produce: 
-a set of recommendations for programming and interfacing target systems, and for allowing their testing in a distributed host-target environment 
-a prototype of this PCTE host-target distributed testing environment, implemented on a network of PC/AT hosts and including one or more target systems 
-a preliminary evaluation of the prototype to assess the viability of the system as a production system. 
The objective was to provide an initial basis for a portable common tool environment (PCTE) host target distributed testing environment. The project's aims were to produce a set of recommendations for programming and interfacing target systems, and for allowing their testing in a distributed host target environment; a prototype of this PCTE host target distributed testing environment, implemented on a network of personal computer/(PC/AT) hosts and including one or more target systems; and a preliminary evaluation of the prototype to assess the viability of the system as a production system. A study of the adaptions necessary to port Emeraude/PCTE to the CHORUS system was made. Development of a version of CHORUS enabling the distribution of a PCTE based CHORUS was achieved. A LOTOS model of the system was developed which proved useful in identifying weaknesses of the approach.
A study of the adaptations necessary to port Emeraude/PCTE to CHORUS was made. 
Development of a version of CHORUS enabling the distribution of a PCTE-based CHORUS was achieved. A LOTOS model of the system was developed which proved useful in identifying weaknesses of the approach. 
Exploitation 
Development tools and services for a PCTE host-target distributed testing environment, developed from the results of APHRODITE, are being marketed by Chorus Systmes.";;;;;Bull SA;FR;"UNIV DE LIEGE;PHILIPS-TRT;Ferranti International plc;Chorus Systèmes SA;Delphi SpA";"BE;FR;UK;IT";
8481;1542;INDOC;;FP1-ESPRIT 1;;FP1;Intelligent Documents Production Demonstrator;01/01/1987;01/07/1988;;"The objectives of INDOC were to: 
-validate an approach incorporating the use of AI techniques in Advanced Information Systems for the production of complex documents 
-define the requirements of a user tool-set for document development and maintenance. 
The production of complex documents such as a contract, a licence, an insurance policy, etc, requires the merging of operational information (data and images), handled by traditional tools, with advanced text processing. 
This project investigated AI techniques that were thought capable of contributing to this process by developing and maintaining large sets of conceptual descriptions of documents and organizational procedures. 
The feasibility of the approach was to be tested on a restricted but real-life application domain, for which a demonstrator was to be built. An evaluation of the results was designated to assess the portability of the approach to a large application. 
Te objectives were to validate an approach incorporating the use of artificial intelligence (AI) techniques in advanced information systems for the production of complex documents, and to define the requirements of a user tool set for document development and maintenance. The production of complex documents requires the merging of operational information (dataand images), handled by traditional tools, with advanced text processing. This project investigated AI techniques that were thought capable of contributing to this process by developing and maintaining large sets of conceptual descriptions of documents and organizational procedures. The feasibility of the approach was tested on a restricted but real life application domain, for which a demonstrator was built. An evaluation of the results was designated to assess the portability of the approach to a large application. A methodology for knowledge acquisition and analysis which provides a reference pattern for questioning experts and classifying the knowledge acquired was agreed. The application domain for the demonstrator was the creation of legal deeds and contracts. The 2 cases analysed were the production of deeds of gift and sale by a lawyer's office, and the production of deeds for a loan receipt by a bank. A formalized behavioural model was defined, and the requirements for a formal language for conceptual modelling stated. A language for the definition of presentation schema was specified. A prototype of the inference machine is being implemented in Prolog.
A methodology for knowledge acquisition and analysis which provides a reference pattern for questioning experts and classifying the knowledge acquired was agreed. 
The application domain for the demonstrator was the creation of legal deeds and contracts. The two cases analysed were the production of deeds of gift and sale by a lawyer's office, and the production of deeds for a loan receipt by a bank. 
A formalised behavioural model was defined, and the requirements for a formal language for conceptual modelling stated. A language for the definition of presentation schema was specified. A prototype of the inference machine is being implemented in Prolog. 
Exploitation 
The INDOC project made a strong contribution to the fundamental harmonisation of AI techniques by proving and verifying their effectiveness in a real-life application. The demonstrator produced by INDOC can be exploited by European industry to evaluate the use of AI and KB techniques within real-life information systems.";;;;;Applied Research Group SpA;IT;"INESC-INSTITUTO DE ENGENHARIA DE SISTEMAS E COMPUTADORES;EPSILON SOFTWARE LTD";"PT;EL";
8445;1513;PEACOCK;;FP1-ESPRIT 1;;FP1;Software Development Using Concurrently Executable Modules;01/01/1985;01/04/1989;;"The objective of the PEACOCK project was to design and implement a unified family of languages covering the whole software life-cycle. All these languages were to use the concept of Concurrently Executable Modules (CEM), and have a common signature (abstract syntax). 
The objective of the project was to design and implement a unified family of languages covering the whole software life cycle. All these languages use the concept of concurrently executable modules (CEM), and have a common signature (abstract syntax). Development of a unified set of design and implementation languages covering whole of the design process (the Pi language) was completed. A single model of system structure, defined in a language reference manual, was specified. A model of system development was constructed, based on the model of system structure, and a primer giving guidelines for its use was prepared.
The project achieved the following: 
-completion of the development of a unified set of design and implementation languages covering the whole of the design process (the Pi language) 
-the specification of a single model of system structure, defined in a language reference manual 
-the construction of a model of system development based on the model of system structure, and a primer giving guidelines for its use. 
Exploitation 
Plessey will be using the method in its RACE ARISE project and in product development. The concepts and methods are being used at Dortmund University in other projects. The use of the Pi language concepts is envisaged, though no support tools were developed.";;;;;Roke Manor Research Ltd;UK;"Universität Fridericana Karlsruhe (Technische Hochschule);EUROSOFT SYSTEMS SA;University of Hertfordshire;Universität Dortmund";"DE;FR;UK";
8466;1158;ATES;;FP1-ESPRIT 1;;FP1;Advanced Techniques Integration into Efficient Scientific Application Software;01/04/1986;01/04/1990;;"The ATES project aimed to incorporate advanced techniques in an integrated software development environment within the area of scientific application programming, with particular emphasis on efficiency. 
A programming language (ATES), integrating three advanced techniques, was to be developed, incorporating: 
-abstraction of data types and operators 
-relational database programming for scientific data 
-formal specification and proof, defined by taking into account the specificity of scientific programming. 
 An efficient software development environment was to include a proof subsystem allowing the user to validate an algorithm with respect to some specification, or to get error information if the algorithm is invalid. The adequacy of the whole system was to be evaluated by developing application libraries. 
The project aimed to incorporate advanced techniques in an integrated software development environment within the area of scientific application programming, with particular emphasis on efficiency. A programming language, integrating 3 advanced techniques, was developed, incorporating abstraction of data types and operators, relational database programming for scientific data, and formal specification and proof, defined by taking into account the specificity of scientific programming. An efficient software development environment would include a proof subsystem allowing the user to validate an algorithm with respect to some specification, or to get error information if the algorithm is invalid. The adequacy of the whole system was evaluated by developing application libraries. The system consists of an algorithmic programming language derived from Fortran, some program manipulation tools, and an execution environment. The proof system was completed. A specification language was designed, allowing the semantics of the user's operators, including selectors and iterators, to be defined. The method uses models like the vector dominance model (VDM) and the preconditions and postconditions of the operators. The conditions are expressed in the VDM models and use predicates of the first order logic. Axiom chapters give properties of the models. A proof language allows a description to be given of how one type implements another type giving a so called 'abstract function'. Loop invariants can also be given to the system. Generation of verification conditions has been defined using Hoare's logic and the semantics of the programming language. The architecture of the whole system was also designed. Several applications of the library and proof system to finite element method demonstrated.
ATES was initially based on the 4X programming system. It consists of an algorithmic programming language derived from Fortran, some program manipulation tools, and an execution environment. 
The ATES proof system was completed. A specification language was designed, allowing the semantics of the user's operators, including selectors and iterators, to be defined. The method uses models like VDM and the pre- and post-conditions of the operators. The conditions are expressed in the VDM models and use predicates of the first-order logic. Axiom chapters give properties of the models. A proof language allows a description to be given of how one type implements another type giving a so-called 'abstract function'. Loop invariants can be also given to the system. Generation of verification conditions has been defined using Hoare's logic and the semantics of the programming language. The architecture of the whole system was also designed. 
Several applications of the ATES library and proof system to finite element method were demonstrated. 
The present interest of ATES for scientific developers lies in its capacity to: 
-allow more reliability and confidence in the development, being either formal at the specification or at the proof level 
-act as an appropriate environment for scientists and mathematicians 
-increase productivity, in particular during the maintenance phase, by the use of the libraries 
It is now planned to have a tape (running the ATES version of 4X, and including the proof system) and user manuals are available since the end of 1990. 
An information dissemination workshop was held in June 1990, and 25 industrial representatives participated. 
A book presenting the ATES results has been published in the 'ESPRIT series' of Springer Verlag. 
Exploitation 
Industrial and commercial use of both the applications and the ATES system are currently planned by the consortium.";;;;;CISI Ingénierie SA;FR;PHILIPS SA;BE;
8328;1465;AMICE;;FP1-ESPRIT 1;;FP1;A European Computer-Integrated Manufacturing Architecture;01/10/1984;01/02/1989;;"The objectives of this project were to: 
-design an open systems architecture for CIM 
-define a set of concepts and rules to facilitate the building of future CIM systems 
-support migration of existing implementations.
The objectives of this project were to design an open systems architecture (OSA) for computer integrated manufacture (CIM), to define a set of concepts and rules to facilitate the building of future CIM systems and to support migration of existing implementations.
CIM-OSA is composed of a consistent set of complementary reference models capable of modelling enterprise requirements in terms of functions, information, resources and organisation and of modelling the implemented CIM systems derived from the requirements model. A key part of the implementation model is the integrated infrastructure (IIS), dealing with the definition of the integrating services, such as communications, information, machine and human front ends and the business process. This IIS provides a common platform to integrate the heterogeneous manufacturing and information technology environments. The IIS builds on and uses the upper layers of the International Standards Organization (ISO) open systems interconnection model. The work is complementary to the manufacturing automation protocols (MAP) initiative and to communications network for manufacturing applications (CNMA). CIM-OSA is complementary to the ISO open distributed processing (ODP) initiative. A document defining the CIM-OSA reference architecture specifications has been published.
CIM-OSA is composed of a consistent set of complementary reference models capable of modelling enterprise requirements in terms of functions, information, resources and organisation, and of modelling the implemented CIM systems derived from the requirements model. A key part of the implementation model is the Integrated Infrastructure (IIS), dealing with the definition of the integrating services, such as communications, information, machine and human front-ends, and the business process. This IIS provides a common platform to integrate the heterogeneous manufacturing and information technology environments. 
The IIS builds on and uses the upper layers of the ISO Open Systems Interconnection model. The work is complementary to the Manufacturing Automation Protocols (MAP) initiative and to CNMA (ESPRIT project 955). CIM-OSA is complementary to the ISO Open Distributed Processing (ODP) initiative (ESPRIT Project 2267, ISA). A document defining the CIM-OSA reference architecture specifications has been published. 
Exploitation 
 The project has actively promoted the architecture in the consortium, the industry and relevant standardisation organisations. The CIM-OSA modelling framework has been accepted as ENV 40 003 (European pre-standard) by the CEN/CENELEC member countries. It  is also an active work item in ISO TC184. Promotion will be significantly supported by the available of the IIS and modelling tool prototypes. These prototypes will be used to validate the CIM-OSA release 1 and to demonstrate the capabilities of CIM-OSA. The architecture will be employed by both users and vendors in the consortium in evaluating and planning their future developments.";;;;;CAP GEMINI INNOVATION;FR;"Dornier System GmbH;AEG Olympia AG;Aérospatiale Société Nationale Industrielle SA;ALCATEL TITN;Fiat Aviazione SpA;IBM Deutschland GmbH;Volkswagen AG;PROCOS A/S;Italsiel SpA;MBLE;Seiaf SpA;ATT NEDERLAND B.V.;International Computers Ltd (ICL);Hewlett Packard France;British Aerospace plc;Siemens Nixdorf Informationssysteme AG;Digital Equipment GmbH;Rheinisch-Westfälische Technische Hochschule Aachen (RWTH);Bull SA";"DE;FR;IT;DK;BE;NL;UK";
8442;1511;COOP;;FP1-ESPRIT 1;;FP1;2-D Coherent Optical Dynamic Processor;03/03/1986;03/03/1989;;"The objective of COOP was to develop and implement an optical processor for pattern recognition based on the most recent technological developments. The feasibility of parallel optical signal processing was to be demonstrated using a spatial light modulator (electrically and/or optically), a solid-state laser, and non-linear components based on the Four Wave Mixing (FWM) process, allowing real-time modification of the correlation function or alternatively matched filters. By improving the spatial light modulator a corresponding improvement in processor performance was expected, leading ultimately to a resolution of 1200 x 1200 pixels, in parallel, at a standard TV frame-rate. 
The system was to be demonstrated and evaluated on a robotic application. 
The objective was to develop and implement an optical processor for pattern recognition based on the most recent technological developments. The feasibility of parallel optical signal processing was demonstrated using a spatial light modulator, a solid state laser, and nonlinear components based on the four wave mixing (FWM) process, allowing real time modification of the correlation function or alternatively matched filters. A process for growing high optical quality bismuth silicon oxide (BSO) crystals of 50 mm diameter was developed. Electrically addressed spatial light modulators and optically addressed spatial light modulators were realised. Exploratory studies on the next generation of supported liquid membrane (SLM) led to the development of 2-dimensional arrays of quantum wells. Two system architectures were studied systems using dynamic correlation (continuous or pulsed);
and systems using filtering algorithms. Pulsed correlation showed good stability and reproducibility. However, due to the low level of maturity of this technology and its complexity, the second option was considered when building the industrial prototype. Various filtering techniques were considered and experimented on. Due to limitations of technology, the pure nonredundant filtering techniques (well suited for the robotic application) could not be implemented. Instead, simpler optically produced matched spatial filters, implemented in a single 4 channel filter, were used. In this way a correlator coupled to a robot was developed for pattern recognition purposes. It resulted in a very good recognition rate, good determination of the position, but rather poor angle measurement. The main difficulty encountered in the multichannel approach was the simultaneous alignment of all the channels. Despite these difficulties, the system is equivalent to a 200 Mips processor.
Excellent results on both materials on components were obtained: 
-a process for growing high optical quality BSO crystals of 50 mm diameter was developed 
-electrically addressed (TFT/liquid crystal) spatial light modulators were realised 
-Optically addressed (BSO/ liquid crystal) spatial light modulators were realised. The BSO/LC valves were initially addressed by CRT and later by a TFT/LC matrix, giving significant improvements. 
-More exploratory studies on the next generation of SLMs led to the development of 2-D arrays of quantum wells. 
Furthermore, two system architectures were studied and experimented on: 
-systems using dynamic correlation (continuous or pulsed) 
-systems using filtering algorithms. 
Pulsed correlation showed good stability and reproducibility. However, due to the low level of maturity of this technology and its complexity, the second option was considered when building the industrial prototype. 
Various filtering techniques were considered and experimented on. 
Due to limitations of technology, the pure non-redundant filtering techniques - well-suited for the robotic application - could not be implemented. Instead, simpler optically produced matched spatial filters, implemented in a single four-channel filter, were used. 
In this way a correlator coupled to a robot was developed for pattern recognition purposes. It resulted in a very good recognition rate, good determination of the position, but rather poor angle measurement. The main difficulty encountered in the multichannel approach was the simultaneous alignment of all the channels. 
Despite these difficulties, the system is equivalent to a 200 Mips processor; improvements could lead to an operating frequency of 1 KHz (a requirement of HDTV) and an increased number of channels (parallelism). 
Exploitation 
In this project various techniques and technologies were developed and tested either by simulation or experimentation. 
The results obtained are of great value for the progress of optical processing which, by its very nature, allows real-time and wave-band applications. 
Moreover, a first prototype working in an industrial environment has been developed and experimented on. It is the initial step in the attempt to develop robust low-cost systems based on optical processing.";;;;;THOMSON CSF;FR;"Thomson CSF;UNIV LIBRE DE BRUXELLES;GEC-Marconi Materials Technology Ltd";"FR;BE;UK";
8414;881;FORFUN;;FP1-ESPRIT 1;;FP1;Formal Description of Arbitrary Systems by means of Functional Languages;01/05/1986;01/05/1990;;"The FORFUN project aimed to develop a prototype of a general purpose system description environment based on so-called 'system semantics'. 
System semantics is an extension of the denotational semantics of programming languages in the sense that it is applicable to arbitrary systems, with various properties of a system described by corresponding meaning functions. 
A prototype general-purpose system description environment based on functional languages and extended with primitives of system semantics was developed. 
Another goal of the project was the design of a prototype system description language for two specific areas: analogue electronic circuits and digital systems (including VLSI). 
System semantics is an extension of the denotational semantics of programming languages in the sense that it is applicable to arbitrary systems, with various properties of a system described by corresponding meaning functions. A prototype general purpose system description environment based on functional languages and extended with primitives of system semantics was developed. Another goal of the project was the design of a prototype system description language for 2 specific areas: analogue electronic circuits and digital systems (including very large scale integration (VLSI)). The feasibility of the approach was demonstrated through case studies using the system description language to describe digital and analog electronic circuits. A general language for system semantics, GLASS, was defined, and a support environment specified. Implementation of the environment is underway through the construction of a coherent set of program generators to support the languages Miranda, Pascal and C. Demonstrations were made in the support of analogue and digital design. Although requiring further development, the basic paradigm shows an important development in the description of systems.
The feasibility of the approach was demonstrated through case studies using the system description language to describe digital and analog electronic circuits. 
A general language for system semantics, GLASS, was defined, and a support environment specified. 
Implementation of the environment is underway through the construction of a coherent set of program generators to support Miranda, Pascal and C. 
Demonstrations were made in the support of analogue and digital design. Although requiring further development, the basic paradigm shows an important development in the description of systems. 
Exploitation 
The partners held a seminar to explain the project results to VLSI designers in industry and thus to support their eventual exploitation. 
An academic partner is applying the results in analogue circuit design in other projects. 
An industrial partner has started the informal transfer of technology to IMEC, the Belgian Inter-University Microelectronics Centre.";;;;;KATHOLIEKE UNIVERSITEIT NIJMEGEN;NL;"BELL TELEPHONE MFG CO NV;TECHNISCHE UNIVERSITEIT DELFT;SAGANTEC BV";"BE;NL";
8487;1598;REPLAY;;FP1-ESPRIT 1;;FP1;Replay and Evaluation of Software Development Plans using Higher-Order Meta Systems;12/02/1987;12/02/1990;;"The objective of REPLAY was to provide evidence of the feasibility of reusing development plans and their component modules within the process of creating industrial software. The project aimed to advance the rather poorly understood domain of reusability. 
Beside building on progressive generalisation of case studies, REPLAY explored both top-down replay of developments and bottom-up assembly of components. The possibilities of continually controlling these development plans was investigated by means of abstract interpretation and modelling of operational properties. 
This project made extensive use of the DEVA language defined in the TOOL-USE project (510). 
The objective was to provide evidence of the feasibility of reusing development plans and their component modules within the process of creating industrial software. Current domains under analysis are replays of development through several different technical approaches: the transformational style of developments; proof steps for data type representations or rectification in the Vienna development method (VDM) context; and composition of programs from components through a graphical connection language. The examples used for the observation and experimentation of these techniques are different development scenarios of a common problem extracted from a large application in biology; human leucocyte antigen (HLA) typing. This problem has been analysed using a symbolic approach with a different implementation target. This case study has been used to show the integration of techniques of the project, namely: transformationdevelopments driven by propogation of operational properties; an integrated top down and bottom up style of development using functional and relational styles for the composition of development parts; integration of methods (VDM algebraic methods) and support of these methods. A set of tools was designed and implemented for the support of the various approaches: the DEVA environment has been modified to support specific operations for reusing formal developments; the LPG environment has been modified and extended by an information system to support the reuse of algebraic components; and a library interconnection language (LIL) has been implemented, offering a graphical interface with facilities for the bottom up relational assembly of components.
Current domains under analysis are replays of development through several different technical approaches: 
-transformational style of developments 
-proof steps for data type representations or rectification in the VDM context 
-composition of programs from components through a graphical connection language. 
The examples used for the observation and experimentation of these techniques are different development scenarios of a common problem extracted from a large application in biology: Human Leucocyte Antigen (HLA) typing. It is presently tackled on large computers by statistical techniques. This problem has been analysed in the REPLAY context using a symbolic approach with a different implementation target. 
This case-study has been used to show the integration of techniques of the project, namely: 
-transformation developments driven by propagation of operational properties 
-integrated top-down and bottom-up style of development using functional and relational styles for the composition of development parts 
-integration of methods (VDM algebraic methods) and support of these methods. 
During the final period of the project, a set of tools was designed and implemented for the support of the various approaches: 
-the DEVA environments, coming from the companion project TOOL-USE, has been modified to support specific operations for reusing formal developments 
-the LPG environment, designed by LIFIA, has been modified and extended by an information system (F1) to support the reuse of algebraic components 
-a Library Interconnection Language (LIL) has been implemented, offering a graphical interface with facilities for the bottom-up relational assembly of components. 
Exploitation 
Although no industrial product has stemmed from the project, the knowledge gained should be valuable in achieving reusability in the longer-term and brings nearer the dramatic improvements of productivity and quality that could follow. 
The project also helped to start the industrialisation of the software related to the HLA case study by a new project launched in the SPRINT research programme.";;;;;CISI Ingénierie SA;FR;"ALPHA S.A.I.;CRI A/S;E2S - EXPERT SOFTWARE SYSTEMS NV;Office National d'Études et de Recherches Aérospatiales (ONERA)";"EL;DK;BE;FR";
8465;1117;KIWI;;FP1-ESPRIT 1;;FP1;Knowledge-Based User-Friendly System For the Utilisation of Information Bases;24/02/1986;24/02/1989;;"The objective of KIWI was to develop a knowledge-based user-friendly system for managing access to external information bases. Four aspects were emphasised: 
-a knowledge representation formalism, through the development and use of the OOPS language, based on an object-oriented approach 
-an Advanced Database Environment (ADE), based on the combination of logic programming and databases 
-the integration of the knowledge representation formalism and ADE within a single concept 
-an intelligent interface between the end-user and the system, based on graphics. 
The objective was to develop a knowledge based user friendly system for managing access to external information bases. Four aspects were emphasised: a knowledge representation formalism, through the development and use of the OOPS language, based on an object oriented approach; an advanced database environment (ADE), based on the combination of logic programming and databases; the integration of the knowledge representation formalism and ADE within a single concept; an intelligent interface between the end user and the system, based on graphics. The definition of the OOPS language and its prototype implementation, together with specification of the architecture of the global system, are available. The architecture of the ADE layer has also been achieved, and theoretical work on the concept of the bottom up execution of Prolog programs was performed. State of the art results in the handling of recursive queries were achieved. Demonstrations have been given of the user interface (UI), the knowledge handler (KH) and the advanced database environment (ADE), which are the three main modules, and of the full system. A tight integration between the UI and KH was achieved and shown to be possible between KH and ADE. A final prototype including all the modules of the system (loosely integrated in what concerns KH and ADE) was successfully demonstrated.
The definition of the OOPS language, and its prototype implementation together with specification of the architecture of the global system, are available. 
The architecture of the ADE layer has also been achieved, and theoretical work on the concept of the bottom-up execution of Prolog programs was performed. 
State-of-the-art results in what concerns the handling of recursive queries were achieved. 
Demonstrations have been given of the User Interface (UI), the Knowledge Handler (KH) and the Advanced Database Environment (ADE), which are the three main KIWI modules, and of the full KIWI system. A tight integration between the UI and KH was achieved and shown to be possible between KH and ADE. 
A final prototype including all the modules of the KIWI system (loosely integrated in what concerns KH and ADE) was successfully demonstrated. 
Exploitation 
The combination of the deductive powers of logic programming with the data management capabilities of large relational databases will result in powerful computing environments, which will dominate computing in the 1990s. 
KIWI will contribute substantially to meeting the key requirements for establishing such environments in a multi-paradigm way using object-oriented techniques, logic programming, rule-based formalisms, etc. It will do this especially in the areas of knowledge representation formalisms, recursive queries handling, and the execution of Prolog programs. 
The results of KIWI constitute the basis for the ESPRIT II project KIWIS (2424).";;;;;Consorzio per la Ricerca e le Applicazioni di Informatica;IT;"UNIVERSITAIRE INSTELLING ANTWERPEN;CRI - DDC;Enidata SpA;PHILIPS GLOEILAMPENFABRIEKEN NV;Università degli Studi di Roma 'La Sapienza';Institut National de Recherche en Informatique et en Automatique - INRIA";"BE;DK;IT;NL;FR";
8472;1271;SED;;FP1-ESPRIT 1;;FP1;SETL Experimentation and Demonstrator;15/07/1986;15/07/1988;;"SED was a design method demonstrator. It intended to provide early feedback on the viability of using PCTE-OMS to support the kind of prototyping and design techniques which have been successfully used to develop a full Ada translator within 16 person years. The main vehicle for these prototyping and design techniques is the SETL language. 
The project was associated with projects 835 (PROSPECTRA-D) and 1265 (SEDOS-DEMO). 
The project was intended to provide early feedback on the viability of using portable common tool environment and object modelling system (PCTE-OMS) to support the kind of prototyping and design techniques which have been successfully used to develop a full Ada translator. A prototype environment for the set theoretical language (SETL) was implemented under MENTOR (an environment generator for programming languages developed at INRIA). Some important results were the definition of a flexible grammer for the full first order logic extended with abstraction terms; the definition of a MENTOR environment for low level rewrite rules, using this new grammer, and based on RAPTS; and the translation of SETL into Ada. The requirements for developments in cartography were outlined; this particular domain demonstrated the utility of SETL despite the need to handle complex data structures and modularity.
A prototype environment for SETL (Set Theoretical Language) was implemented under MENTOR (an environment generator for programming languages developed at INRIA). 
Some important results were: 
-definition of a flexible grammar for the full first-order logic extended with abstraction terms 
-definition of a MENTOR environment for low-level rewrite rules, using this new grammar, and based on RAPTS 
-translation of SETL into Ada 
-Requirements for developments in cartography; this particular domain demonstrated the utility of SETL despite the need to handle complex data structures and modularity. 
Work was performed on automatic translation into Ada. 
Exploitation 
The project assessed the adequacy of SETL as a specification and implementation language for industrial use.";;;;;THOMSON CSF;FR;"UNIV OF PATRAS;Enidata SpA;Conservatoire National des Arts et Métiers (CNAM);Universität Hildesheim";"EL;IT;FR;DE";
8462;1525;PCTE;;FP1-ESPRIT 1;;FP1;A Basis for a Portable Common Tool Environment;01/10/1984;01/04/1989;;"The objectives of the PCTE project were to define the necessary interface specifications and to implement the basic utilities and working prototypes of a portable common tool environment (PCTE) to support tool development. The tool and user interface specifications were to be maintained as public domain documents to ensure common tool portability. 
Portable common tool environment (PCTE) is a set of interface specifications for a public (software) tools interface. It is intended to be used as the basis for the construction of integrated software engineering environments.By defining a standard public tool interface, such as environment can be constructed more economically from a range of different vendors' products, since adherence to the standard would make such tools independent of a particular vendor or particular hardware. In addition, there is now widespread recognition that computer aided software engineering (CASE) requires a control common database to act as a repository for all the development objects (code, designs, requirements, etc) which are an integral part of large scale software development. PCTE provides sophisticated mechanisms for such a repository by means of its object management system. It should also be stressed that PCTE is primarily targeted towards the open systems market.

The objectives of the project were to define the necessary interface specifications and to implement the basic utilities and working prototypes of a portable common tool environment (PCTE) to support tool development. The tool and user interface specifications were to be maintained as public domain documents to ensure common tool portability. The kernel which constitutes the environment was evaluated by developing a configuration management system (CMS), a knowledge based programer's assistant (KBPA), and other tools. Specifications of the tool and user interfaces were made, and are available in the public domain under the control of the independent PCTE interfaces management board (PIMB). Both Ada and C specifications are also available. Various prototypes of the PCTE functionalities have been demonstrated. Commercial implementations are already available on the market. An Ada versions of the PCTE object modelling system (OMS) and tool interfaces is available in order to ensure that the PCTE can provide the basis for an efficient Ada project support environment.
The kernel which constitutes the environment was evaluated by developing a Configuration Management System (CMS), a Knowledge-Based Programmer's Assistant (KBPA), and other tools. 
Specifications of the tool and user interfaces were made, and are available in the public domain under the control of the independent PCTE Interfaces Management Board (PIMB). Both Ada and C specifications are also available. 
Various prototypes of the PCTE functionalities have been demonstrated. Commercial implementations are already available on the market (Emeraude on Bull SPS7 and Sun 3). An Ada version of the PCTE OMS and tool interfaces is available in order to ensure that the PCTE can provide the basis for an efficient Ada project support environment. 
Exploitation 
PCTE provides a European standard for support environment interfaces enabling the growth of a software tools market and the efficient, coherent development of large systems across multi-company development teams. Links are presently being established withvarious European national programmes and European development agencies, and industry prospects appear good for achieving a high level of coordination. 
PCTE is used in national programmes and EUREKA projects, and is forming the basis for international efforts to build standard programmer environments. 
 The PCTE Interfaces Management Board (PIMB) is controlling the interfaces and will be in charge of their evolution. Particular attention is given to standardisation through the activities of ECMA Technical Committee 33. Many tool designers and developers have adopted these interfaces in Europe, and the Ada version will have a considerable impact in the US.";;;;;Bull SA;FR;"Ingegneria C. Olivetti and C. SpA;International Computers Ltd (ICL);GEC Marconi Research Centre;SIEMENS-NIXDORF INFORMATIONSSYSTEME AG;Siemens Nixdorf Informationssysteme AG";"IT;UK;DE";
8640;1606;TYPEWRITERS;;FP1-ESPRIT 1;;FP1;European Typewriters and Other Workstations Integration;01/03/1986;01/03/1988;;"This project investigated the role of typewriters in a postulated future office automation environment where communicating typewriters, word processors, personal computers and PABXs will interwork in distributed systems. The work programme contained the following objectives: 
First phase: 
-analysis of technological and market trends for typewriters and workstations 
-investigation of functional integration between typewriters and other office automation devices. 
Second phase: 
-specification of a common code for all the European languages and specification of editing function commands for exchanging information between European typewriters 
-proposal of communications protocols (PABX or LAN) 
-proposal of a general architecture for interconnecting European typewriters and workstations via PABX or LAN. 

A number of areas where the evolution of the technology should be investigated were identified. These are processing facilities, printing, storage, the user interface, display systems and communications. These investigations were extended to cover functional user requirements for low-cost and high-cost office workstations, integration of text and graphics, graphics software environments, and the use of existing standards. The results were as follows: 
-a proposal for a framework for handling mixed-mode communication was produced. 
-cost trends of base technologies for typewriters and PCs were analysed. 
-a report containing standard primitives for a new intergraphics system was produced. 
Exploitation 
The results achieved are expected to be transferred to new products.";;;;;Ingegneria C. Olivetti and C. SpA;IT;"POLITECNICO DI TORINO;TA-TRIUMPH-ADLER AG;AEG Olympia Office GmbH";"IT;DE";
8653;1624;IT-UPTAKE;;FP1-ESPRIT 1;;FP1;Human and Economic Factors in IT-Uptake Processes;07/04/1986;07/04/1988;;"The IT-UPTAKE project focused on the role of human, organisational and economic (HOE) factors in the effective and productive uptake of information technology (IT) application systems in complex work environments. The project explicitly addressed IT uptak e in more traditionally organised work environments and in the new forms of work organisation made possible by teleworking. While office systems were the major focus of concern, the project also addressed developments in computer-integrated manufacturing (CIM). 
The project focused on the role of human, organizational and economic (HOE) factors in the effective and productive uptake of information technology (IT) application systems in complex work environments. The project explicitly addressed IT uptake in more traditionally organized work environments and in the new forms of work organization made possible by teleworking. While office systems were the major focus of concern, the project also addressed developments in computer integrated manufacturing (CIM). The major ouputs were a generic model of HOE factors in the IT uptake process; an instrument for the collecting of information concerning these HOE factors in working environments; field trials of the generic model and instrument in working environments; and guidelines concerning the management of HOE factors in the uptake of IT and telework in working environments. A third version of the model and instrument was developed and refined through field testing in a wide range of user environments. This version integrated expertize and perspectives from 4 areas: human and organizational factors in IT/telework uptake processes; traditional business systems analysis techniques; vendors' perspectives on IT/telework uptake processes; and expertise concerning the diffusion potential and uptake dynamics of telework. An analysis of the potential and the uptake dynamics of telework was conducted through large scale empirical surveys, and their indications refined through detailed field trials undertaken in a range of user environments. On the basis of this and the modelling work, the refined extended model provides an integrated conceptual framework where IT and telework uptake processes are embedded in broader organizational change processes. A testbed investigation was undertaken using traditional business systems analysis techniques, and an IT system proposed which would support and improve the functioning of the testbed site. A guidelines package for managing IT/teleworking upt ake processes in user environments was produced. This document emphasises the management of human, organizational and economic factors, and its targeted at managing IT/telework uptake in user environments.
The major outputs were a generic model of HOE factors in the IT uptake process; an instrument for the collection of information concerning these HOE factors in working environments; field trials of the generic model and instrument in working environments;and guidelines concerning the management of HOE factors in the uptake of IT and telework in working environments. The project complemented and worked with project 56, FAOR. 
A third version of the model and instrument was developed and refined through field testing in a wide range of user environments. This version integrated expertise and perspectives from four areas: human and organisational factors in IT/telework uptake processes; traditional business systems analysis techniques; vendors' perspectives on IT/telework uptake processes; and expertise concerning the diffusion potential and uptake dynamics of telework. This extended and refined version of the model provided a comprehensive framework for conceptualising, understanding and investigating (or intervening in) IT/telework uptake processes in user environments. 
An analysis of the potential and the uptake dynamics of telework was conducted through large-scale empirical surveys, and their indications refined through detailed field-trials undertaken in a range of user environments. On the basis of this and the modelling work, the refined extended model provides an integrated conceptual framework where IT and telework uptake processes are embedded in broader organisational change processes. 
 A testbed investigation was undertaken using traditional business systems analysis techniques, and an IT system proposed which would support and improve the functioning of the testbed site. Significant features of this proposed systems design concern the systematic incorporation of human, organisational and teleworking perspectives into the final specification for the design of the proposed IT application system. 
A guidelines package for managing IT/teleworking uptake processes in user environments was produced. This document emphasises the management of human, organisational and economic factors, and is targeted at managing IT/telework uptake in user environments. It is also of considerable benefit to suppliers of IT products and services and to IT manufacturers.";;;;;IRISH CLEANING OCODE;IE;"EMPIRICA GESELLSCHAFT FUER KOMMUNIKATIONS- UND TECHNOLOGIEFORSCHUNG MBH;WORK RESEARCH CENTRE LTD";"DE;IE";
8642;295;PAPER;;FP1-ESPRIT 1;;FP1;The Paper Interface;01/09/1984;01/09/1989;;"This project dealt with techniques for the automatic transfer of information between electronic systems and paper documents. Three major components of paper interface systems were identified: 
From paper: 
-Scanning of composed paper documents. Separation into image, graphics, and text. Recognition and encoding of text and graphics for further processing to generate an electronic document. 
To paper: 
-Generation of a paper document from electronically filed information. 
With paper: 
-Recognising and encoding text and graphics information as it is produced. 
These components have been integrated into one system, with particular emphasis for each task, on aspects such as the human interface, editing, and the document architectures ODA/ODIF and ISO 8613. The project objectives included the specifications of requirements, a technology study, system and functional specifications, and the development of algorithms. 
The project dealt with techniques for the automatic transfer of information between electronic systems and paper documents. 3 major components of paper interface systems were identified:
(scanning of composed paper documents, separation into image, graphics, and text and recognition and encoding of text and graphics for further processing to generate an electronic document);
to paper (generation of a paper document from electronically filed information);
with paper (recognizing and encoding text and graphics information as it is produced).

These components have been integrated into 1 system, with particular emphasis for each task, on aspects such as the human interface, editing, and the document architectures. The project developed a broad set of subsystems. These are: multicolour scanner, page printer, graphics analyser, image analyser, text recognition module, module for online handwriting recognition, document rendition software for combining text and graphics.

A demonstrator system was produced which integrated the 3 project components, data entry (scanner or graphics tablet), analysis software and printer, for evaluation and demonstration.
The project developed a broad set of subsystems. These are: 
-multicolour scanner 
-page printer 
-graphics analyser 
-image analyser 
-text-recognition module 
-module for online handwriting recognition 
-document rendition software for combining text and graphics. 
A demonstrator system was produced which integrated the three project components (data entry (scanner or graphics tablet), analysis software and printer) for evaluation and demonstration. This integrated system was successfully demonstrated at the 1989 ESPRIT Conference. 
Exploitation 
The results are expected to be incorporated into office products from 1990 onwards. They will contribute to establishing a link between the paperless parts of the office of the future and those areas where paper will remain an indispensable element. The provision of this link will meet the growing need to avoid incompatibility between paperless and paper-bound tasks.";;;;;AEG ELECTROCOM GMBH;DE;"VALVO BAUELEMENTE PHILIPS GMBH;Ingegneria C. Olivetti and C. SpA;PLESSEY RESEARCH";"DE;IT;UK";
8814;1640;IES;;FP1-ESPRIT 1;;FP1;Information Exchange System Support Services;24/07/1985;24/07/1990;;"Theobjectives of the IES Support Services project were to: 
Identify and implement services complementary to or in support of present and future IES services. 
Monitor user needs in relation to their information exchange requirements in cooperative R&D community programmes and to propose ways in which these can be satisfied through existing or new IES services. 
Edit, publish and distribute a publication reporting on IES projects and developments as well as other major European-wide activities related to information exchange through telecommunication networks.
The objectives of the information exchange system (IES) support services project were to: identify and implement services complementary to or in support of present and future IES services, to monitor user needs in relation to their information exchange requirements in cooperative research and development community programmes and to propose ways in which these can be satisfied through existing or new IES services and to edit, publish and distribute a publication reporting on IES projects and developments as well as other major European wide activities related to information exchange through telecommunication networks.
An online machine translation pilot service called COTEL was demonstrated.
A set of online databases, IES data collection was made available through the European Commission Host Organization (ECHO) in Luxembourg (this service will be transferred to CORDIS).
The first edition of Information Technology (IT) Atlas, a reference publication on public IT research and development activities in Europe was sponsored.
The pilot implementation of the PROTEAS database was launched.
The bimonthly IES News was published.
News via EuroKom electronic conferences was provided on topics such as European information technology standards news, news from the European institutions related to IT, and news on IT technological developments.
The startup phase of preliminary the Community research and development information service (CORDIS) as part of the VALUE programme within the Community research and development FRAMEWORK programme.

The project has been established to provide the European academic, industrial and governmental research community with a computer networking communications infrastructure based on open systems interconnection (OSI) protocols. The project includes a number of subprojects and the provision of pilot services to the user community. A number of these subprojects and services are now in place and have a direct impact on the working environment of the research community. They bring European wide connectivity in electronic mail, directories and information services, expanding on the services already available at local and national levels. Further subprojects and services are in the process of being established.
Since the contract began the project has: 
Tested and demonstrated an online machine translation pilot service called COTEL. This service was offered through a host in Luxembourg and the SYSTRAN programme, which could be accessed through public X.25 networks by any asynchronous telecommunication device. An interface allowing users to submit text files in the source language and receive a raw translation in the target language was developed and provided to interested users. The service was terminated when a commercial operator began to offer a si milar service. 
Launched a set of online databases, IES Data Collections, available through the European Commission Host Organisation (ECHO) in Luxembourg (this service will be transferred to CORDIS). 
Launched a multilingual telephone service, IES HELP-LINE, providing information and answers to questions on IES services and the IES in general (this service has now stopped). 
Sponsored the development of the first edition of Information Technology Atlas, a reference publication on public IT R&D activities in Europe. 
Launched the pilot implementation of the PROTEAS database, which contained information on R&D developments and prototypes with potential commercial applications (PROTEAS is now part of the VALUE programme). 
Published the bimonthly IES News. As of December 1990, 31 issues had been distributed to a European mailing list in excess of 10 000. From January 1991, IES News was merged with the News Review section of the new XIII Magazine, published by DGXIII. 
Provided news via EuroKom electronic conferences on topics such as European information technology (IT) standards news, news from the European institutions related to IT, and news on IT technological developments. 
Provided assistance in the start-up phase of preliminary the Community R&D Information Service (CORDIS) as part of the VALUE programme within the Community R&D FRAMEWORK programme.";;;;;IEGI;LU;"GRS;IOS;Expertel Consultants;NOUVEAU MEDIAS;FT Healthcare and Cartermill International Ltd";"UK;LU";
8639;1604;SPEECH;;FP1-ESPRIT 1;;FP1;Investigation into the Effective Use of Speech at the Human-Machine Interface;01/06/1985;01/07/1986;;"The SPEECH project addressed voice applications in a wide range of environments. The objectives were to: 
-determine the current state of the art (hardware and software) and the current areas of actual and imminent application 
-explore the potential for future applications 
-determine the additional new requirements for hardware and software so that the potential application areas can be realised 
-provide a five-year forecast of the likely development of speech technology, with specific reference to application areas. 
The project addressed voice applications in a wide range of environments. The objectives were to:
determine the current state of the art (hardware and software) and the current areas of actual and imminent application;
explore the potential for future applications;
determine the additional new requirements for hardware and software so that the potential application areas can be realized;
provide a 5-year forecast of the likely development of speech technology, with specific reference to application areas.

The results of the research showed that the effectiveness of an application was often governed by the appropriateness of the microphones and other ancillary equipment with properly calibrated equipment, consistently high background noise did not detract from recognition. A well designed vocabulary on a low quality recognizer could out perform a badly designed vocabulary on superior equipment. Many of the current successful applications used small vocabularies organized into context selected sets. Large vocabularies tended to encourage the notion that unrestricted language can be used, which is not yet possible.

The most important considerations for the development of a successful system were that:
isolated word recognition systems perform satisfactorily;
several reliable speech synthesis systems can be used with speech recognition systems to give a completely hands free environment;
speech should be part of the overall design of a system;
implementation is successful (as this requires more knowledge than the average potential system designer has available);
the greatest expenses do not arise from the cost of the voice equipment but the cost of thorough system design and integration.

The major considerations for future development are discussed.
There were several significant findings: 
-The effectiveness of an application is often governed by the appropriateness of the microphones and other ancillary equipment. 
-With properly calibrated equipment, consistently high background noise (up to 90 dBA) does not detract from recognition. 
-A well-designed vocabulary on a low-quality recogniser can out-perform a badly designed vocabulary on superior equipment. 
-Many of the current successful applications use small vocabularies organised into context-selected sets. Large vocabularies tend to encourage the notion that unrestricted language can be used, which is not yet possible. 
A comprehensive final report is available which includes a list of conclusions and recommendations. These are the most important considerations for the development of a successful system: 
-Isolated word-recognition systems perform satisfactorily; connected speech is possible with good equipment and good design. Continuous speech recognition is unreliable or extremely specialised and expensive. 
-There are several reliable speech synthesis systems that can be used with speech recognition systems (for example, with touch-tone telephones for dial-in enquiry systems) to give a completely hands-free environment. 
-Speech should be part of the overall design of a system; success is less likely when speech is added to a current package. 
-Successful implementation requires more knowledge than the average potential system designer has available. The suppliers' supporting software, technical descriptions and documentation tend to be poor. 
-The greatest expenses do not arise from the cost of the voice equipment but the cost of thorough system design and integration. 
The major considerations for future developments are: 
-Continuous speech recognition systems require research into and analysis of phonetic and linguistic factors and need to be implemented via knowledge-based interpreters on faster and cheaper processors. This is unlikely within the next ten years. 
-Speech synthesis applications are the most likely for early widespread development, especially by telephone companies. 
-The industrial area is the most amenable to speech recognition applications with current equipment. Further exploitation in the office environment can only come from speech synthesis and with better continuous speech recognition. 
-The next generation of systems will analyse and store speech based on phonemes; this will cut down storage requirements, but will result in language and dialect dependencies. 
 -The achievement of true speaker-independent recognition, removing the need for 'enrolment' or 'voice training' for each new speaker, will be highly dependent upon the outcome of current knowledge-based system and algorithm research and is definitely som e way off. 
Exploitation 
Speech technology is already being successfully used, and, provided the current limitations are observed and taken account of in the design, there are good prospects for increased use of the technology in selected and restricted situations. Unrealistic expectations of the customer and over-selling by the suppliers, coupled with poor documentation, are producing a large number of failed projects, causing prospective beneficiaries to delay their commitment. Improvements in the basic technology are continuing. Continuous speech recognition is not available commercially, but neither are the systems ideas or designs that could make effective use of it. It has become clear from limited experimentation that considerable complexity in software may be necessary todeal with even quite limited vocabularies and restricted syntax where interpretation is called for. On the other hand, the benefits of simple speech input coupled with synthesised voice prompting have been demonstrated publicly by the project team. Theyhave shown the benefit of totally hands-free control and the value of a well-designed, simple command syntax.";;;;;British Maritime Technology Cortec Ltd;UK;"Fincantieri Cantieri Navali Italiani SpA;Voice Systems International;International Computers Ltd (ICL)";"IT;UK";
8663;1631;IWS;;FP1-ESPRIT 1;;FP1;Intelligent Workstation;01/03/1985;01/03/1989;;"This project aimed to develop a complete system to help office workers do their job. In particular, office activities were modelled (documents, organisation and procedures) and these representations used to provide advice on actions required. Hardware andsoftware aspects were concerned with application-oriented developments and the user interface. For this purpose the project was divided into six modules: 
 -The assembly of the hardware for the construction of the workstation. Dedicated hardware, such as the filtering mechanisms developed during the first year, were taken into account in assembling the workstation and servers. The hardware was selected from products available on the market. 
-The operating system of the workstation. This was network-oriented and supported multitasking and synchronisation with all the necessary mechanisms for increasing the reliability of the distributed system. 
-The implementation of the LISP environment and Knowledge Representation System (KRS). 
-The layer of office system tools that embed office semantics. 
-Concrete applications implemented with the office system tools. 
-The improvement of the user interface. This module was divided into three parts: natural language processing and an author system; enhancing the user interface with multimedia features (sound and image); and defining and implementing a conceptual modelof the user interface. 
The project used artificial intelligence (AI) techniques to design an office system that employed both knowledge about office organization and procedures, and the necessary tools (natural language and multimedia) for an easy to use interface with the user. The workstation hardware, based on the BULL Metaviseur provided a table top office engine with a large, fast access memory capacity, efficient graphics and voice support, a 32-bit microprocessor, Ethernet communications support and a telephone interface.
The operating system environment was a Unix-based and had efficient graphic and audio support. The intelligent environment is made up of a LE-LISP compiler with its object oriented and virtual graphics extensions. A set of natural language processing (NLP) tools were built for English and Dutch. A dialogue system implemented above the knowledge representation system (KRS) used these tools to enable natural language query expressions onthe office model and natural language answer formulations.
The KRS was tested and extended to include the fast construction of knowledge based applications. The user interface management system (UIMS) was developed as a tool for assisting the easy design and reimplementation of office application user interfaces. This is related to the development of ACHILLES, a general tool for the faster specification and generation of user interfaces for particular applications.
The project used AI techniques to design an office system that employed both knowledge about office organisation and procedures, and the necessary tools (natural language and multimedia) for an easy-to-use interface with the user The basic components and tools for complex applications were successfully developed and verified. Interim versions of several prototypes were built and demonstrated at the Hannover Fair and the ESPRIT Conference Week. 
The workstation hardware, based on the BULL Metaviseur, provides a table-top office engine with a large, fast-access memory capacity (40-190 Mbytes on a 5.25' hard disk), efficient graphics and voice support, a 32-bit microprocessor, Ethernet communications support and a telephone interface. 
The operating system environment is Unix-based and has efficient graphic and audio support. The intelligent environment is made up of a LE-LISP compiler with its object-oriented and virtual graphics extensions. 
A set of Natural Language Processing (NLP) tools were built for English and Dutch. A dialogue system implemented above the KRS uses these tools to enable natural language query expressions on the office model and natural language answer formulations.The KRS was tested and extended to include the fast construction of knowledge-based applications. KRS has been proved to be ideally suited for research laboratories investigating advanced knowledge-representation issues. At the same time it can also be used as a knowledge engineering environment for the construction of complex interfaces, or for other knowledge-based tasks. 
The User Interface Management System (UIMS) was developed as a tool for assisting the easy design and reimplementation of office application user interfaces. This is related to the development of ACHILLES, a general tool for the faster specification and generation of user interfaces for particular applications. 
Exploitation 
 A complete prototype of an office workstation connected to servers through a network and based on artificial intelligence techniques is available. The results will be immediately transferable into a broad spectrum of workstations. These will be the focal point of information systems in the 1990s. Spin-offs from the IWS have already been introduced in product developments. 
In the areas of specific exploitation: 
 -Bull are developing a programmatic interface for the X.400 mail system used in a multimedia server. A graphics-oriented browsing tool derived from GSE will be used in conjunction with the server. Bull is also expanding its activities in X-Windows by act ively participating in X-Windows development activities within the scope of OSF. 
-The ACHILLES system has been used in the large MUSE project funded by NATO, assisting the development and reimplementation of the MUSE system's highly complicated user interface. This work has been undertaken by Forth. 
-Oc and the Katholieke Universiteit Nijmegen both participated in a national project on natural language processing, Stimuerings Project Informatica Nederland (SPIN). 
-A spin-off company (Knowledge Technologies CV) has been set up in Italy for the commercialisation of KRS and to contribute to KRS in southern Europe.";;;;;BULL SA;FR;"VRIJE UNIVERSITEIT BRUSSEL;KATHOLIEKE UNIVERSITEIT NIJMEGEN;OCE-NEDERLAND BV;FORTH-RESEARCH CENTER OF CRETE;Institut National de Recherche en Informatique et en Automatique - INRIA";"BE;NL;EL;FR";
8419;1497;RAISE;;FP1-ESPRIT 1;;FP1;Rigorous Approach to Industrial Software Engineering;01/01/1985;01/01/1990;;"The RAISE project aimed to create a formally based software development method together with a comprehensive support environment. RAISE is an enhancement of the VDM method, and maintains several intrinsic properties of this, such as model-based specification techniques and the 'Invent and Verify' development strategy. 
The development process, described by 'project graphs', was to be mathematically modelled in terms of logical systems (institutions eg equational logic, temporal logic), their transformations, system descriptions in various logical systems, and transformations of descriptions. Operational models of the project graphs were to be related to the activities of project managers, software engineers, programmers and project librarians. 
A wide-spectrum language supporting specification design was to be defined. Extensions of the model-based VDM method, particularly for the specification of concurrent systems, were to be considered, together with property-based methods and other model-based methods. 
Tools supporting the RAISE methodology were to be built (first in prototype form, then in production quality form), several industrial applications undertaken, and training and educational material produced. 
The project produced the following results. Firstly, a specification language. This is a wide spectrum language suitable for expressive high level abstract specifications as well as low level detailed designs. The specification language offers facilities for specifying sequential and parallel systems and for structuring specifications, and it supports applicative and imperative styles combined with axiomatic, implicit or explicit specification techniques. The specification language is equipped with a formal semantics enabling proofs of and reasoning about properties of specifications. Secondly, a development method. This is based on the notion of stepwise refinement in which software development proceeds in a number of increasingly concrete steps. The method is rigorous in the sense that it supports a completely formal development but it does not insist on formality. The level of formality appropriate to each particular development can be chosen. Thirdly a tool set supporting method and language. The heart of the tool set is a library for storing specifications and developments. Version control and configuration management is integrated with the library, as well as browsing tools for navigating and querying. Other tools are language and method specific: a type checking syntax directed editor for the specification language a pretty printing tool for it; translators from the specification language to various programming languages; and cross referencing tools and proof tools. The proof tools include a proof obligation generator, a simplifier to discharge proof obligations automatically, and a proof editor to assist in dealing with those left. Many tools were generated by the Cornell synthesiser generator (a tool that generates structure editors from attribute grammars). This in itself ensures a uniform interface of the tools, but careful planning of available functionality and online help led to the creation of an integrated tool set. The tools run on Unix workstations using the X Window system. Fourthly, technology transfer material which includes courses and seminars on all aspects of the project, with a target audience ranging from high level managers to development and maintenance engineers, and encompassing 1 to 2 hour overview seminars, educational courses of a few days, and week long training courses.
The RAISE project produced the following results: 
 -Specification Language. This is a wide-spectrum language suitable for expressive high-level abstract specifications as well as low-level detailed designs. The specification language offers facilities for specifying sequential and parallel systems and fo r structuring specifications, and it supports applicative and imperative styles combined with axiomatic, implicit or explicit specification techniques. The specification language is equipped with a formal semantics enabling proofs of and reasoning about properties of specifications. 
 -Development Method. This is based on the notion of stepwise refinement in which software development proceeds in a number of increasingly concrete steps. The method is rigorous in the sense that it supports a completely formal development - one in which each step in a development is proven correct with respect to the former step - but it does not insist on formality. The level of formality appropriate to each particular development can be chosen. 
 -Tool-Set Supporting Method and Language. The heart of the tool-set is a library for storing specifications and developments. Version control and configuration management is integrated with the library, as well as browsing tools for navigating and queryi ng. 
 Other tools are language and method specific: a type-checking syntax-directed editor for the specification language and a pretty-printing tool for it; translators from the specification language to various programming languages; and cross-referencing too ls and proof tools. The proof tools include a proof obligation generator, a simplifier to automatically discharge proof obligations, and a proof editor to assist in dealing with those left. 
 Many tools were generated by the Cornell Synthesiser Generator (a tool that generates structure editors from attribute grammars). This in itself ensures a uniform interface of the tools, but careful planning of available functionality and online help led to the creation of an integrated tool-set. The tools run on Unix workstations using the X Window system. 
-Technology Transfer material. Includes courses and seminars on all aspects of RAISE, with a target audience ranging from high-level managers to development and maintenance engineers, and encompassing 1-2 hour overview seminars, educational courses of afew days, and week-long in-depth training courses. 
-A book on RAISE is to be published. 
Exploitation 
The tool-set is being used by ICL and Asea Brown Boveri. 
The emphasis of the entire RAISE project was on industrial usability. This has been ensured by undertaking, as a part of the project, realistic trials in industrial environments of the resulting product. One trial has been the formal specification of an X-ray telescope control system using RSL. 
RAISE will enhance the possibility of large-scale use of VDM-based methods in industrial applications. Large-scale use of RSL is also intended to be realised within the ESPRIT project LACOS (number 5383). 
The technology transfer process will be supported by the provision of educational material.";;;;;CRI-COMPUTER RESOURCES INTL. A/S;DK;"International Computers Ltd (ICL);BROWN BOVERI & CIE.";"UK;DK";
8473;1265;SEDOS-D;;FP1-ESPRIT 1;;FP1;SEDOS ESTELLE Demonstrator;03/07/1986;03/07/1989;;"The objectives were to demonstrate: 
-the maturity (applicability, efficiency, etc) of the SEDOS technology (project 410) for the design of open distributed systems by the development of an industrial prototype, the so-called 'ESTELLE Work Station' (an integrated toolset for the use of theESTELLE formal description technique, editor, translator, code generator, simulator motor and implementation motor) 
-the applicability of the ESTELLE language for the formal description and development of protocols for the interconnection of systems, done by means of an application-oriented evaluation (industrial networks, telecommunications and space). 
The project aimed to provide a precompetitive demonstration (ie applicability, efficiency, etc) of the SEDOS technology in different relevant fields. 
The objectives were to demonstrate the maturity of the SEDOS technology for the design of open distributed systems by the development of an industrial prototype, the so called ESTELLE workstation (an integrated toolset for the use of the ESTELLE formal description technique, editor, translator, code generator, simulator motor and implementation motor), and the applicability of the ESTELLE language for the formal description and development of protocols for the interconnection of systems, done by means of an application oriented evaluation. The ESTELLE workstation is running on SUN OS 4.0 and APPOLLO SR 10, and is to be implemented on other systems. The ESTELLE FDT has been standardized by the international standards organization in ISO 9074. The ESTELLE language has been developed to describe the services and protocols of the layers of open system interconnection (OSI) architecture. ESTELLE's potential application area is wider the OSI protocol specifications. It has been demonstrated the ESTELLE is a powerful tool for the description of distributed systems in many other important fields, such as telecommunications, computer integrated manufacturing (CIM) and office automation. The SEDOS ESTELLE demonstrator is now available, providing a basic set of prototype tools including a syntax oriented editor, a translator, a C code generator, a debugger, simulator, and an implementation kernel.
The ESTELLE workstation is running on SUN OS 4.0 and APPOLLO SR 10, and is to be implemented on other systems. 
The ESTELLE FDT has been standardised by ISO in ISO 9074. The ESTELLE language has been developed to describe the services and protocols of the layers of Open System Interconnection (OSI) architecture. ESTELLE's potential application area is wider than OSI protocol specifications. It has been demonstrated that ESTELLE is a powerful tool for the description of distributed systems in many other important fields, such as telecommunications, computer-integrated manufacturing (CIM) and office automation. 
The SEDOS ESTELLE demonstrator is now available, providing: 
-a basic set of prototype tools (EWS) including a syntax-oriented editor, a translator, a C code generator, a debugger, simulator, and an implementation kernel 
-the first results of the project evaluation task, conducted on 10 selected examples of industrial applications. 
Exploitation 
Distribution of the environment to European universities was undertaken in 1989 as part of the process of standardising the ESTELLE language. 
A product is being built which the partners will market. 
The last release of the ESTELLE workstation environment is now available via Verilog (F) for universities and non-profit research centres or for industries via CNET Lannion (F), LAAS (F) or ENTEL (E).";;;;;Verilog SA;FR;"E2S - EXPERT SOFTWARE SYSTEMS NV;Marben";"BE;FR";
8458;1106;PROLOG III;;FP1-ESPRIT 1;;FP1;Further Development of Prolog and its Validation by KBS in Technical Areas;28/01/1986;28/03/1990;;"The objective of this project was to design and implement a new Prolog, PROLOG III. The new language was to be designed to integrate reasoning mechanisms and numeric processes and to be based on the efficient integration of constraint resolution. It was to include the possibility of adding inequalities and arbitrary propositional well-formed formulae as constraints. 
The project intended to demonstrate the usefulness of PROLOG III for the construction of knowledge-based systems in technical areas, in particular in the diagnosis of faults in car injection systems, and to show the deduction of knowledge from an analysisof functional and structural designs. 
The objective of this project was to design and implement a new Prolog, PROLOG III. The new language was designed to integrate reasoning mechanisms and numeric processes and was based on the efficient integration of constraint resolution. It included the possibility of adding inequalities and arbitrary propositional formulae as constraints. Design, implementation and testing of a new algorithm were carried out to verify the degree of satisfaction of arbitrary well formed formulae in propositional logic. This algorithm exhibits satisfactory performance in a class of practical cases. A sufficiently general subset of arithmetic operators to be allowed in the inequalities appearing as constraints in PROLOG III clauses was chosen, in such a way that the solution of sets of such inequalities would be computationally efficient. Algorithms to solve inequalities were designed, complemented and tested. The first implementation of PROLOG III was revised and debugged, and new optimized simplification algorithms and floating point arithmetic implemented. A simple expert system was constructed using an expert system shell. The strategies for diagnosis and repair used by human specialists and their classification of knowledge were studied. Specification and implementation of a comprehensive expert system demonstrator, PROMOTEX II, which models components, entirely based on PROLOG III, was achieved and demonstrated. Characteristic curves of some component parts of the automobile have been studied and modelled in PROLOG III.
On the language side, the following results were obtained: 
-Design, implementation and testing of a new algorithm to verify the degree of satisfaction of arbitrary well-formed formulae in propositional logic. This algorithm exhibits satisfactory performance in a class of practical cases. 
 -Choice of a sufficiently general subset of arithmetic operators to be allowed in the inequalities appearing as constraints in PROLOG III clauses. This subset was chosen in a way that the solution of sets of such inequalities would be computationally eff icient. 
-Design, implementation, and test of algorithms to solve inequalities. 
-The first implementation of PROLOG III was revised and debugged, and new optimised simplification algorithms and floating point arithmetic implemented. 
On the application side, the following results were achieved: 
-Construction of a simple expert system using an expert system shell developed by one of the partners before the start of the project. 
-Study of the strategies for diagnosis and repair used by human specialists and their classification of knowledge. 
-Specification and full implementation of a pilot expert system. 
-Specification and implementation of a comprehensive expert system demonstrator, PROMOTEX II, which models components, entirely based on PROLOG III, was achieved and demonstrated. Characteristic curves of some component parts of the automobile have beenstudied and modelled in PROLOG III. 
Exploitation 
The expert system, PROMOTEX II, is being exploited by the industrial partners. 
Daimler-Benz and R. Bosch plan to internally exploit CLP techniques for diagnosis and test, and for CAD of components and of complex systems. 
Prologia has launched the first version of PROLOG III (October 1989) and is exploiting PROLOG III for specific applications development. 
Results of the project have been incorporated in ESPRIT II project 5246 (PRINCE).";;;;;Prologia SARL;FR;"Daimler-Benz AG;GESELLSCHAFT FÜR INGENIEURTECHNIKEN;ROBERT BOSCH GMBH;Université d'Aix-Marseille III (Université de Droit d'Économie et des Sciences)";"DE;FR";
8446;1514;EUROHELP;;FP1-ESPRIT 1;;FP1;Intelligent Help for Information Systems Users;01/11/1984;01/11/1989;;"The aim of EUROHELP was to find ways of helping information system users to make optimal use of the functions of information systems. The findings have been implemented operationally in the form of a prototype HELP system to provide guidelines, instructio ns and explanations in response to user requests for information system facilities. Intelligent computer-based assistance can be provided from the terminal while the system is in use, with the advice tailored to individual needs from knowledge of the use each has made. Among the trial implementations is a HELP system for UNIX-Mail. 
EUROHELP is a help system development system (HSDS) consisting of 3 components:
 an intelligent help system shell (IHSS);
 a set of tools enabling the development of an application model in an efficient and controlled manner, and allowing the shell to be refitted to certain hardware dependencies;
 a description of the usage of the above tools including a software design philosophy for applications with intelligent help.
 The HSDS is a collection of tools primarly concerned with the construction of application models, and currently exists in prototypical form. A second generation of HSDS tools is now being designed and implemented.

The aim was to find ways of helping information system users to make optimal use of the functions of information systems. The findings have been implemented operationally in the form of a prototype HELP system to provide guidelines, instructions and explanations in response to user requests for information system facilities. Intelligent computer based assistance can be provided from the terminal while the system is in use, with the advice tailored to individual needs from knowledge of the use each has made. Among the trial implementations is a HELP system for UNIX mail. The project defined a conceptual model for intelligent help systems (IHSS) which can be used as a framework for all further research in this area, and has also produced the following results: Firstly, an IHSS implemented on a Unix, common Lisp and X11 software platform, which embodies many of the research ideas generated by the project. Secondly, a detailed application model definition report. Thirdly, an integrated set of help system development system (HSDS) tools implented on a Unix, Common Lisp and X11 software platform, driven by a metamodel generated directly from the application model definition report. Lastly, a methodology to guide developers in the construction of application models.
The project defined a conceptual model for Intelligent Help Systems which can be used as a framework for all further research in this area, and has also produced the following four results: 
-an IHSS implemented on a Unix, Common Lisp and X11 software platform, which embodies many of the research ideas generated by the project 
-a detailed Application Model Definition report 
-an integrated set of HSDS tools implemented on a Unix, Common Lisp and X11 software platform, driven by a meta-model generated directly from the Application Model Definition report. 
-a methodology to guide developers in the construction of application models. 
Exploitation 
The Intelligent Help System Shell has been implemented and ported to a target environment. Demonstrations and the final review took place in July 1990. 
CRI and ICL have internal exploitation plans aimed at the reuse of the components of EUROHELP in product lines. 
The university partners will be incorporating the results in research projects and using them in teaching. 
The final report is available as a book.";;;;;UNIVERSITEIT VAN AMSTERDAM;NL;"International Computers Ltd (ICL);COURSEWARE EUROPE BV;University of Leeds";"UK;NL";
8410;865;MUMP;;FP1-ESPRIT 1;;FP1;Non-Monotonic Reasoning Techniques for Industrial Planning Applications;01/05/1986;01/05/1990;;"MUMP aimed to produce the prototype of a planning tool for industrial applications. The tool - called MUMP, MUlti-Method Planner - incorporates artificial intelligence techniques and automatic form feature recognition. The design of MUMP and the techniques it uses were chosen on the basis of practical experience with different process planning problems and were refined and tested in a manufacturing application. 
 MUMP is based on three basic components: an assumption-based truth maintenance system, a frame system and a special control mechanism. A set of methods, ranging from rule interpretation to skeletal planning, can be used for solving different aspects of a problem. MUMP is composed of modules containing the implementation of the different methods and that can be chosen in such a way to produce an optimal configuration for the type of problem to be solved. 
The project developed a prototype tool (called MUMP, multi-method planner) that incorporates artificial intelligence techniques and automatic form feature recognition. The design of MUMP and the techniques it uses were chosen on the basis of practical experience with different process planning problems and were refined and tested in a manufacturing application. MUMP is based on 3 basic components: an assumption-based truth maintenance system, a frame system and a special control mechanism. A set of methods, ranging from rule interpretation to skeletal planning, can be used for solving different aspects of a problem. MUMP is composed of modules containing the implementation of the different methods and that can be chosen in such a way to produce an optimal configuration for the type of problem to be solved. The development task has been concluded, producing all the modules foreseen for MUMP as well as the user and reference manuals. The system has been used for planning the machining of medium complexity aircraft parts and for several simpler problems. For the process planning application, a knowledge engineering approach was used to identify the form features and their attributes and to analyse and reproduce the task of a human expert. The form feature recogniser completed in the projectes can recognise features such as pockets (of any form), blind through holes, and protrusions and slots, all either isolated or combines (ie, nested). The planning kernel of process plans for prismatic parts with a quality comparable to that of a human expert.
The development task has been concluded, producing all the modules foreseen for MUMP as well as the user and reference manuals. The system has been used for planning the machining of medium-complexity aircraft parts and for several simpler problems. 
For the process planning application, a knowledge engineering approach was used to identify the form features and their attributes and to analyse and reproduce the task of a human expert. 
The form-feature recogniser completed in the project can recognise features such as pockets (of any form), blind and through holes, and protrusions and slots, all either isolated or combined (ie nested). The planning kernel of MUMP, using a special knowledge base, can produce complete process plans for prismatic parts with a quality comparable to that of a human expert. 
Exploitation 
The prototype of MUMP was completed in June 1990 and the prospects for exploitation are good. 
The AI group of Aeritalia has taken over internal customisation following a successful trial based on the machining of aircraft parts. 
Other partners have plans for exploitation of MUMP as an additional feature or selling point of their products and systems in industrial automation and in CAD.";;;;;Battelle-Institut eV;DE;"Elsag Bailey SpA;Aeritalia Società Aerospaziale Italiana SpA";IT;
8400;387;KRITIC;;FP1-ESPRIT 1;;FP1;Knowledge Representation and Inference Techniques in Industrial Control;01/01/1985;01/01/1988;;"The objective of KRITIC was to construct a set of tools for the development of expert systems for process control. 
The tool set was to be tested and demonstrated by designing and implementing two expert systems to assist maintenance, fault diagnosis, optimisation of data flows and control in an industrial process-control environment. The major attributes of this classof expert systems are: 
-a high level of organisational complexity 
-time-dependent reasoning 
-a large number of inputs and outputs 
-learning/adaptation. 
A consolidated set of basic tools for the development of expert systems in complex industrial process control environments was produced. The tools include: a knowledge representation language, AVALON; a rule based expert system shell, MIKIC (which originated from an academic development); two graphical description languages, G-MOD and V-GRAPH; a blackboard system, BBF; a planning system incorporating dependency directed backtracking, CELL-PLAN; and a high level environment for explicitly specifying the control flow, CELL-TISSUE. The tools have benefited from use in building the demonstrators. For example, the use of MIKIC in 2 demonstrator applications resulted in 2 sets of extensions, which were then merged into a 'Common MIKIC'. The research results from the project have been well integrated in tools, and validated by the demonstrators. For example, the work on truth maintenance systems (TMS) resulted in a novel use of the TMS to limit search in the rule base that, in turn, resulted in a combined MIKIC/TMS tool used in one of the demonstrators. Two demonstrators, the first for the control and diagnosis of advanced telecommunications switching systems, the second for the control of power distribution networks, were completed and made available to the partners for experimental purposes.
A consolidated set of basic tools for the development of expert systems in complex industrial process-control environments was produced. The tools include: a knowledge representation language, AVALON; a rule-based expert system shell, MIKIC (which originated from an academic development); two graphical description languages, G-MOD and V-GRAPH; a blackboard system, BBF; a planning system incorporating dependency-directed backtracking, CELL-PLAN; and a high-level environment for explicitly specifying the control flow, CELL-TISSUE. The tools have benefited from use in building the demonstrators. For example, the use of MIKIC in the two demonstrator applications resulted in two sets of extensions, which were then merged into a 'Common MIKIC'. 
The research results from the project have been well integrated in tools, and validated by the demonstrators. For example, the work on truth maintenance systems (TMS) resulted in a novel use of the TMS to limit search in the rule base that, in turn, resulted in a combined MIKIC/TMS tool used in one of the demonstrators. 
Two demonstrators, the first for the control and diagnosis of advanced telecommunications switching systems, the second for the control of power distribution networks, were completed and made available to the partners for experimental purposes. 
Exploitation 
The tools are being used by the partners in other projects. To facilitate their use by other organisations engaged in ESPRIT projects, they are being packaged, documented, and ported to SUN. 
MIKIC has been used in project 1592, TAO. Results of the project are being used in a project for satellite control, SATEXPERT, in conjunction with the results of project 820, QUIC.";;;;;Krupp Atlas Elektronik GmbH;DE;"Framentec SA;British Telecom plc (BT)";"FR;UK";
8408;1491;TOOL-USE;;FP1-ESPRIT 1;;FP1;An Advanced Support Environment for Method-Driven Development and Evolution of Packaged Software;15/10/1984;15/10/1989;;"TOOL-USE's objective was to develop techniques for the formal definition of methods used in the development of software. The project focused on one main idea, that the building of a support environment should be parameterised by methods expressed in a development language. It sought to achieve understanding and formal modelling of: 
-the software construction process 
-the application domains 
-target systems. 
The consortium intended to continue with the definition, implementation and evolution of a prototype environment for software development based on formally defined methods 
Techniques were developed for the formal definition of methods used in the development of software. The project focused on one main idea, that the building of a support environment should be parameterised by methods expressed in a development language. It sought to achieve understanding and formal modelling of the software construction process, the application domains, and the target systems. Starting from the requirements defined in an early stage of the project, the development language DEVA was specified and documented. A version of DEVA is available in prototype form, and tools to facilitate its use have been demonstrated. However, the specification of DEVA is not frozen, and it will be modified as and when the results of the intensive experimentation warrant it. Support tools for the prototype of a parameterised environment were demonstrated as well as the specification of a requirement requisition tool and method advisors.
Methods used in the development of software were explored and formalised. Starting from the requirements defined in an early stage of the project, the DEVA development language was specified and documented. 
A version of DEVA is available in prototype form for internal applications for the different partners, and tools to facilitate its use have been demonstrated. However, the specification of DEVA is not frozen, and it will be modified as and when the results of the intensive experimentation, that will ensue throughout any future developments, warrant it. 
In the final review, the support tools for the prototype of a parameterised environment were demonstrated as well as the specification of a requirement requisition tool and method advisors. 
Exploitation 
The production of environments in a near-automatic way, parameterised by the methodology used, provides the theoretical evolutionary path from the current generation of PCTE (Portable Common Tool Environment) environments to the next one. This will ensurethe compatibility of European industrial investment in software development facilities, and will be extremely useful for setting up case-studies on the use of the development language for office systems and computer-integrated manufacturing. 
However, a long period of refinement is anticipated before concepts developed inside this project are ready for commercial exploitation. In the meantime, their participation has created a pool of R&D knowhow among the partners' staff.";;;;;CISI Ingénierie SA;FR;"Gesellschaft für Mathematik und Datenverarbeitung mbH;GENERICS SOFTWARE LTD;UNIV CATHOLIQUE DE LOUVAIN;Office National d'Études et de Recherches Aérospatiales (ONERA)";"DE;IE;BE;FR";
8669;1059;DAMS-1;;FP1-ESPRIT 1;;FP1;Dynamically Adaptable Multiservice Switch;03/02/1986;03/02/1988;;"The objective of the project was to identify and exploit the relative advantages of a switch-oriented communications architecture with respect to a wide variety of traffic and services required in the office. Dynamic allocation of bandwidth (according to the varying needs of users) was investigated in order to manage the available bandwidth in the most efficient way. 
The objective of the project was to identify and exploit the relative advantages of a switch oriented communications architecture with respect to a wide variety of traffic and services required in the office. Dynamic allocation of bandwidth (according to the varying needs of users) was investigated in order to manage the available bandwidth in the most efficient way. Reports on the external requirements of an advanced private automatic branch exchange (PABX) and the services to be supported were produced, leading to the specification of an outline architecture based on an optical ring backbone. A technology study was completed showing the current availability of the component parts of the system. A marketing report highlighted the need and timeliness of the project whilst warning of the stiff competition from Japanese and US suppliers.
Reports on the external requirements of an advanced PABX and the services to be supported were produced, leading to the specification of an outline architecture based on an optical ring backbone. 
A technology study was completed showing the current availability of the component parts of the system. A marketing report by the subcontractor, Langtons (UK), highlighted the need and timeliness of the project whilst warning of the stiff competition fromJapanese and US suppliers. 
Exploitation 
Industrially exploitable results are expected by 1993. These will be based on R&D to be carried out following the study phase. This work is being followed up in project 2146, DAMS-2.";;;;;Roke Manor Research Ltd;UK;"JEAN LEFEBVRE TELECOM;Telenorma GmbH Bosch Telecom";"FR;DE";
8548;554;SPECTRE;;FP1-ESPRIT 1;;FP1;Submicron CMOS Technology;31/12/1984;31/12/1989;;"The objective was to develop the necessary building blocks for a 0.7micron CMOS process, primarily dedicated to the production of high-speed (within the limitations imposed by MOS) digital circuits. 
In order to allow the programme to proceed with the best chances of success, two main phases were identified and organised, the first focusing on an intermediate step at the 1 micronlevel, the second on the final 0.7micron CMOS family. Two additional ta sks were added to the original project at the end of the first year, making eight tasks in all. These addressed the topics of architecture, optical and electron-beam lithography, MOS structures, isolation, interconnect, and refractory metal gates. It was the responsibility of the first task to arrange the pilotline demonstration of the 1micron and submicron demonstrators; the other tasksprovided the technology inputs for this. 
The objective was to develop the necessary building blocks for a 0.7 micron complementary metal oxide semiconductor (CMOS) process, primarily dedicated to the production of high speed digital circuits.

2 main phases were identified and organised, the first focusing on an intermediate step at the 1 micron level, the second on the final 0.7 micron CMOS family.

The demonstrator of the 1 micron CMOS process was fabricated.

The demonstrator device is a multichip including:
a 4 K, 6-transistor SRAM;
a 4 K, 6-transistor SRAM;
an image processor;
modules for the extraction of electrical parameters, including the common test developed for electromigration studies.
In parallel, a 64 K, 6-transistor SRAM, whose size of 27 square millimetres prevented it from being included on the multichip, was processed in the same line, making use of the same process.

A logic circuit (70 000 transistors, 35 square millimetres, 54 MHz) has subsequently been realided in the 1 mircon process. Several technologies were also developed but were not included in the 1 micron demonstrator. This was the case for electron beam lithography.
Amongst other development technologies, 3 could be included as achievements of the first phase:
trench isolation (this technology was developed and demonstrated and found compatible with 5 V power supply);
metal gate transistor (the programme was pursued up to the processing of a 16 K SRAM memory);
2 aluminium layers (test devices gave good results down to pitches of 2.8 micron and 3.6 micron for the first and second metal respectively).

A submicron core process flow, that is, a common skeleton to which different technologies could be grafted was agreed and a common set of design rules was developed. To investigate the possible evolution toward a 0.5 micron process, special advanced rules were developed.
Functional circuits based on the developed submicron CMOS process modules were demonstrated, tested and fabricated. Large density chips (256 K SRAM; 1 Mbit erasable programmable read only memory (EPROM) plus sea of gates circuit) based on the common set of design rules were manufactured.
By the end of year three, the demonstrator of the 1 micron CMOS process had been fabricated by CNET. The process is an Nwell CMOS process, with polycide gates and two metal levels. The first metal level is formed by CVD tungsten. Isolation is based on an optimised LOCOS technique, while LDD with deposited oxide spacers was used to increase the reliability of Nchannel devices. 
The demonstrator device is a multichip including: 
-a 4K, 6-transistor SRAM by CNET 
-a 4K, 6-transistor SRAM by IMEC 
-an image processor by British Telecom (obtained from the Wafer-Scale Integration project, number 824) 
-modules for the extraction of electrical parameters, including the common test developed for electromigration studies. 
In parallel, a 64K, 6-transistor SRAM designed by MHS, whose size of 27mm2 prevented it from being included the multichip, was processed in the same line, making use of the same process. 
The access time of the 4KSRAM from CNET was 20 ns, limited by design, while the 64KSRAM by MHS showed parts with access time lower than 15ns and a stand-by current absorption of 10uA. A logic circuit (70000transistors, 35mm2, 54MHz) has subsequent 
ly been realised by CNET in the 1micron process issued by SPECTRE. 
Several technologies were also developed but were not included in the 1micron demonstrator. This was the case for Ebeam lithography, which after a three-year development was dropped due to the appearance on the market of Iline steppers and Gline lenses with good submicron performances. Amongst other development technologies, three could be included as achievements of the first phase: 
-Trench isolation: this technology was developed and demonstrated and found compatible with 5 V power supply. However, since comparable results could be obtained with a more conventional approach, the trench was not used in the final demonstration. 
-Metal gate transistor: the programme was pursued up to the processing of a 16K SRAM memory. Nevertheless, due to the lack of availability of the equipment, the work was stopped. 
-Two aluminium layers: test devices gave good results down to pitches of 2.8micron and 3.6micron for the first and second metal respectively. 
Exploitation 
By the end of December1987 the one-micron CMOS process results were disseminated throughout eleven companies and research laboratories located in five European countries. 
Additionally, Matra Harris successfully transferred the SPECTRE CMOS technology into its fast static RAM and microprocessor fabrication lines, and selected process steps are being integrated into the fabrication process of a 1M EPROM by STM. 
 During year four, the partners agreed on a submicron 'core' process flow, that is, a common skeleton to which different technologies could be grafted and a common set of design rules was developed. To investigate the possible evolution toward a 0.5micron process, special 'advanced' rules were developed for use by the research laboratories. 
 During year five, the process partners demonstrated and tested functional circuits based on the developed sub-micron CMOS process modules and fabricated at each of the five locations. The industrial partners manufactured large density chips (256K SRAM; 1 Mbit EPROM plus sea-of-gates circuit) based on the common set of design rules; in this way the project culminated in the provision of a multi-sourced state-of-the-art CMOS ASIC capability for Europe.";;;;;Centre National d'Études des Télécommunications (CNET);FR;"MATRA-MHS;United Kingdom Atomic Energy Authority (UKAEA);IMEC VZW;AARHUS UNIVERSITET;UNIV CATHOLIQUE DE LOUVAIN;Thomson Microelectronics Srl (SGS);Telettra SpA;British Telecom plc (BT);Consiglio Nazionale delle Ricerche (CNR);Bull SA";"FR;UK;BE;DK;IT";
8479;1527;SPEM;;FP1-ESPRIT 1;;FP1;Software Productivity Evaluation Model;01/05/1987;01/05/1990;;"The main objective of the SPEM project was to build an evaluation model of software development productivity for use across the spectrum of the software development industry. 
The main goals of the project were to: 
-contribute to the measurement, comparison management and improvement of software development productivity in an industrial context 
-contribute to the awareness and understanding of software productivity models and modelling, throughout the software development industry 
-construct, formalise, and offer as a standard, data definitions and data collection procedures proved as usable on software projects 
-develop, use and validate a prototype of a new model of software development productivity 
-cooperate with other projects in the metrics and models area, aiming at creating a mutually beneficial synergy with them. 
The main objective of the project was to build an evaluation model of software development productivity for use across the spectrum of the software developement industry. The main goals of the project were: to contribute to the measurement, comparison management and improvement of software development productivity in an industrial context; to contribute to the awareness and understanding of software productivity models and modelling, throughout the software development industry; to construct, formalize, and offer as a standard, data definitions and data collection procedures proved as usable on software projects; to develop, use and validate a prototype of a new model of software development productivity; and to cooperate with other projects in the metrics and models area, aiming to create a mutually beneficial synergy with them. Development cost models were reviewed and classified, salient cost and quality determinates identified, and the measurement techniques and data definitions for the drivers reviewed and collated. A preliminary phase, to test data definitions, collection procedures, etc, was specified and performed, and the results studied. A second phase, incorporating the lessons of the first, was defined. The second phase included new date definitions, collection procedures, and new data verification and analysis techniques. Data was collected, verified and analysed from 30 industrial projects. Cost and quality determinants in the collected data were analysed for their importance and a prototype productivity evaluation model built.
Development cost models were reviewed and classified, salient cost and quality determinants identified, and the measurement techniques and data definitions for the drivers reviewed and collated. 
A preliminary phase, to test data definitions, collection procedures, etc., was specified and performed, and the results studied. 
A second phase, incorporating the lessons of the first, was defined. The second phase included new date definitions, collection procedures, and new data verification and analysis techniques. 
Data was collected, verified and analysed from 30 industrial projects. 
Cost and quality determinants in the collected data were analysed for their importance and a prototype productivity evaluation model built. 
Exploitation 
The model should allow: 
-the measurement of software development productivity across a spectrum of software application areas 
-comparison of the software development factors of any specific project with a general database of such factors, to support more accurate planning and prediction on further projects 
-identification of detrimental development factors in a project, and indicating the need of intervention to achieve favourable development factors, supported by evidence from a database of existing projects. 
The data collection should allow: 
-data definitions and a collection manual to be offered as a standard to international bodies, offered as a standard for other metrics projects, and exploited commercially as a data collection tool for the software development industry 
-the database to be offered as a starting point to other metrics projects, and exploited commercially as a database of 'anonymous' projects from the software development industry. 
At the time of writing, there have already been approaches from other projects with respect to the data definitions, collection manual and database.";;;;;FUIGI ITALIANA;IT;"United Kingdom Atomic Energy Authority (UKAEA);SOFEMASA;VERILOG SA;O DATI ESPANOLA S.L.;CERCI";"UK;ES;FR";
8650;1621;TRUE-COLOUR;;FP1-ESPRIT 1;;FP1;Acquisition, Compression and Reproduction of True-Colour Image Documents;21/04/1986;21/04/1989;;"The four main objectives of this project were to: 
-develop highly sophisticated colour image acquisition, processing and enhancement systems 
-define and develop colour image coding and compression algorithms, using techniques which took into account human perceptual characteristics 
-develop an advanced non-impact printing technique for colour images with fine tone definition 
-test different non-impact printing techniques for the rendition of true colour (the results showed the ink-jet technique be too slow, leading to the adoption of the thermal transfer technique for the final demonstrator). 
The objectives of this project were to:
develop highly sophisticated colour image acquisition, processing and enhancement systems;
define and develop colour image coding and compression algorithms, using techniques which took into account human perceptual characteristics;
develop an advanced nonimpact printing technique for colour images with fine tone definition;
test different nonimpact printing techniques for the rendition of true colour.

An integrated prototype was developed to demonstrate the result of the research, incorporating algorithms for:
colour transformation rules from red, green and blue (RGB) to cyan, magenta and yellow;
error diffusion intensity modulation techniques (the transformation and diffusion algorithms first developed for ink jet printers were adapted for wax thermal transfer printers);
compression ratios from 10 to 20 on RGB true colour images with a size of 512 by 512 pixels.

Studies and experiments were carried out on colour image acquisition and enhancement and a general software architecture, giving maximum flexibility, was defined and implemented.

All the programmes are embedded in the CIPLY package, which is a very general image processing package. The identifiable product is the CIPLY software package, which could be used for image processing. Other packages exist on the market, but CIPLY has more flexibility, making it easier to build an application.
An integrated prototype was developed to demonstrate the result of the research, incorporating algorithms for: 
-colour transformation rules from red, green and blue to cyan, magenta and yellow 
-error diffusion intensity modulation techniques (the transformation and diffusion algorithms first developed for ink-jet printers were adapted for wax thermal transfer printers) 
-compression ratios from 10 to 20 on RGB true-colour images with a size of 512 by 512 pixels. 
Studies and experiments were carried out on colour image acquisition and enhancement and a general software architecture, giving maximum flexibility, was defined and implemented. 
All the programmes are embedded in the CIPLY package, which is a very general image-processing package. The identifiable product is the CIPLY software package, which could be used for image processing. Other packages exist on the market, but CIPLY has more flexibility, making it easier to build an application. 
Exploitation 
 The TRUE-COLOUR project has promoted the use of colour documents in the office environment by developing new and advanced methods for colour image reproduction, storage and transmission. The consortium will exploit the project results industrially during 1990 in electronic colour processing systems and colour image reproduction peripherals.";;;;;Ingegneria C. Olivetti and C. SpA;IT;"KATHOLIEKE UNIVERSITEIT LEUVEN;INTERSYS GRAPHIC";BE;
8662;385;HUFIT;;FP1-ESPRIT 1;;FP1;Human Factors Laboratories in Information Technologies;01/12/1984;01/12/1989;;"The key objective of HUFIT was to provide the European IT industry with a means of developing world-class products more closely matched to the tasks, needs and characteristics of users, and made feasible and economic by the employment of user-centred design and development tools with effective, usable, and flexible user interfaces. 
The objective was to provide the European information technology (IT) industry with a means of developing world class products more closely matched to the tasks, needs and characteristics of users, and made feasible and economic by the employment of user centred design and development tools with effective, usable, and flexible user interfaces. Some of the tools developed are described below. The human factors toolset provides an integrated approach to user centred design for use by designers and human factors practitioners. The intelligent user interface design tool (INTUIT) is a tool for user centred design in the construction of usable application software, in particular the building of user interfaces. Both the display formats and dialogue management components of interface design can be developed with computer assistance from the system. The computer human factors information service is a bibliographic information service dealing specifically with the diverse field of computer human factors (CHF). The service provides online access to a database of bibliographic references. The rapid prototyping toolset enables and supports prototyping and rapid development of user interfaces for experimental, evaluation and implementations purposes. The tools have been developed on the basis of an extensive survey of user interface management systems and dialogue modelling approaches. The multimedia expert system is a demonstrator combining different forms of information presentation and their respective forms of dialogue techniques. Collections of guidelines and appropriate software components have been developed which allow the designer to choose appropriate combinations of media and interaction techniques suited for the particular application domain. On the basis of empirical studies, a direct manipulation design guide has been developed which provides well structured operational advice and examples for the design of direct manipulation interfaces. The system for learning re quirements provides a structured methodology and tools for determining learning requirements and procedural knowledge for performing defined tasks with interactive systems.
A variety of human factors methods and tools were developed for the design of usable IT products. They exist in different forms, ranging from simple paper-based ones to an IT-based decision-support system which contains a large amount of human factors knowledge. 
The most important methods and tools stemming from the project are: 
-HUFIT, Human Factors Toolset 
 This toolset provides an integrated approach to user-centred design for use by designers and human factors practitioners, and contains: User Requirements Specification Tools; QED - Quick Ergonomic Design; Usability Human Factors Tools; Methodology for th e Identification of User and Task Characteristics; Documentation Design Tool; CUSI - Computer User Satisfaction Inventory; and IT Support for Managerial Tasks. Prototypes of the tools were developed. They are: 
-INTUIT - Intelligent User Interface Design Tool 
 INTUIT is a tool for user-centred design in the construction of usable application software, in particular the building of user interfaces. Both the display formats and dialogue management components of interface design can be developed with computer ass istance from the system. 
-CHF - Computer Human Factors Information Service 
 This is a unique bibliographic information service dealing specifically with the diverse field of Computer Human Factors (CHF). The service provides online access to a database of bibliographic references with abstracts, conference reviews, book reviews, citations to books, reports, standards, conference proceedings and non-book materials and journals. 
-Rapid Prototyping Toolset (QUICK, Dialogue Manager, DIAMANT) 
 The purpose of this toolset is to enable and to support prototyping and rapid development of user interfaces for experimental, evaluation and implementations purposes. The tools have been developed on the basis of an extensive survey of user interface ma nagement systems and dialogue modelling approaches. QUICK is mainly concerned with speech interfaces. The Dialogue Manager supports the development of integrated graphical interfaces and has been further developed into a commercial product with numerous installations all over Europe. DIAMANT is an object-oriented tool which allows the development of integrated, dynamic multimedia interfaces. 
-MULTEX, Multimedia Expert System 
 This is a demonstrator combining different forms of information presentation (text, graphics, images, animation, video, speech) and their respective forms of dialogue techniques. Collection of guidelines and appropriate software components have been deve loped which allow the designer to choose appropriate combinations of media and interaction techniques suited for the particular application domain. 
-Direct Manipulation Design Guide 
On the basis of empirical studies, a design guide has been developed which provides well-structured operational advice and examples for the design of direct manipulation interfaces. 
-System for Learning Requirements, SANE 
This toolkit provides a structured methodology and tools for determining learning requirements and procedural knowledge for performing defined tasks with interactive systems. 
Exploitation 
The project strongly influenced the national (DIN, BSI) and international (ISO, CEN) standard organisations in the field of usability and computer interaction. A widely accepted consultancy service has been set up for the transfer of human factors knowledge to industry. 
A company, ESA, has been formed to commercialise the results of the project, especially DIAMANT, an object-oriented tool for the development of integrated, dynamic multimedia interfaces.";;;;;Fraunhofer-Gesellschaft zur Förderung der Angewandten Forschung eV (FhG);DE;"PHILIPS DUPONT OPTICAL;UNIV COLLEGE CORK;BULL SA;Ingegneria C. Olivetti and C. SpA;WESTFÄLISCHE WILHELMS-UNIVERSITÄT MÜNSTER;THE PIRAEUS GRADUATE SCHOOL;International Computers Ltd (ICL);UNIV DO MINHO;Loughborough University of Technology;Siemens AG";"NL;IE;FR;IT;DE;EL;UK;PT";
8643;291;LING-ANALYSIS;;FP1-ESPRIT 1;;FP1;Linguistic Analysis of the European Languages;01/02/1985;01/04/1989;;"The LING-ANALYSIS project produced the software necessary to perform grapheme-to-phoneme and phoneme-to-grapheme conversion at word level. This involved conversions between the textual and acoustical representation of words and the acquisition of the knowledge required to include speech in the man-machine interface. A linguistic model, based on typical syntactic patterns extracted from texts by statistical analyses, has been developed to deal with ambiguous solutions. The project covered the following languages: Dutch, English, French, German, Greek, Italian and Spanish. The first step was the development of a common methodology among the different languages in order to provide coherent and comparable results. Hardware and software tools were standardisedamong the partners, and language-specific tools developed where necessary. Reference corpora of about 200000 words plus dictionaries and lists of ambiguities (homographs and homophones) were extracted from common European Community texts and newspapers.The  efinition and development of a linguistic model for the semi-automatic labelling of new text corpora and for phoneme-to-grapheme conversion on the basis of a contextual analysis was achieved. ed. 
The project produced the software necessary to perform grapheme to phoneme and phoneme to grapheme conversion at word level. This involved conversions between the textual and acoustical representation of words and the acquisition of the knowledge required to include speech in the man machine interface. A linguistic model, based on typical syntactic patterns extracted from texts by statistical analyses, has been developed to deal with ambiguous solutions. The project covered the following languages: Dutch, English, French, German, Greek, Italian and Spanish. The first step was the development of a common methodology among the different languages in order to provide coherent and comparable results. Hardware and software tools were standardized among the partners, and language specific tools developed where necessary. Reference corpora of about 200 000 words plus dictionaries and lists of ambiguities (homographs and homophones) were extracted from common European Community texts and newspapers. The definition and development of a linguistic model for the semiautomatic labelling of new text corpora and for phoneme to grapheme conversion on the basis of a contextual analysis was achieved.
The following results are now available for the different languages: 
Conversion Algorithm: word level grapheme-to-phoneme and phoneme-to-grapheme conversion algorithms. 
Analysis of Language at Word Level 
-computer-readable common phonemic alphabet 
-consistent systems of grammatical classes 
-labelling of text corpora of a few thousand words 
-dictionaries, extracted from the corpora, providing (for each word) graphemic and phonemic representations, possible grammatical tabs, and usage frequency 
 -statistics, extracted from the dictionaries, providing: phonemes and phoneme cluster frequency; graphemes and grapheme cluster frequency; word distribution based on the grapheme length and on the length with or without frequency weighting; and the set f unction K(n) providing K, the percentage coverage of the corpora obtained with the n most frequent words. 
Disambiguation Rules for Phoneme-to-Grapheme Conversion 
-list of ambiguous words and ambiguity frequency estimates regarding the grapheme/phoneme/grapheme conversions 
-transition matrices providing the observed frequency of any pair or triplet of grammatical classes. 
Assessment of Conversions: methodologies for evaluating the statistical validity of the information appearing in the transition matrices and for comparing the expected performance in speech recognition of different class systems. 
Integration in a Practical Conversion System: a blackboard model of the language that uses the available knowledge on contextual constraints for solving the ambiguities consequent to the phoneme to grapheme conversion and for selecting the most likely sentence from a word lattice. 
Exploitation 
Full industrial exploitation of the results is expected in the early 1990s in speech processing based systems. Target application areas are unrestricted texts, speech synthesis, and large vocabulary speech recognition. The acquired knowledge and the results obtained will also be useful for applications in other domains, such as optical scanning, word-processing and automatic translation.";;;;;Ingegneria C. Olivetti and C. SpA;IT;"Tecnopolis Csata Novus Ortus;UNIV OF PATRAS;Acorn Computers Ltd;UNIV NACIONAL DE EDUCACION A DISTANCIA;KATHOLIEKE UNIVERSITEIT NIJMEGEN;RUHR-UNIVERSITY BOCHUM;Centre National de la Recherche Scientifique (CNRS)";"IT;EL;UK;ES;NL;DE;FR";
8636;1597;E-INTERFACE;;FP1-ESPRIT 1;;FP1;Standardisation of Integrated LAN Services and Service Access Protocols;01/09/1984;01/10/1987;;"The objective of this project was to define the services to be provided by an integrated traffic LAN and to define a stable interface between terminals and a LAN access unit. This interface was to comprise the physical interface and the service access protocols by means of which such services could be used. The definition of service parameters, events, etc, was to be presented for standardisation to ECMA and IEEE. 
After having analysed several possible types of standard interfaces (parallel, serial, and computer-bus), the project focused its effort on the external, serial-link E-interface, which was seen as the most competitive and the most likely to become a standard. 
The objective of the project was to define the services to be provided by an integrated traffic local area network (LAN) and to define a stable interface between terminals and a LAN access unit. This interface was to comprise the physical interface and the service access protocols by means of which such services could be used.
The project focussed its effort on the external, serial link E-interface, which was seen as the most competitive and the most likely to become a standard.

The final specification of this interface was produced and validated, and was submitted to ECMA for consideration. A breadboard model, including customized integrated circuits has been implemented. On the basis of the established standard, it is possible to connect data terminal equipment of different types and manufacturer, independent of the structure and media used. The development of the potentially large LAN and terminal market depends heavily on the existence of such a recognized standard. The E-interface concept has apparently not been accepted by either the LAN or terminal manufacturers, because real time voice, audio and video communication does not take place via LANs. However, the E-interface concept was used as the basis for the Broadband User Network Interface (BUNI) for the Integrated Broadband Communication (IBC) network. The need for standardization appears to be higher in the area of public networks than in the LAN domain.
The final specification of this interface was produced and validated, and was submitted to ECMA for consideration in January 1987. A breadboard model, including customised ICs, has been implemented. On the basis of the established standard, it is possible to connect data terminal equipment of different types and manufacturer to LANs of different types and manufacturer, independent of the structure and media used. The development of the potentially large LAN and terminal market depends heavily on the exist ence of such a recognised standard. 
The E-interface concept has apparently not been accepted by either the LAN or terminal manufacturers, because real-time voice, audio and video communication does not take place via LANs. 
However, the E-interface concept was used as the basis for the Broadband User Network Interface (BUNI) for the Integrated Broadband Communication (IBC) network. The need for standardisation appears to be higher in the area of public networks than in the LAN domain.";;;;;PHILIPS DUPONT OPTICAL;NL;"Siemens Nixdorf Informationssysteme AG;CAP SESA Télécom;UNIV VAN TWENTE;General Electric Company plc;GEC Marconi Research Centre;OCE-NEDERLAND BV;PLESSEY RESEARCH;RESEAUX COMMUNICATION ENTREPRISE;ALCATEL TITN;British Telecom plc (BT);Centro Studi e Laboratori Telecomunicazioni SpA;Roke Manor Research Ltd;Bull SA";"DE;FR;NL;UK;IT";
8630;1589;BWN;;FP1-ESPRIT 1;;FP1;Broad-Site Local Wideband Communication System;01/09/1984;01/09/1989;;"This project was concerned with the research and development of a local area wideband communication system for broad sites. The prototype system produced meets the anticipated communication requirements of large industrial scientific and administrative organisations. The project took into account data, text, voice and graphics communication requirements and the need to provide backbone networks and gateways for heterogeneous LANs. 
The project was concerned with the research and development of a local area wideband communication system for broad sites. The prototype system produced meets the anticipated communication requirements of large industrial scientific and administrative organizations. The project took into account data, text, voice and graphics communication requirements and the need to provide backbone networks and gateways for heterogeneous local area networks (LAN).

The project covered the design, implementation and prototype testing of a multimedia (data, voice, image) high performance communications infrastructure with the following characteristics:
backbone data rate of 140 Mbit/s on optical fibre;
2 Mbit/s full duplex data access rate;
broad site coverage of typically 100 km;
interconnection to LANs of various topologies and access protocols;
gateways to public networks;
video conferencing support;
message handling system with extended messaging services;
compatibility with existing and emerging standards of the local area networks (ISO-OSI) reference model.

A pilot system with 12 nodes has been successfully put into operation at the Sart-Tilman campus of the Universite de Liege.
The BWN project covered the design, implementation and prototype testing of a multimedia (data, voice, image) high-performance communications infrastructure with the following characteristics: 
-backbone data rate of 140 Mbit/s on optical fibre 
-2 Mbit/s full duplex data access rate 
-broad-site coverage of typically 100 km 
-interconnection to LANs of various topologies and access protocols 
-gateways to public networks 
-video conferencing support 
-message-handling system with extended messaging services 
-compatibility with existing and emerging standards of the ISO-OSI reference model. 
Exploitation 
A pilot system with 12 nodes has been successfully put into operation at the Sart-Tilman campus of the Universit de Lige.";;;;;ACEC SA;BE;"BELL TELEPHONE MFG CO NV;UNIV DE LIEGE;CMSU-COMMUNICATION & MANAGEMENT SYSTEMS UNIT.;Act Informatique;FRANCE CABLES ET RADIO;GENIE INFORMATIQUE;CISI Ingénierie SA;CPV-Stollmann Vertiebs GmbH";"BE;EL;FR;DE";
8474;1283;VIP;;FP1-ESPRIT 1;;FP1;VDM Interfaces for PCTE;01/11/1986;01/11/1989;;"The objective of the VIP project was to produce a formal specification giving a precise semantic description of the interfaces to the kernel of the PCTE. 
This project was associated with projects 1252 (AMADEUS), 1262 (SFINX), 1277 (SAPPHIRE), 1282 (PAVE). 
The objective of the project was to produce a formal specification giving a precise semantic description of the interfaces to the kernel of the portable common tool environment (PCTE). The PCTE specifications were produced using an extended version of VDM (VVSL-VIP VDM specification language). Both tooland user interfaces were specified using the same style of language and partially verified and validated. The project also demonstrated the feasibility of using formal methods to specify systems of this type. The availability of a precise and correct interface specification supports the reduction in the costs of evolutionary development. Tool writers now have access to the precise specification needed to derive a PCTE environment and to support tools emerging from other projects. Implementations can be compared against the formal specification by rapid prototyping using a precise specification. The formal specification can be used to derive an improved natural language specification.
The PCTE specifications were produced using an extended version of VDM (VVSL-VIP VDM specification language). 
Both tool and user interfaces were specified using the same style of language and partially verified and validated. 
The project also demonstrated the feasibility of using formal methods to specify systems of this type. The formal specifications were published in early 1989. 
Exploitation 
 The availability of a precise and correct interface specification supports the reduction in the costs of evolutionary development. Tool writers now have access to the precise specification needed to derive a PCTE environment and to support tools emerging from other ESPRIT projects. Implementations can be compared against the formal specification by rapid prototyping using a precise specification. The formal specification can be used to derive an improved natural language specification.";;;;;Computer General Electronic Design;UK;"CWI-CENTRUM VOOR WISKUNDE & INFORMATICA;OCE-NEDERLAND BV";NL;
8436;1508;GIPE;;FP1-ESPRIT 1;;FP1;Generation of Interactive Programming Environments;05/11/1984;05/11/1989;;"The main objective of GIPE was to investigate the possibilities of automatically generating interactive programming environments from language specifications. 
Such an interactive environment was to be generated from a complete syntactic and semantic characterisation of the language to be used, formally expressed in a Language Definition Formalism (LDF). An inference rule-based approach and an algebraic approachwere considered as the starting point for the design of the LDF. 
A prototype system was designed and implemented, consisting basically of an LDF compiler, a file system and a user interface. 
The main objective of the project was to investigate the possibilities of automatically generating interactive programming environments from language specifications. Such an interactive environment was to be generated from a complete syntactic and semantic characterization of the language to be used, formally expressed in a language definition formalism (LDF). An inference rule based approach and an algebraic approach were considered as the starting point for the design of the LDF. A prototype system was designed and implemented, consisting of an LDF compiler, a file system and a user interface. A language for specifying static constraints declaratively, TYPOL, was defined, and the formalism compiled into Prolog for execution. Another important set of results concerns investigations into obtaining a method of enhancing first order algebraic data type specifications to support concrete syntax descriptions, using a sub-typing mechanism. Central to the system is the virtual tree processor (VTP), which was specified and implemented. Portability of developments is assured by a software development environment common to all partners, connecting Unix, LE-Lisp, C-Prolog, the VTP, and a virtual window manager
Significant progress was achieved by the GIPE project in several areas. A language for specifying static constraints declaratively, TYPOL, was defined, and the formalism compiled into Prolog for execution. 
Another important set of results concerns investigations into obtaining a method of enhancing first-order algebraic data type specifications to support concrete syntax descriptions, using a sub-typing mechanism. Central to the system is the Virtual Tree Processor (VTP), which was specified and implemented. 
 A first version of the GIPE (Centaur) system presenting major improvements with regard to the MENTOR system (developed at INRIA) has been demonstrated to more than 50 research organisations. One direction of work, to be pursued in another project, is now the improvement of the person-machine interface. Portability of those developments is assured by a software development environment common to all partners, connecting Unix, LE-Lisp, C-Prolog, the VTP, and a virtual window manager. 
Exploitation 
The first version of CENTAUR has been distributed to academic and research laboratories, and 25 systems have already been installed. 
The GIPE project resulted in a prototype system which will now be industrialised. The results should advance the state of practice of the software industry. The industrial applicability will also be demonstrated through well-targeted experiments. It is also intended to use some of GIPE's results in the definition of a software factory (EUREKA project ESF).";;;;;SEMA Metra Group SA;FR;"CWI-CENTRUM VOOR WISKUNDE & INFORMATICA;Institut National de Recherches en Informatique et en Automatique (INRIA);BSO-BUREAU VOOR SYSTEEMONTWIKKELING";"NL;FR";
8420;1498;ADKMS;;FP1-ESPRIT 1;;FP1;Advanced Data and Knowledge Management Systems;01/12/1984;01/12/1989;;"The objective of ADKMS was to develop a knowledge-based system with an inferential capability for the intelligent and efficient management of large databases, suitable for both naive and domain-expert users. Access to the system was to be provided by a Natural Language (NL) interface. 
The task for Phase 1 was to develop the NL handlers, and to integrate a relational database management system with a knowledge-based system. 
The tasks for Phase 2 were the improvement, integration and evaluation of the Phase 1 results in an industrial application domain. 
The advanced data and knowledge management system (ADKMS) project covers knowledge representation, knowledge base development, data and knowledge base coupling, natural language analysis and generation, and intelligent access to databases. The main components of ADKMS are:
the knowledge representation system BACK, a hybrid reasoning system supporting complex representation of a domain terminology and database access via a powerful logic oriented interface language;
the knowledge base development environment BIT, providing a range of integrated graphics tools for interactive acquisition, browsing, navigating and validating large knowledge bases;
the natural language access system, consisting of 3 levels: tactical, for language parsing and generation (NUGGET); strategic, for generating structured query language (SQL) queries and the formal representation of the answers; and a data level, consisting of the database (using ORACLE) and the additional knowledge.

The objective was to develop a knowledge based system with an inferential capability for the intelligent and efficient management of large databases, suitable for both naive and domain expert users. Access to the system was provided by a natural language (NL) interface. A functional layered architecture was designed. Prototypes of natural language interfaces for German and Italian were constructed. A prototype of a hybrid knowledge representation and inferencing system (KRS) was mapped onto the database in a transparent fashion, through a Prolog structured query language (SQL) interface. A prototype of a database extension module was constructed, and coupled to a relational database management system (RDBMS). The whole project was subsequently evaluated and the definition of requirements according to a real application proposed. A common semantic representation was specified for Italian and German. A new version of KRS was provided, including a new query language to fulfil industrial demands and to interface DB4. The extended database query language was installed on a Nixdorf Targon 35. The NL handlers, the knowledge representation system and the extended RDBMS were state of the art products.
The major results of Phase 1 were: 
-the design of a functional layered architecture for an ADKMS 
-prototypes of natural language interfaces for German and Italian from Nixdorf and Olivetti 
-a prototype of BACK, a 'hybrid' knowledge representation and inferencing system (KRS) from the Technical University of Berlin, and a partial reimplementation from Nixdorf 
-a mapping of the KRS onto the database in a transparent fashion, through a Prolog/SQL interface 
-a prototype of a database extension module, and its coupling to an RDBMS 
-evaluation of the system in field and laboratory trials. 
Phase II started resulted in: 
-the evaluation of the whole project and the definition of requirements according to a real application proposed by Datamont 
-the specification of a common semantic representation for Italian and German 
-a new version of BACK-System, including a new query language to fulfil industrial demands and interfacing DB4 
-the porting of the extended database query language onto a Nixdorf Targon 35. 
The NL handlers, the BACK knowledge representation system and the extended RDBMS were state-of-the-art products. 
Exploitation 
The industrial prototypes provided a foundation for intelligent database management systems with greater functionality and non-restricted natural language handlers, allowing sophisticated AI applications to very large data and knowledge bases. These systems should combine the advantages of expert systems and database management systems. 
The results have been incorporated into the ESPRIT II project 5210, AIMS.";;;;;Siemens Nixdorf Informationssysteme AG;DE;"Ingegneria C. Olivetti and C. SpA;TECHNISCHE UNIVERSITÄT BERLIN;Bull SA";"IT;DE;FR";
11798;FI1W0002;PAGIS II;;FP1-RADWASTOM 3C;;FP1;PERFORMANCE EVALUATION OF HLW WASTE DISPOSAL IN GEOLOGICAL FORMATION PAGIS PROJECTS PHASE 2 : SALT ROCK OPTION;01/01/1985;30/04/1987;;"SALT IS ONE OF THE GEOLOGICAL DISPOSAL OPTIONS OF THE CEC COORDINATED PROJECT 'PAGIS' FOR THE SAFETY ASSESSMENT OF HLW DISPOSAL SYSTEMS. DATABASE, PARAMETERS AND MODELS WERE SELECTED AND THE METHODOLOGY DEVELOPED IN PHASE 1. THE PERFORMANCE ASSESSMENT WAS CARRIED OUT IN PHASE 2. BEST ESTIMATE AND UNCERTAINTY CALCULATIONS ARE PERFORMED FOR THE COMBINED SYSTEM OF REPOSITORY, AND BIOSPHERE. DOSES TO MAN RESULTING FROM THE RELEASE OF RADIOACTIVITY FROM THE REPOSITORY ARE OBTAINED. THE PARAMETER SENSITIVITY IS STUDIED. AMONG OTHER IT SHOWS HOW FAR APPROPRIATE CHOICES OF THE REPOSITORY DESIGN PARAMETERS CAN IMPROVE THE PERFORMANCE OF THE WHOLE SYSTEM. THIS IS DONE FOR A SELECTED REFERENCE SITE (THE GORLEBEN SALT DOME) AND THE VARIOUS RELEASE SCENARIOS. ALSO VARIANT SITES ARE CONSIDERED IN THE NETHERLANDS AND DENMARK AS WELL AS A BEDDED SALT FORMATION IN FRANCE. 

B.1. DETERMINISTIC CALCULATIONS WITH BEST ESTIMATE VALUES 
B.2. PROBABILISTIC CALCULATIONS 
B.3. DEFINITION AND SELECTION OF PARAMETERS FOR SENSITIVITY AND UNCERTAINTY ANALYSES 
B.4. SENSITIVITY STUDY 
B.5. UNCERTAINTY ANALYSIS 
B.6. FINAL ASSESSMENT";;;;CSC;GSF - FORSCHUNGSZENTRUM FUER UMWELT UND GESUNDHEIT GMBH;DE;;;
6312;RI1B0191;EMD;;FP1-BRITE;;FP1;ELECTRIC MOTOR DESIGN USING CAD TECHNIQUES SUPPORTED BY EXPERT SYSTEMS;01/04/1988;31/05/1991;;"The combination of computer aided design (CAD) techniques with various analysis subsystems supported by an expert system is quite a new concept in the field of electric motors. This project produced a final, tested prototype of an expert system for the design of electric motors and various analysis subsystems.
It is thought that the analysis subsystems, mechanical, thermal and electromagnetic, can be marketed indepently.
The positive results of this project came only after many technical problems developing the various analysis subsystems, then integrating them into an expert system. However, the potential for both analytic subsystems and expert systems for design on the European market is significant.
THE DESIGN OF ELECTRIC MOTORS HAS EVOLVED ALONG SEVERAL STAGES, SUPPORTED FIRST BY MANUAL CALCULATIONS AND THEN BY COMPUTER AIDED DESIGN (CAD) AND ANALYSIS (CAE) SYSTEMS.
HOWEVER, THESE SYSTEMS STILL REQUIRE THE SUPERVISION BY THE DESIGNER, WHO INTRODUCES ANY DECISION THAT LEADS TO THE PRODUCT. THEREFORE, THE MAIN PURPOSE OF THIS PROJECT IS TO CREATE AN AUTOMATIC AND INTELLIGENT SYSTEM FOR DESIGNING ELECTRIC MOTORS.

THIS IS TO BE ACHIEVED BY
1.- AUTOMATIC GENERATION OF THE MOTOR PRELIMINARY DESIGN FROM ITS SPECIFICATIONS. THE DESIGN METHODOLOGY IS TO BE BASED UPON ESTABLISHED WORKING PRINCIPLES FOR ELECTRIC MOTORS AND ON MANUFACTURER'S EXPERIENCE.
2.- DEVELOPMENT OF A MOTOR ANALYSIS SUBSYSTEM, THROUGH INTEGRATION OF ELECTROMAGNETIC, THERMAL AND MECHANICAL FINITE ELEMENT ANALYSIS.
3.- IMPROVEMENT OF THE DESIGN BY MEANS OF AN ITERATIVE PROCESS OF VALIDATION-REDESIGN VIA THE USE OF AN EXPERT SYSTEM.
4.- DEVELOPMENT OF A SUBSYSTEM FOR DOCUMENT GENERATION, NAMELY: BILL OF MATERIALS, MANUFACTURING DRAWINGS, WINDING DESCRIPTION AND MOTOR CHARACTERISTICS.";;;;CSC;LABORATORIO DE ENSAYOS E INVESTIGACIONES INDUSTRIALES - FUNDACION LABEIN;ES;"Elorriaga Industria Eléctrica SA;CEDRAT TECHNOLOGIES SA;INSTITUT NATIONAL POLYTECHNIQUE DE GRENOBLE";"ES;FR";
12630;EN3S0048;CAMUR;;FP1-ENNONUC 3C;;FP1;COMPUTER AIDED MANAGEMENT SYSTEM FOR URBAN RENEWAL.;01/07/1986;31/10/1989;;"TOWNSCOPE was developed to assist the renewal of an urban area as a whole. Rehabilitation with careful use of existing resources and a gentle, step by step approach, involving the local population in the decision structure, is now understood to be an appropriate way of solving urban renewal problems. The computer package produced can be run on a SUN graphic workstation in a UNIX environment.
REPLACEMENT OF WHOLE TOWN DISTRICT, PULLING ALL THE EXISTING BUILDINGS DOWN AND STATING WITH CLEAN STATE IS NOT CONSIDERED ANY MORE TO BE A SOLUTION TO THE PROBLEM. 
TOWN RENEWAL, SPECIALLY IN THE ECONOMIC CRISIS CONTEXT, IS MORE ADAPTED TO THE AVAILABLE MEANS OF ACTION AND TO THE ACTUAL SITUATION. BUT THE USUAL WAY TO ORGANIZE THIS RENEWAL VIA MUNICIPAL SERVICES INVOLVES PROCEDURES THAT HAVE ALWAYS BEEN COMPLICATED AND LENGHTY. THE NEIGHBOURHOOD-ORIENTED ACTION IS A NEW PROCEDURE RELATED AT THE SAME TIME TO URBAN PLANNING AND TO PRIVATE ARCHITECTURE. A MULTIDISCIPLINARY TEAM COMPRIZING DESIGNERS (PLANNERS AND ARCHITECTS) AND REPRESENTATIVES OF THE USERS (MUNICIPALITY AND RESIDENTS) ORGANIZES THE RENEWAL PROCESS AS INTEGRALLY AS POSSIBLE, A DISTRICT AT A TIME. IN ORDER TO FACILITATE THIS ACTION, THE R&D WORK WILL PRODUCE A COMPUTER PACKAGE ALLOWING THE TEAM TO EXPLORE DIFFERENT POSSIBLE RENEWAL STRATEGIES OF URBAN DISTRICTS. THIS PACKAGE IS PROPOSED AS A HIGHLY EFFICIENT INTERFACE BETWEEN ALL THE PEOPLE CONCERNED WIYH THE PROPOSED REHABILITATION ACTION.";;;;CSC;UNIVERSITE DE LIEGE*ULG;BE;"University of Strachlyde;ETHNOKTIMATIKI SPA;Synergia Progetti Srl;UNIVERSITY COLLEGE DUBLIN;Dialogic SA";"UK;EL;IT;IE;FR";
869;ST2*0451;VIERS 1;;FP1-STIMULATION 1C;;FP1;PREPARATION INTERPRETATION ERS - 1;01/10/1988;30/09/1990;;This research has been on the modelling and implementation of the backscattering module, the wind wave module and the integration of the modules in a consistent model-VIERS-1. Several recently developed theories on backscattering from slightly rough surfaces were compared using results from the measurement campaigns. An improved 2-scale model was selected for implementation in the final model. Similarly the approximations used in the wind wave model have tested with the data and the module was finalized. The modular structure of the VIERS model permits interchange of backscattering modules and wind wave modules. A new wave measuring instrument, the reflective stereo slope gauge, was tested for the first time in open sea.;;;;CSC;Business Unit of TNO Built Environment and Geosciences;NL;"ROYAL NETHERLANDS METEOROLOGICAL INSTITUTE;Stichting Waterbouwkundig Laboratorium;Technische Universiteit Delft;RUPRECHT-KARLS-UNIVERSITAET HEIDELBERG";"NL;DE";
12647;EN3S0030;PASSYS;;FP1-ENNONUC 3C;;FP1;PARTICIPATION OF THE NETHERLANDS IN THE CEC PASSYS PROJECT.;01/06/1986;31/12/1989;;"THE DUTCH ACTIVITIES WITHIN THE FRAMEWORK OF THE PASSYS PROJECT CURRENTLY COVER THE AREAS 'TEST METHODOLOGIES', 'SIMPLIFIED DESIGN TOOLS', AND 'MODEL VALIDATION'. 
A REPORT HAS BEEN PRODUCED ON THE DEVELOPMENT OF AN INTEGRATED, SUBTRACCTIVE TEST METHODOLOGY. IN THIS METHOD, ALL HEAT FLUXES WHICH TAKE PART IN THE THERMAL BALANCE OF THE TEST CELL ARE MEASURED, AS INTEGRATED VALUES OVER LARGE (E.G. DAY, WEEK) TIME INTERVALS, EXCEPT FOR THE FLUXES THROUGH THE PASSIVE SOLAR COMPONENT (PSC) IN THE SOUTH FACING OPENING. THE RESULT IS THE INTEGRATED NET HEAT FLUX THROUGH THE PSC AS A FUNCTION OF SOME WEATHER PARAMETER(S). THE REPORT DESCRIBES THE FIRST STEPS IN THE DEVELOPMENT; THE MAIN EQUATIONS ARE INTRODUCED AND RESULTS OF FIRST SIMULATED TESTS (USING AN UNSTEADY STATE COMPUTER MODEL) ARE USED FOR EXAMINING THE FEASIBILITY OF THE METHOD. 
THE INTEGRATED, SUBTRACTIVE METHOD IS STUDIED, NOT BECAUSE IT IS THE MOST PROMISING ONE; DRAWBACKS ARE POSSIBLY A LONG TEST DURATION AND THE LOW LEVEL OF INFORMATION IT EXTRACTS FROM A TEST. SO OTHER TECHNIQUES MAY BE NEEDED TO EXTRACT ADDITIONAL INFORMATION. IT'S MAIN ADVANTAGES, HOWEVER, ARE (1) THAT THE METHOD IS STRAIGHT FORWARD AND (2) THAT THE SAME MATHEMATICAL RELATIONS AND ELEMENTS ARE USED AS IN A PROMISING TYPE OF SIMPLIFIED DESIGN TOOL. FOR INSTANCE, THE RECENTLY DEVELOPED TOOL TCM-HEAT (TPD CORRELATION BASED MULTI-ZONE MONTHLY METHOD TO CALCULATE HEATING REQUIREMENTS) WHICH HAS BEEN INTRODUCED AS A POSSIBLE TOOL. THE MAIN ELEMENTS ARE THE STEADY STATE THERMAL AND SOLAR TRANSMITTANCES OF THE FACADE AND THE GAIN UTILIZATION FACTOR AND GAIN LOSS RATIO WHICH DESCRIBE THE THERMAL BALANCE OF THE ROOM. 
THE FIRST TWO CELLS ARRIVED AT THE TEST SITE IN DELFT AND WERE INSTRUMENTED. THE CELLS WERE CALIBRATED DURING THE 1987/1988 WINTER SEASON. DUE TO THE VERY LARGE INERTIA OF THE CELLS IT APPEARED NECESSARY TO DEVELOP SPECIAL TESTS AND TEST EVALUTION PROCEDURES. FOR INSTANCE A COMPARATIVE TEST WITH ONE TEST CELL HEATED WITH CONSTANT, THE OTHER WITH ZERO POWER, WHICH YIELDS THE HEAT LOSS FACTOR OF THE CELLS IN CASE OF AN ADIABATIC SOUTH WALL COMPONENT. APART FROM THIS, A FLEXIBLE NON-LINEAR REGRESSION ANALYSIS METHOD HAS BEEN DEVELOPED TO QUANTIFY THE UNSTEADY STATE CHARACTERISTICS ('CAPACITY') OF THE CELLS FROM THE TEST RESULTS. FIRST COMPUTATIONS ON THE CALIBRATION RESULTS SHOW THAT THE APPROACH IS VERY PROMISING. 
AS A SPECIAL ADDITION TO THE TEST CELLS IN DELFT THE TPD HAS DESIGNED A MOVEABLE COLD BOX WHICH CAN TURN A TEST CELL TEMPORARILY INTO A HOT BOX FACILITY. 
THE ESP SIMULATION MODEL HAS BEEN IMPLEMENTED AT THE TPD IN EINDHOVEN AND DELFT AND IS BEING USED IN THE CONTEXT OF MODEL VALIDATION. SIMULATIONS WITH ESP ARE ALSO CARRIED OUT TO PRODUCE RESULTS FOR THE DEVELOPMENT OF TEST METHODOLOGIES AND A SIMPLIFIED DESIGN TOOL. 
WITHIN THE SUBGROUP MODEL VALIDATION THE TPD IS SUBJECT EDITOR FOR THE TOPICS INTERNAL CONVECTION AND THERMAL COMFORT; IN ADDITION SENSITIVITY STUDIES WILL FOCUS ON THE TOPICS EXTERNAL LONG WAVE RADIATION AND PASSIVE SOLAR COMPONENTS. SELECTED RESULTS WILL BE PRESENTED AT THE CONFERENCE.";;;;CSC;Business Unit of TNO Built Environment and Geosciences;NL;;;
12888;EN3E0136;SYNEP;;FP1-ENNONUC 3C;;FP1;METHODOLOGY GOVERNING THE ENERGY INTEGRATION OF INDUSTRIAL PROCESSES.;01/07/1986;31/12/1988;;"THE AIMS OF THIS STUDY WERE TO DEVELOP A METHODOLOGY FOR THE ANALYSIS AND DESIGN OF ENERGY-SAVING MANUFACTURING PROCESSES AND THE INTEGRATION OF THAT METHODOLOGY INTO EASY-TO-USE SOFTWARES, OF WHICH TWO HAVE BEEN DEVELOPED.
SYNEP is one of the modules of a complete set of software used in process engineering, notably aimed at chemical plants. The systems presented include the phases of measurement, collection, validation of the data, parameter identification of the proposed model, simulation of process performance and the evaluation of alternatives and optimisation. SYNEP is the tool used in the evaluation and optimisation phase.
DEVELOPMENT OF APPROPRIATE METHODS AND SOFTWARES IN ORDER TO INTEGRATE THE ENERGY SAVING OF THE PROCESSES INVOLVED AND TO ENABLE THE MANAGEMENT OF INDUSTRIAL-SITE UTILITY NETWORKS TO BE OPTIMIZED. 
ENERGY INTEGRATION ON THE BASIS OF AN OVERALL ECONOMIC CRITERION INCLUDING INVESTMENTS AND OPERATING COSTS BY MEANS OF AN AUTOMATIC OPTIMIZATION PROGRAMME INCLUDING A TAKING INTO ACCOUNT OF THE RESTRICTIONS IMPOSED BY NON-LINEARITY AND VARIATIONS IN THE OPERATING CONDITIONS. 
DEVELOPMENT OF A UTILITY MANAGEMENT TOOL WHICH CAN OPERATE AUTOMATICALLY, BUT WHICH ENABLES ALTERNATIVE STRATEGIES TO BE ASSESSED IN THE CONVERSATIONAL MODE, TOGETHER WITH CALCULATION OF THE PENALTIES IN RELATION TO THE OPTION. 
THESE DEVELOPMENTS WILL TAKE PLACE AS PART OF A GENERAL EXISTING SIMULATION PROGRAMME, BELSIM, IN SUCH A WAY AS TO BE ABLE TO TEST THE FEASIBILITY OF THE SOLUTIONS ENVISAGED AT EACH STAGE OF AN IMPLEMENTATION STUDY.";;;;CSC;UNIVERSITE DE LIEGE*ULG;BE;;;
14008;FI1W0078;FAR;;FP1-RADWASTOM 3C;;FP1;FIELD MODELLING OF RADIONUCLIDE MIGRATION;01/01/1987;31/12/1990;;"NUMERICAL SIMULATION OF GROUNDWATER FLOW AND SOLUTE TRANSPORT IS AN ESSENTIAL ELEMENT OF ANY ASSESSMENT OF THE PERFORMANCE OF A PROPOSED REPOSITORY FOR NUCLEAR WASTE. THE ACCURACY AND REALISM OF SUCH SIMULATION MUST BE CLEARLY DEMONSTRABLE AND ALSO DEFENSIBLE AGAINST CRITICAL PUBLIC SCRUTINY. DETAILED SIMULATIONS ARE EXPENSIVE SO ANY INCREASED COMPUTATIONAL EFFICIENCY OFFERS THE OPPORTUNITY FOR MORE EXTENSIVE SENSITIVITY ANALYSIS AS PART OF A COMPREHENSIVE REPOSITORY ASSESSMENT. 

THE PROJECT AIMS TO IMPROVE THE CAPABILITY, EFFICIENCY AND REALISM OF THE NAMMU CODE, WHICH SIMULATES GROUNDWATER FLOW AND SOLUTE TRANSPORT THROUGH A POROUS MEDIUM. OUR DETAILED OBJECTIVES ARE TO DISCOVER AND EXPLOIT SUPERIOR METHODS FOR SOLVING SIGNIFICANTLY NON-LINEAR PROBLEMS; TO INTRODUCE INTO THE CODE A CAPABILITY FOR MODELLING CHEMICAL REACTIONS; TO IDENTIFY AND TEST IMPROVED TECHNIQUES FOR SIMULATING THE PROGRESS OF SHARP FRONTS IN SOLUTE CONCENTRATION; AND TO IDENTIFY BETTER-FOUNDED REPRESENTATIONS OF SOLUTE DISPERSION. THE LAST TWO TOPICS WILL BE COVERED BY SUB-CONTRACTS PLACED AT UNIVERSITIES IN THE UNITED KINGDOM. 

THE NAPSAC CODE PRESENTLY CALCULATES FLOW THROUGH A THREE-DIMENSIONAL NETWORK OF FRACTURES. OUR AIM IS TO DECIDE UPON AND IMPLEMENT THE MOST APPROPRIATE METHOD FOR CALCULATING SOLUTE TRANSPORT THROUGH A THREE-DIMENSIONAL NETWORK, SO NAPSAC COULD BE USED TO INVESTIGATE RADIONUCLIDE MIGRATION FROM REPOSITORY IN HARD FRACTURED ROCK. 
The aim of this project was to improve the capability, efficiency and realism of the NAMMU and NAPSAC codes, which simulate groundwater flow and solute transport.

Using NAMMU, various solution methods for nonlinear problems were investigated. The Broyden method gave a useful reduction in computing time and appeared robust. The relative saving obtained with this method increased with the problem size. This was also the case when parameter stepping was used.

The existing empirical sorption models in MANNU were generalized and a ternary heterogeneous ion exchange model was added. These modifications were tested and gave excellent results. The desirability of coupling NAMMU to an existing geochemical speciation code was assessed.

Numerical methods for the solution of cases involving sharp fronts in solute concentration were investigated. Roe's Superbee method was applied to several test cases. The method gave impressive results for some high Peclet number test problems. However, problems were encountered in cases with large permeability contrasts.

Models of solute dispersion were investigated. A survey of the literature, and a Monte Carlo study of the early stages of plume development were carried out. The concentration distribution did not settle down to a normal distribution within the length and timescales of the experiment. Methods of calculating effective parameters were investigated.

A very efficient particle following algorithm has been added to the NAPSAC code, enabling tracer transport to be predicted through large fracture networks. The new algorithm has been tested against 3 test examples. These demonstrations confirmed the accuracy of the code for simple networks, where there is an analytical solution to the transport problem, and illustrated the use of the computer code on a more realistic problem.
1. IMPROVED METHODS FOR SOLVING SIGNIFICANTLY NON-LINEAR GROUNDWATERFLOW PROBLEMS WILL BE IMPLEMENTED IN NAMMU BECAUSE CURRENTLY AVAILABLE, ALTHOUGH ROBUST, ARE EXPENSIVE. 
2. THE NAMMU CODE WILL BE ENHANCED TO PROVIDE A MEANS OF MODELLING THE IMPACT OF CHEMICAL REACTIONS ON SOLUTE TRANSPORT IN A POROUS MEDIUM. 
3. METHODS WILL BE ASSESSED AND TESTED THAT OFFER PROSPECTS OF SIMULATING EFFICIENTLY THE ADVANCE OF SHARP FRONT IN SOLUTE CONCENTRATION, WITHOUT SPURIOUS DISPERSION. 
4. MODELS OF INHOMOGENEOUS MATERIALS WILL BE EXPLORED TO PROVIDE BETTER UNDERSTANDING AND DESCRIPTIONS OF SOLUTE DISPERSION. 
5. THE NAPSAC FRACTURE-NETWORK CODE WILL BE ENHANCED BY INCORPORATING A JUDICIOUSLY CHOSEN TECHNIQUE FOR CALCULATING SOLUTE TRANSPORT.";;;;CSC;United Kingdom Atomic Energy Authority;UK;;;
8443;1041;GENESIS;;FP1-ESPRIT 1;;FP1;An Environment for Formal Systems Development;28/01/1986;28/01/1991;;"The GENESIS project set out to create a meta-system which would generate syntax-directed editors, transformation and proof tools from descriptions of the syntax and semantics of the formalisms used in software development. Metalanguages for the description of projection layouts, proof rules and tactics were to be defined. 
The project set out to create a metasystem which would generate syntax directed editors, transformation and proof tools from descriptions of the syntax and semantics of the formalisms used in software development. Metalanguages for the description of projection layouts, proof rules and tactics were defined. The base system consists of the projection language KENSHO and the typed logic programming language JADE. Several kinds of proof in different logicial systems were tried out.
The GENESIS project has now been completed. The base system consists of the projection language KENSHO and the typed logic programming language JADE. Imperial Software Technology built support tools for VDM and Z, and several kinds of proof in different logical systems were tried out. Philips provided editors for the COLD-K and ERAE languages, as well as implementing a constructive logic machine. Imperial College implemented the omega-p logic environment for prototyping and experimenting with logic systems. 
Exploitation 
GENESIS has already been used as the platform for two formal methods support tools which are sold as products by IST. The VDM tool grew as a commercial development of the tool implemented under the GENESIS project case-study. The Z tool development was financed by a client of IST wishing to have Z tools for its own use. The client subsequently licensed IST to sell the tool commercially. IST has so far sold these tools to nine commercial and four academic organisations. IST intends to continue selling these tools and to seek commercial collaborations with other organisations to develop other tools (eg for CCS, CSP and LOTOS) using the GENESIS platform. 
The GENESIS system is available at commercial rates to other organisations wishing to build tools and has been offered to other ESPRIT projects and to academic organisations on favourable terms. 
IST has entered into a tool development contract with one client that offers considerable potential for further refinements to, and enhancements of, the GENESIS system itself. This arrangement, and others similar to it, will provide a self-financing routefor the continuing development of GENESIS within IST. 
Philips currently releases all their project results together with necessary user documentation to all interested parties. Apart from software development departments within Philips, the results have been licensed to NOKIA research (for the ATMOSPHERE project, number 2565) and the University of Amsterdam. 
Interest is mainly on applications, although the generator system has been evaluated within Philips Kommunikations Industrie for contribution to RACE project 1202 (SPECS). 
Work on the constructive logic machine and associated publications continues. Proof construction in type theory is currently of great interest.";;;;;Imperial Software Technology Ltd;UK;"IMPERIAL COLLEGE OF SCIENCE, TECHNOLOGY AND MEDICINE;Philips GmbH";"UK;DE";
8433;938;IMPW;;FP1-ESPRIT 1;;FP1;Integrated Management Process Workbench;25/02/1986;25/02/1989;;"The objective of IMPW was the implementation of a prototype workbench with particular emphasis on planning, project control and decision support. The tools rely heavily on a common knowledge base. The system is intended to be Unix V and PCTE portable.This project was associated with project 814, PIMS. 
The objective was the implementation of a prototype workbench with particular emphasis on planning, project control and decision support. The tools rely heavily on a common knowledge base. The system is Unix V and portable common tool environment (PCTE) portable. Emphasis was laid on the design of the workbench software and on the design and implementation of a comprehensive set of use functions covering all automatable project management actions. Important results were:
The development of an object oriented development method;
The design of a standard manager workbench interface;
The preparation of a user requirements specification of estimation purposes;
The specification and design of the risk analysis tool;
The development of a first version of an estimation tool. Following the survey of cost modelling theories and practices, a generic cost estimation tool was developed that can be customized for all existing models and combinations thereof.
Emphasis was laid on the design of the workbench software and on the design and implementation of a comprehensive set of use functions covering all automatable project management actions. 
Important results were: 
-development of an object-oriented development method 
-design of a standard manager workbench interface 
-preparation of a user requirements specification for estimation purposes 
-specification and design of the risk analysis tool 
-development of a first version of an estimation tool. 
Following the survey of cost modelling theories and practices, a generic cost estimation tool was developed that can be customised for all existing models and combinations thereof. 
Exploitation 
The prototype system is being demonstrated and used in industrial trials. 
Industrialisation of the prototype will have immediate impact on software development project management.";;;;;International Computers Ltd (ICL);UK;"NIHE-NATIONAL INSTITUTE FOR HIGHER EDUCATION;Centre d'Études Techniques de l'Équipement Méditerrannée (CETE);IMPERIAL COLLEGE OF SCIENCE, TECHNOLOGY AND MEDICINE;Verilog SA";"IE;FR;UK";
14039;FI1W0004;HADES;;FP1-RADWASTOM 3C;;FP1;A PILOT FACILITY IN THE ARGILLACEOUS LAYER BENEATH THE NUCLEAR SITE AT MOL.;01/01/1985;30/06/1990;;"IN 1974 SCK/CEN LAUNCHED A R&D PROGRAMME CONCERNING THE POSSIBILITIES FOR DISPOSAL OF HIGH LEVEL SOLIDIFIED AND ALPHA-BEARING RADIOACTIVE WASTES IN A CONTINENTAL STRATIFORM CLAY FORMATION (BOOM CLAY) SITUATED BELOW ITS OWN SITE. SITE INVESTIGATIONS, SAFETY STUDIES, REPOSITORY DESIGN, CONCEPTUALISATIONS AND IN SITU RESEARCH CONFIRM PROGRESSIVELY THE FAVOURABLE  CHARACTERISTICS OF THE HOST ROCK AND THE SITE FOR DISPOSAL OF RADIOACTIVE WASTE. 
MANY PARTICULAR AREAS REQUIRE FURTHER STUDIES AND TESTS ON A LARGER SCALE AND IN SITU DEMONSTRATIONS UNDER REALISTIC CONDITIONS. THE AREAS IDENTIFIED ARE RELATED TO THE CONSTRUCTION ON AN INDUSTRIAL SCALE OF AN UNDERGROUND REPOSITORY IN PLACTIC CLAY, THE OPERATION OF AN UNDERGROUND FACILITY, THE INTERACTION BETWEEN THE REPOSITORY AND THE IMMEDIATE TESTS, STUDIES AND DEMONSTRATIONS WILL CONTRIBUTE TO INCREASE THE CONFIDENCE IN THE TECHNICAL PRACTIVABILITY, THE ECONOMICAL FEASIBILITY AND THE SAFETY OF THE DISPOSAL OPTION IN DEEP CLAY. 
THE DIRECT DEMONSTRATIONS DEAL WITH THE CONSTRUCTABILITY OF REAL SCALE GALLERIES WITHOUT PARTICULAR CONDITIONING OF THE ROCK, THE CHOICE AND DIMENSIONING OF A REALISTIC LINING AND SUPPORT SYSTEM, THE INTERACTION BETWEEN THE UNDERGROUND STRUCTURES AND THE IMMEDIATE GEOLOGICAL ENVIRONMENT, THE INFLUENCE OF HEAT AND RADIATION UPON THE UNDERGROUND STRUCTURES AND THE IMMEDIATE GEOLOGIC ENVIRONMENT, THE BACKFILLING AND ITS BEHAVIOUR IN TIME, THE  PERFORMANCE OF VARIOUS SYSTEM COMPONENTS DURING THE OPERATIONAL PHASE AND MONITORING SYSTEMS. 
WITHIN THE HADES PROJECT A TECHNOLOGICAL TEST RELATED TO A GALLERY LINING TECHNIQUE ACCORDING TO THE CONVERGENCE-CONFINEMENT PRINCIPLE IS PERFORMED BY ANDRA (FRANCE). (SEE CONTRACT FI1W/0112). 
The activities of the Centre d'Etude de l'Energie Nucleaire, Studiecentrum voor Kernenergie (CEN/SCK) between 1985 and 1989 in the framework of the HADES demonstration/pilot project were reported. The overall objective of the HADES programme was the evaluation of the technical feasibility and safety of the disposal of radwaste in a deep clay formation. The pilot phase was aimed at demonstrating the system behaviour for those components of the system and those operations and issues which can be demonstrated directly.

The time period considered covered the first phase of the development programme of the pilot project which included:
the construction of a concrete lined test drift of about 30 m in length with a useful inner diameter of 3.5 m (in the lining, a number of openings or ports are foreseen for emplacing the various tests and sensors for the general auscultation in the host rock);
a mine by test for the investigation of the response of the surrounding clay on the excavation;
the CERBERUS test, a combined heating irradaition test aimed at evaluating by simulation (electrical heaters and cobalt-60 radiation source) the impact of a high level waste (HLW) canister on its imediate near field;
design of a gallery heating test for the demonstration by simulation of the behaviour of a concrete lined gallery structure and of the surrounding clay mass in a temperature field.
THE DEMONSTRATION PILOT PHASE OF THE HADES PROJECT IS DEVELOPED IN TWO PHASES, WHICH ARE COMPLEMENTARY TO EACH OTHER AND IN PART PARALLEL. 
B.1. PHASE I : THE CONSTRUCTION AND OPERATION OF A TEST DRIFT WITH TESTS RELATED TO : 
B.1.1. MINING TECHNOLOGY (DIGGING, LINING, EXTRADOS BACKFILLING, RHEOLOGY); 
B.1.2. RADIOACTIVE WASTE DISPOSAL (EXPERIMENTAL EMPLACEMENT, BACK-FILLING, DEGRADATION OF WASTE MATRICES AND MIGRATION OF RADIO-NUCLIDES, IN SITU IRRADIATION OF CLAY, THERMO-MECHANICAL BEHAVIOUR OF CLAY AND GALLERY STRUCTURES, MONITORING AND AUSCULTATION SYSTEMS). 
B.2. PHASE II CONCERNING : 
B.2.1. DESIGN AND CONSTRUCTION OF A PILOT FACILITY. 
B.2.2. TESTS AND OBSERVATIONS ON HANDLING, EMPLACEMENT, HACKFILLING AND RETRIEVAL OF DUMMIES AND FINALLY ACTUAL RADIOACTIVE WASTES. 
THE PERFORMANCE OF B.2. IS SCHEDULED BEYOND THE ACTUAL CONTRACT PERIOD.";;;;CSC;BELGIAN NUCLEAR RESEARCH CENTRE;BE;ANDRA;FR;
12646;EN3S0029;PASSIVE;;FP1-ENNONUC 3C;;FP1;PROJECT PASSYS;01/03/1986;31/12/1989;;"THE AIMS OF THE PASSYS PROJECT ARE: 

- TO INCREASE CONFIDENCE IN PASSIVE SOLAR SIMULATION MODELS AND DESIGN METHODS THROUGH FURTHER DEVELOPMENT AND VALIDATION. 
- TO DEVELOP RELIABLE AND COST-EFFECTIVE TEST PROCEDURES FOR PASSIVE SOLAR COMPONENTS. 

THE BELGIAN MAIN ACTIVITIES CAN BE SUMMARIZED AS FOLLOWS: 

- TWO TEST-CELLS, THE MEASUREMENT CONTAINER AND THE ELECTRICAL EMERGENCY SYSTEM WERE INSTALLED. THE SENSORS WERE INSTALLED BETWEEN AUGUST AND DECEMBER 1987. 

- THE B.B.R.I. HAS COORDINATED THE ACTIVITIES OF THE SUBGROUP 'INSTRUMENTATION'. 
THEREFORE, A PROPOSAL FOR COMMON SENSORS TO BE USED IN THE PROJECT, HAS BEEN MADE, DETAILED PRESSURISATION MEASUREMENTS WERE CARRIED OUT ON THE B.B.R.I. TEST-CELLS, AN ANALYSIS OF ALL THE PRESSURISATION MEASUREMENTS WAS DONE AND SOME PRELIMINARY TRACER GAS MEASUREMENTS WERE MADE. 

- THE THEORETICAL TWO- AND THREE DIMENSIONAL HEAT LOSSES WERE ANALYSED IN DETAIL BY THE B.B.R.I. SPECIAL ATTENTION HAS BEEN PAID FOR THE ENTRY DOOR IN THE MEASUREMENT ROOM WHERE AN IMPORTANT THERMAL BRIDGE WAS FOUND. 
THEREFORE ONE OF THESE DOORS WAS ALSO INSTALLED IN A HOT BOX-COLD BOX TO MEASURE THE THERMAL PERFORMANCE OF THE DOOR AND THE WALL IN WHICH IS INSTALLED. 

- A LARGE NUMBER OF CALCULATIONS WITH ESP WERE DONE BY THE V.U.B. SEVERAL TOPICS WERE ANALYSED E.G.: 
* THE TEST-CELL BEHAVIOUR FOR DIFFERENT EUROPEAN CLIMATES AND THE DESIRED POWER OF THE HEATING AND COOLING SYSTEM 
* SOME OF THE SIMPLIFIED DESIGN TOOLS PROCEDURES WERE ANALYSED BY THE V.U.B. IN DETAIL 
* CLIMATIC DATA FILES WERE PREPARED FOR COPENHAGEN, LERWICK, BRUSSELS, MILANO AND TRAPANI, COMPATIBLE WITH ESP AND MG-1 
* NEW VALIDATION WORK WAS DONE BY THE V.U.B. ON ESP AS WELL AS ANALYTICAL TESTS AND SENSITIVITY STUDIES.";;;;CSC;Centre Scientifique et Technique de la Construction;BE;;;
11776;FI1W0043;PACOMA;;FP1-RADWASTOM 3C;;FP1;PERFORMANCE ASSESSMENT OF CONFINEMENTS FOR MEDIUM LEVEL WASTE DISPOSAL AT HARWELL SITE;01/11/1986;31/03/1989;;"WE SHALL SIMULATE THE TRANSPORT TO THE SURFACE OF RADIONUCLIDES RELEASED FROM A HYPOTHETICAL REPOSITORY IN A CLAY LAYER BENEATH HARWELL LABORATORY. THE RATES OF RELEASE FROM SUCH A REPOSITORY, FOR VARIOUS WASTE INVENTORIES, HAVE BEEN CALCULATED BY ELECTROWATT ENGINEERING. CAP SCIENTIFIC HAVE DERIVED PROBABILITY DISTRIBUTIONS FOR THE VALUES OF PARAMETERS INVOLVED IN THE RELEVANT GROUNDWATER-FLOW AND SOLUTE-TRANSPORT CALCULATIONS, BY STRUCTURED QUESTIONING OF GROUPS OF EXPERTS. RADIOLOGICAL RISKS DUE TO THE MIGRATION OF RADIONUCLIDES FROM THE REPOSITORY WILL BE CALCULATED BY THE NATIONAL RADIOLOGICAL PROTECTION BOARD. THE FINAL STAGE OF THE PROJECT INVOLVES A COMPARISON BY CAP SCIENTIFIC OF RADIOLOGICAL RISKS DERIVED BY PROBABILISTIC RISK ASSESSMENT AND FROM DETERMINISTIC SIMULATION. THIS ANALYSIS SHOULD IDENTIFY ANY SIGNIFICANT DIFFERENCES IN THE APPROACHES TO SAFETY ASSESSMENT ADOPTED BY UK NIREX LTD. AND BY THE UNITED KINGDOM DEPARTMENT OF THE ENVIRONMENT. 

1. REVIEW, AND IF NECESSARY REVISE, EXISTING CALCULATIONS OF GROUNDWATER-FLOW IN THE VICINITY OF THE HARWELL SITE, SO AS TO ESTABLISH NUMERICAL ACCURACY AND TO EXAMINE SENSITIVITY TO MODELLING ASSUMPTIONS. 

2. CARRY OUT RADIONUCLIDE-TRANSPORT CALCULATIONS AND DETERMINE HOW RESULTS DEPEND UPON UNCERTAINTIES IN THE MODELLING ASSUMPTIONS AND IN THE VALUES OF PHYSICAL PARAMETERS. 

3. ASSIST CAP SCIENTIFIC LTD. TO COMPARE SAFETY ASSESSMENTS BASED UPON PROBALISTIC AND DETERMINISTIC CALCULATIONS.";;;;CSC;United Kingdom Atomic Energy Authority;UK;;;
8460;1523;ESB;;FP1-ESPRIT 1;;FP1;Expert System Builder;18/07/1984;18/07/1989;;"The ESB project investigated the extent to which the production of expert systems could be industrialised. It created an Expert System Builder (ESB) for the use of personnel not experienced in artificial intelligence to develop and test expert systems. Trial applications were made. The result compares with the most advanced products in the world. 
The expert system builder (ESB) project was launched at a time when research into expert systems technology was intense. The project's basic objective was to produce a highly integrated environment for expert systems development.
Several basic components were defined: the expert system shell itself; an object oriented language, FLAME; and a person machine interface generator. These components were built on top of common LISP. The X-window standard was chosen, and four different demonstrators within the domain of fault diagnosis of electronic systems and process control were used to test and validate concepts and results.

A solution has been developed for the construction of knowledge based expert systems which is particularly useful for the rapid prototyping of computer based applications.

The project investigated the extent to which the production of expert systems could be industrialized. It created an expert system builder (ESB) for the use of personnel not experienced in artificial intelligence to develop and test expert systems. Trial applications were made. The following components of the ESB system were realized: the object oriented system; the inference engine; the knowledge representation formalism; the model system; and the man machine interface system. Three simple expert systems for the diagnosis of electronic equipment and one for the diagnosis of a process control system were developed to provide practical feedback.
The following components of the ESB system were realised: 
-the object-oriented system (FLAME) 
-the inference engine (called the Basic Expert System Builder or BESB) 
-the knowledge representation formalism (CONCEPT) 
-the model system 
-the Man-Machine Interface system (MMI). 
Three simple expert systems for the diagnosis of electronic equipment and one for the diagnosis of a process control system were developed by the partners to provide practical feedback. 
The full system is now complete, and a commercial product is available (with special conditions for CEC-supported projects). 
Exploitation 
A preliminary version of the ESB has been used by third parties since early 1988. 
Sren T. Lyngs has announced the commercial release of THOR (based on BESB) and ODIN (based on an early version of the ESB) for the automatic creation of the domain and product layers for power plant applications. 
Plessey-Siemens and Sren T. Lyngs have ported and commercially developed the latest version of the ESB, which is now available as a commercial product (ESB96). 
Tecsiel has announced porting to various machines and the commercialisation of the system. 
Syseca has exploited the system internally (especially the MMI system), and has put on the market an interface design and prototyping tool for complex applications called SPIRITS. A new version with improved functionalities is to be announced in the autumn of 1992. 
ESB will be used extensively in the study of multimedia MMI for expert systems in a real-time environment in ESPRIT II project 2397, PROMISE.";;;;;PLESSEY SIEMENS ELECTRONIC SYSTEMS LTD;UK;"SOREN T.LYNGSOE A/S;CIMSA SINTRA;Tecsiel SpA;Centro Studi e Laboratori Telecomunicazioni SpA";"DK;FR;IT";
8638;1603;DOEOIS;;FP1-ESPRIT 1;;FP1;Design and Operational Evaluation of Office Information Servers;16/01/1985;16/08/1989;;"The objective of DOEOIS was to design, build and evaluate a small family of prototype Office Information Servers (OIS) capable of holding, in digital electronic form, representations of all office information, including what is currently committed to paper, and also the state of such activities as clerical procedures and industrial processes. The design and evaluation of the OIS were based on survey data directly derived from current office practice. 
The objective of project was to design, build and evaluate a small family of prototype office information servers (OIS) capable of holding, in digital electronic form, representations of all office information, including what is currently committed to paper, and also the state of such activities as clerical procedures and industrial processes.

A common 2-layer representation was established for the information held in the servers and the functions needed to manipulate and manage it. At the lower layer, documents were held in an internalized version of the office document architecture (ODA)/office document interchange format (ODIF) standard, with the descriptive terms in the profile and logical structure made visible. A semantic data model, the fact model, was used to represent the higher level interrelationships between the objects held in the OIS. Key to the project was careful consideration of the issues involved in the handling of office procedures with a view to creating, activating and subsequently monitoring their progress. The functionality of the OIS was embodied in an external functional interface. This was intended to be an open applications interface designed to make applications portable to any OIS conforming to its specification. During the implementation phase 2 prototype servers supporting most of the specified functions, were completed. One was designed as a front end to a relational database management system (RDBMS). The other was on a mainframe resident semantic database management system that exploits hardware search by content of text files. A common real life application was implemented on top of each server to be used as a testbed for evaluating the functionalities provided.
A common two-layer representation was established for the information held in the servers and the functions needed to manipulate and manage it. At the lower layer, documents are held in an internalised version of the ODA/ODIF standard, with the descriptive terms in the profile and logical structure made visible. A semantic data model, the Fact Model, is used to represent the higher level interrelationships between the objects held in the OIS. Key to the project was careful consideration of the issues invo lved in the handling of office procedures with a view to creating, activating and subsequently monitoring their progress. The functionality of the OIS was embodied in an External Functional Interface. This is intended to be an open applications interface designed to make applications portable to any OIS conforming to its specification. 
During the implementation phase two prototype servers supporting most of the specified functions, were completed. One was designed as a front-end to a relational database management system (RDBMS). The other is on a mainframe-resident semantic database management system that exploits hardware search by content of text files. A common real-life application was implemented on top of each server to be used as a testbed for evaluating the functionalities provided. The evaluation was based on a methodology developed within the project for this purpose and included both a technical inspection of the OIS functionality and a live evaluation of a sample application. The latter was compared in terms of measurable benefit indicators against a conventional paper equivalent and also an implementation based on a conventional RDBMS. The results of the evaluation were encouraging, with reductions of over 50% recorded in the time taken to execute highly structured and well-defined office tasks when compared to paper equival nts. 
Exploitation 
The analysis and design phases produced two advances: a four-level analysis methodology, which contributed the data needed to specify the functional requirements to be met by a generic server; and the OIS external functional interface, the actual definition of those functions The prototype servers resulted in technological improvements in the companies involved as well as intelligent front-ends to the databases employed. The project also contributed towards the establishment of the ODA tools currently available.";;;;;International Computers Ltd (ICL);UK;"TRINITY COLLEGE DUBLIN;BULL SA;Universität Stuttgart";"IE;FR;DE";
8417;300;REQUEST;;FP1-ESPRIT 1;;FP1;Reliability and Quality of European Software;01/07/1985;01/07/1990;;"The objectives of REQUEST were to provide improved and validated techniques for measuring and modelling software quality and reliability, supported by the appropriate prototype tools. The metrics and models were to span as much of the life-cycle as possible provide information for project management decision-making and control. Particular targets were to develop: 
-a Constructive Quality Model (COQUAMO) to predict quality characteristics throughout the software development process 
-metrics and models for reliability prediction 
-a database for software quality and reliability for validating models and metrics 
-prototype tools to enable ready use to be made of quality and reliability metrics and models.
Quality models and tools for prediction, control and assessment, together with the associated support tools for data collection and analysis, were developed. The development of successive prototypes of quality management systems (QMS) provided a frame for a construction quality model (COQUAMO) and its surrounding tools. Work on modelling the reliability of single systems concentrated on 2 aspects: the integration of testing activities and reliability modelling in order to improve the control of testing activities, and provision of a suitable human-machine interface. An environment for reliability assessment (PERFIDE) was demonstrated. The PERFIDE environment provides a good interface with a software package and support documents. Contributions to the theory of modelling the reliability of fault tolerant systems were made in 2 areas: in the quantification of dependency in models which predict the reliability of systems with multiple versions of software, and in comparing the cost effectiveness of testing and fault tolerance in achieving required reliability levels. Software project data have been collected as part of the process of metric and model validation, and a database has been established.
Quality models and tools for prediction, control and assessment, together with the associated support tools for data collection and analysis, were developed. The development of successive prototypes of Quality Management System (QMS) provided a frame for COQUAMO and its surrounding tools. COQUAMO is an innovative tool, putting new and higher-performing services on the market. 
Work on modelling the reliability of single systems concentrated on two aspects: 
-the integration of testing activities and reliability modeling in order to improve the control of testing activities 
-provision of a suitable human-machine interface. 
An environment for reliability assessment (PERFIDE) was demonstrated. The PERFIDE environment provides a good interface with a software package (available to ESPRIT participants) and support documents. 
Contributions to the theory of modelling the reliability of fault-tolerant systems were made in two areas: in the quantification of dependency in models which predict the reliability of systems with multiple versions of software, and in comparing the cost-effectiveness of testing and fault-tolerance in achieving required reliability levels. 
Software project data have been collected as part of the process of metric and model validation, and a database has been established. 
The database model is currently being used in the SCOPE (project 2151) and DARTS (2354), and is mature enough to be exploited by any ESPRIT project which intends to make data collection. The two options are: 
-either to use the REQUEST model as it is 
-to generate a dedicated database. 
 The role of the meta-model is to generate specific databases, working on the same principle as the REQUEST database, but with different relations or objects. Therefore, any other application or extension of the current data model (eg on hardware quality) can be expected for future exploitations. 
More than one hundred deliverables have been produced, and the results of REQUEST have been presented at more than twenty international conferences (synopses and other documents are available from STC). 
Exploitation 
An exchange of all tools related to data collection has been agreed between the Alvey Software Data Library and the REQUEST consortium. Further agreements are under negotiation with other enterprises. The availability of a public database dealing with software quality and reliability is of particular interest for organisations new to those fields. 
An open course on the REQUEST data model is now given in the NCRS. 
REQUEST definitions for software metrics standards are used in other ESPRIT projects. The large number of countries represented in the project should facilitate the emergence of European standards for metrics. 
The REQUEST quality results are being used by ICL to define the requirements of a software quality environment for the ESA. 
Elektronik Centralen is currently providing services to introduce Software Quality Management in Danish companies, using REQUEST's results. 
A book, entitled 'Strategies for the achievement and assessment of Fault-Tolerant Software', has been published by Springer Verlag about the work on fault-tolerant systems (SP2), and one may be published on the COQUAMO quality model (SP1).";;;;;BNR Europe Ltd;UK;"Bailey Esacontrol SpA;Gesellschaft für Anlagen- und Reaktorsicherheit mbH;THOMSON CSF;AEG Olympia AG;United Kingdom Atomic Energy Authority (UKAEA);CISI Ingénierie SA";"IT;DE;FR;UK";
8475;1277;SAPPHIRE;;FP1-ESPRIT 1;;FP1;PCTE Portability;15/10/1986;15/10/1989;;"The main objective of the SAPPHIRE project was to evaluate the adequacy, completeness, performance and portability of the PCTE. 
Other objectives were to: 
-link the Fortune and Eclipse projects with the ESPRIT PCTE initiative by porting them on top of the PCTE interface 
-support the PCTE interface on a number of common machines 
-port an ADA compiler to PCTE. 
The objective of the project was to evaluate the adequacy, completeness, performance and portability of the portable common tool environment (PCTE). EMERAUDE has been ported to the SUN workstation. A first version of a Sun-based PCTE was shown. The SUN PCTE, with the Eclipse integrated project support environment (IPSE) and a tool to generate code from MASCOT 3 diagrams, was demonsrated. ECLIPSE, the Alvey-developed integrated environment, has been integrated on the Sun PCTE implementation, and was demonstrated. A demonstration of the object modelling system (OMS) on the IBM personal computer (PC)/AT was given. This reflected some of the problems, due mainly to incompatibility in word sizes, that occur in porting the PCTE to PC/AT. The port to Vaxstation ULTRIX-based machines is complete. Demonstrations have been given on Sun, Vax/ULTRIX and Hewlett Packard machines.
EMERAUDE has been ported to the SUN. A first version of a SUN-based PCTE was shown at the Stockholm conference in May 1987. The SUN PCTE, with the Eclipse IPSE and a tool to generate code from MASCOT 3 diagrams, was demonstrated at the 1987 ESPRIT Conference. ECLIPSE, the Alvey-developed integrated project support environment (IPSE), has been integrated on the Sun PCTE implementation, and was demonstrated at the 1987 ESPRIT Workshop. 
A demonstration of the OMS on the IBM PC/AT was given in June 1988. This reflected some of the problems, due mainly to incompatibility in word sizes, that occur in porting the PCTE to PC/AT. 
The port to Vax STATION ULTRIX-based machines is complete. Demonstrations have been given on Sun, Vax/ULTRIX and HP machines. 
Exploitation 
PCTE implementations on the various hardware architectures will maximise the industrial application of PCTE and will provide a de facto standard PCTE for European software development projects. 
The Sun version, available since December 1987, has been distributed and is in use on several sites.";;;;;Sema Group UK Ltd;UK;"Software Sciences Ltd;GIE-EMERAUDE";"UK;FR";
8329;955;CNMA;;FP1-ESPRIT 1;;FP1;Communication Network for Manufacturing Applications;01/01/1986;01/01/1989;;"The objective of the CNMA project was to select, implement and demonstrate profiles of existing and emerging communications standards in real production environments, thus extending MAP developments. Widespread acceptance of the communications methodologywas encouraged by providing implementation guides and common testing procedures. The project addressed all layers of the ISO/OSI model, particularly layers 6 and 7. 
The development and compilation of the implementation guide and conformance testing tools proceeded at the same time.
The objective of the communications network for manufacturing applications (CNMA) project was to select, implement and demonstrate profiles of existing and emerging communications standards in real production environments, thus extending manufacturing automation protocol (MAP) developments. Widespread acceptance of the communications methodology was encouraged by providing implementation guides and common testing procedures. The project addressed all layers of the International Standards Organization (ISO) open system interconnection (OSI) model, particularly layers 6 and 7. The development and compilation of the implementation guide and conformance testing tools proceeded at the same time.
A phase I implementation guide was publised in October 1986 and was widely circulated. The phase 2 implementation guide was published at the beginning of 1988.
The achievements of the first phase of the project were demonstrated at the Hannover Fair in April 1987. A typical manufacturing cell was controlled by computing hardware from 5 vendors, interworking by using CNMA communications software. The success of this demonstration drew attention to the feasibility of multivendor systems and affected the development of the relevant international standards.
A Phase I Implementation Guide was published in October 1986 and was widely circulated. The Phase 2 Implementation Guide was published at the beginning of 1988. 
The achievements of the first phase of the project were demonstrated at the Hannover Fair in April 1987. A typical manufacturing cell was controlled by computing hardware from five vendors, interworking by using CNMA communications software. The success of this demonstration drew attention to the feasibility of multivendor systems and affected the development of the relevant international standards. 
Exploitation 
 The CNMA Phase 2 software was demonstrated by participation in the Enterprise Networking Event'88 International in Baltimore in June 1988. This underlined the compatibility of the CNMA and MAP profiles of communications standards, and provided an opportu nity for Europe to influence the development of MAP standards. Siemens demonstrated a MAP 3.0/SINEC gateway at the 1989 Hannover Fair. A product release based on this device took place in the third quarter of 1989. The CNMA profiles are used in real production applications by BMW, British Aerospace and Aeritalia. In parallel with the specification and development of communications software, conformance testing tools were released to testing institutes.";;;;;BRITISH AEROSPACE PLC;UK;"ELF AQUITAINE;Olivetti Systems & Networks Srl;Fraunhofer-Gesellschaft zur Förderung der Angewandten Forschung eV (FhG);International Computers Ltd (ICL);PEUGEOT SA;Alenia - Aeritalia & Selenia SpA;BAYERISCHE MOTOREN WERKE AG (BMW);BULL SA;SIEMENS-NIXDORF INFORMATIONSSYSTEME AG;General Electric Company plc;SIEMENS AG;CGE-TITN";"FR;IT;DE;UK";
8469;1256;CHAMELEON;;FP1-ESPRIT 1;;FP1;Dynamic Software Migration between Cooperating Environments;01/09/1986;01/03/1990;;"The objective of CHAMELEON was to build a dynamic software migration system. The purpose of this system is to enable the migration and execution of active objects throughout a heterogeneous computer network. The elements of the system are an abstract common machine, an abstract common machine environment and the network. 
This project was associated with project 1261, HTDS. 
The objective was to build a dynamic software migration system, to enable the migration and execution of active objects throughout a heterogeneous computer network. The elements of the system are an abstract common machine, an abstract common machine environment and the network. The starting point for this project was the AMBER machine, an intermediate machine model. The abstract machine is a model which reflects target machine and programming language concepts to support the portability of programs. Two intermediate machine models, IACM and HARP, were proposed and examined by the partners. HARP is a general purpose machine model and makes no assumptions about the supported languages; IACM is more closely modelled on the AMBER machine. These designs differ in the ease with which they could support the languages C and SCHEME. Models of both abstract machines were developed within the project. Demonstrations of software migration in an homogeneous environment using abstractions of 2 intermediate machine models were given.
The starting point for this project was the AMBER machine, an intermediate machine model. The abstract machine is a model which reflects target machine and programming language concepts to support the portability of programs. Two intermediate machine mode ls, IACM and HARP, were proposed and examined by the partners. HARP is a general purpose machine model and makes no assumptions about the supported languages; IACM is more closely modelled on the AMBER machine. These designs differ in the ease with which they could support the languages 'C' and SCHEME. Models of both abstract machines were developed within the project. 
Demonstrations of software migration in a homogeneous environment using abstractions of two intermediate machine models were given. 
Exploitation 
 The productivity gains will allow users to undertake important projects which would be prohibitively time consuming with existing technology. For example, a software porting task which nowadays could take several months, could conceivably be accomplished  in, at most, one morning. Therefore, this project is expected to greatly improve productivity and to drastically reduce the cost of moving software. The concepts being developed could also be exploited in networks where programs could be moved around the network and activated at remote nodes.";;;;;Delphi SpA;IT;"Non Standard Logics;Harlequin Ltd";"FR;UK";
8818;1644;THORN;;FP1-ESPRIT 1;;FP1;The Obviously Required Name-Server;01/01/1985;01/01/1990;;"The THORN project's objectives are to study directory services and to build and demonstrate a prototype service. 
The obviously required name server (THORN) project's objectives are to study directory services and to build and demonstrate a prototype service. Due to the lack of relevant International Standards Organisation - International Telephone and Telegraph Consultative Committee (ISO-CCITT) standards for directory services, the project started with an implementation of the European Computer Manufacturers Association (ECMA) standards. Based on this implementation, a large scale pilot exercise (LSPX) was set up. This work allowed the partners to gain early experience in designing, implementing and using directory services, which enabled them to make a valuable contribution to the final ISO-CCITT standards.
As soon as thesestandards became available (first as drafts, later as final standards), the ECMA-conformant implementations were adapted and enhanced. The final prototype consisted of directory user agent (DUA) and directory service agent (DSA) software, ported to the various hardware platforms used by the THORN partners. This prototype was further enriched with different sets of user interface (UI) software, each supporting a different style of user interaction, and administration tools. During the project, a suite of testing tools was also developed to help test the conformance of the system to the standard.
Begun with only the THORN project partners, the LSPX had grown, by the end of the project, to 14 DSA in 4 countries, offering information on several hundred organizations, a few thousand hosts and more than 20000 people. The system was probably used by over 1000 users.
Due to the lack of relevant ISO-CCITT standards for directory services, the project started with an implementation of the ECMA standards. Based on this implementation, a Large Scale Pilot eXercise (LSPX) was set up. This work allowed the partners to gain early experience in designing, implementing and using directory services, which enabled them to make a valuable contribution to the final ISO-CCITT standards. 
As soon as these standards became available (first as drafts, later as final standards), the ECMA-conformant implementations were adapted and enhanced. The final prototype, as demonstrated during the 1989 ESPRIT Conference, consisted of Directory User Agent (DUA) and Directory Service Agent (DSA) software, ported to the various hardware platforms used by the THORN partners. This prototype was further enriched with different sets of User Interface (UI) software, each supporting a different style of user interaction, and administration tools. During the project, a suite of testing tools was also developed to help the partners test the conformance of their system (after porting to their particular hardware platform) to the standard. 
 Begun with only the THORN project partners, the LSPX had grown, by the end of the project, to 14 DSAs in 4 countries, offering information on several hundred organisations, a few thousand hosts and more than 20 000 people. The system was probably used by over 1000 users. 
Exploitation 
The experience and know-how acquired during the THORN project will be used by the various partners for further work. Most partners have announced or are developing X.500-based directory service products. Products already available include PIZARRO (INRIA), DIR-X (Siemens), DirWiz (SW). The DIR-X product of Siemens has been chosen by the Open Software Foundation (OSF) as the basis for their X.500 naming service. Furthermore, the testing tools developed as part of the project are still in use with the partne rs to test their own products, and the experience gained via the LSPX is being reused to set up directory services for the research community.";;;;;Ing. C. Olivetti E C. Spa;IT;"ICL Ltd;SIEMENS AG;GEC Plessey Telecommunications Ltd;System Wizards Srl;CERN;Bull SA;Institut National de Recherches en Informatique et en Automatique (INRIA);DFN";"UK;DE;IT;FR";
8454;1098;KADS;;FP1-ESPRIT 1;;FP1;A Methodology for the Development of Knowledge-Based Systems;23/09/1985;23/09/1990;;"The objective of KADS is to assist the transfer of knowledge-based systems (KBS) technology into the marketplace by providing methodological guidance for the development process. It is believed that KBS development can be treated as a particular case of software engineering, and that the same requirements must be placed on the development of KBS as on other types of software. In short, KBS must be produced to specification and to acceptable standards by a controllable process.
The objective of the project was to assist the transfer of knowledge based systems (KBS) technology into the marketplace by providing methodological guidance for the development process. The conceptual modelling methodology and tools have been applied in 11 experiments with well documented success. Methods and techniques have been developed to support all aspects of KBS analysis and design. The important models used are of expertise, cooperation, requirements, functional design, and physical design. A library of generic task models, called interpretation models, has been developed to support structured knowledge acquisition. The methodology is currently supported by the Shelley workbench, implemented using a configuration of Prolog and the object oriented graphical language PCE. It includes a variety of tools together with advice and guidance on the use of the methodology.
The conceptual modelling methodology and tools have been applied in eleven experiments with well-documented success in at least one revenue-earning study for a commercial client in the UK. 
Methods and techniques have been developed to support all aspects of KBS analysis and design. The important models used within KADS are of expertise, cooperation, requirements, functional design, and physical design. A library of generic task models, called interpretation models, has been developed to support structured knowledge acquisition. 
The KADS (Knowledge Acquisition and Design Support) methodology is currently supported by the Shelley workbench, implemented using a configuration of Prolog and the object-oriented graphical language PCE. It includes a variety of tools to support different aspects of KADS together with advice and guidance on the use of the methodology. 
Exploitation 
PCE, developed at the University of Amsterdam, is being marketed in Europe and America through non-exclusive licensing agreements. The Shelley workbench has been released to some academic institutions. 
The KADS methodology is being exploited via commercial projects, industrial training courses, academic courses and within books and other publications. A number of important companies, such as IBM and Arthur Andersen, are adopting KADS as their standard KBS methodology. The CCTA in the UK are taking KADS as the methodological foundation for the GEMINI programme which is aimed at providing the successor for SSADM. 
Results of the project have been incorporated in ESPRIT II projects 2576 (ACKNOWLEDGE) and 5248 (KADS-II).";;;;;STC Technology Ltd;UK;"CAP GEMINI INNOVATION;UNIV VAN AMSTERDAM;South Bank University;Scicon Ltd;Scientific Control Systems Informationstechnik Gmbh";"FR;NL;UK;DE";
27257;EN3S0150;PASSYS;;FP1-ENNONUC 3C;;FP1;THE DEVELOPMENT OF PASSIVE SOLAR COMPOMENTS : THE PORTUGUESE PARTICIPATION;01/01/1988;31/12/1989;;;;;;CSC;Universidade do Porto;PT;;;
8739;1032;ERW;;FP1-ESPRIT 1;;FP1;AN OFFICE SYSTEMS RESEARCH WORKSTATION FOR EUROPE;01/03/1986;28/02/1990;;;;;;;Whitechapel Computer Works Ltd;UK;"VRIJE UNIVERSITEIT AMSTERDAM-DEPARTEMENT OF LINGUISTICS;Ingegneria C Olivetti and Co SpA;Siemens Nixdorf Informationssysteme AG;UNIVERSITY OF SUSSEX";"NL;IT;DE;UK";
12544;EN3S0155;BUILDING 2000;;FP1-ENNONUC 3C;;FP1;"COORDINATION AND ADMINISTRATIVE MANAGEMENT OF PROJECT ""BUILDING 2000""";01/01/1988;30/04/1991;;;;;;CSC;EGM Beheer;NL;;;
1684;BI6*0340;SETARAD II;;FP1-RADPROT 6C;;FP1;SECONDE INTERCOMPARAISON EUROPEENNE EN ATMOSPHERE MINIERE DES INSTRUMENTS ET DES METHODES DE MESURE DU RADON ET DE SES DESCENDANTS;01/01/1989;31/12/1989;;;;;;CSC;Compagnie Générale des Matières Nucléaires (COGEMA);FR;;;
8819;1645;HERMES;;FP1-ESPRIT 1;;FP1;MESSAGE HANDLING SURVEY AND TRENDS FOR THE IES USER COMMUNITY;;;;;;;;;F&L EUROPEAN TELECOMMUNICATIONS CONSULTANTS A/S (FISCHER & LORENZ);DK;;;
12645;EN3S0032;PASSYS;;FP1-ENNONUC 3C;;FP1;PASSIVE SOLAR SYSTEM DEVELOPMENT IN CLOSE COLLABORATION WITH BRE (WATFORD) AND ABACUS (GLASGOW).;01/01/1987;31/12/1989;;;;;;CSC;University of Strathclyde;UK;;;
8813;1639;EUROKOM;;FP1-ESPRIT 1;;FP1;COMPUTER CONFERENCING AND ELECTRONIC MAIL FOR ESPRIT;01/09/1983;31/08/1988;;;;;;;UNIVERSITY COLLEGE DUBLIN;IE;;;
8815;1641;ELAN;;FP1-ESPRIT 1;;FP1;ESPRIT/EUROPEAN LOCAL AREA NETWORK;01/03/1984;28/02/1987;;;;;;;ICL-INTERNATIONAL COMPUTERS LTD;BE;"BULL SA;SIEMENS DATA SA;OLIVETTI SA";BE;
27259;EN3S0165;COMBI;;FP1-ENNONUC 3C;;FP1;PROGRAM DEFINITION STUDY;01/10/1988;31/12/1988;;;;;;CSC;CENTRE SCIENTIFIQUE ET TECHNIQUE DU BATIMENT - CSTB;FR;;;
8524;1529;BICMOS;;FP1-ESPRIT 1;;FP1;A High-Performance CMOS/Bipolar Process for VLSI Circuits;01/04/1985;30/11/1988;;;;;;;PHILIPS DUPONT OPTICAL;NL;Siemens Nixdorf Informationssysteme AG;DE;
8447;1515;SPMMS;;FP1-ESPRIT 1;;FP1;Software Production and Maintenance Management Support;01/10/1984;01/04/1989;;"The SPMMS project aimed to design and implement a system supporting all management activities in the software life-cycle. 
The SPMMS system was to be capable of monitoring the distributed engineering environment to determine the status of the development process. One of the most important requirements of the system was to be its adaptability to different management methods.The project planned to reach this objective by building a basic generic SPMMS kernel which is easily customisable, possibly using a rule-based approach. 
The project was to design and implement a system supporting all management activities in the software life cycle, capable of monitoring the distributed engineering environment to determine the status of the development process, and adaptable to different management methods. Results comprise: specification of the system; first prototype of the semantic data model; complete architectural design. Progress was made on mapping simplified work breakdown schedules onto the semantic data model. A subset of an organisation structure was successfully mapped and demonstrated. The project produced a prototype for the development of an information system to support management activities in the software product life cycle, constructed in Carnegie representation language (CRL). Implementation of the prototype in a portable common tool environment (PCTE) was completed. This included a semantic data model for software development projects in order to provide a conceptual schema of the project process. Functionalities have been implemented and demonstrated in a PCTE.
Results comprise: 
-specification of the SPMMS system 
-first prototype of the semantic data model 
-complete architectural design. 
Progress was made on mapping simplified work breakdown schedules onto the semantic data model. A subset of an organisation structure was successfully mapped and demonstrated. 
The SPMMS project produced a prototype for the development of an information system to support management activities in the software product life-cycle, constructed in CRL (Carnegie Representation Language). Implementation of the easily customisable prototype in a PCTE environment was completed. This includes a semantic data model for software development projects in order to provide a conceptual schema of the project process. 
Functionalities have been implemented and demonstrated in a PCTE environment. 
Exploitation 
The SPMMS project contributed to the common data schema and the vocabulary used by several ESPRIT management tools projects. 
The project is expected to contribute to the PCTE by providing management tools operating on a data schema in a distributed PCTE system.";;;;;GSI TECSI Software SA;FR;"Siemens AG;Data Management SpA;SEMA Metra Group SA;ALCATEL TITN;SOFEMASA;GSI TECSI Software SA";"DE;IT;FR;ES";
18172;BAP*0364;CARBBANK;;FP1-BAP;;FP1;A STRUCTURAL AND BIBLIOGRAPHIC DATA BASE FOR COMPLEX CARBOHYDRATES;01/01/1989;31/01/1991;;"The objective was the development of the Complex Carbohydrate Structural Database (CCSD) and the database management program CarbBank which will give systematic access to published carbohydrate structures. Collection of structural data is performed manually by a systematic survey of the existing carbohydrate literature, relevant citations are obtained by computer assisted searching on the Chemical Abstract CAS ONLINE service and other important data (for example a compressed structural formula, optical rotation, nuclear magnetic resonance data, melting point) are added manually. The first version of the CCSD and CarbBank released in October 1989 has been revised and updated, the latest version (December 1990) now contains 3888 complex carbohydrate structures. A contract has been negotiated between the European partners, the American collaborators in Georgia and Chemical Abstract services, which has resulted in free exchange of data and thereby securing a much more complete database.
Correlation of structures with Nuclear Magnetic Resonance Spectroscopic data has been facilitated by creating a computer program, which allows easy connection between structure and data. The program is available as a test version.";;;;CSC;RIJKSUNIVERSITEIT UTRECHT;NL;;;
21419;1261;HTDS;;FP1-ESPRIT 1;;FP1;Host-Target Development System;01/12/1986;01/10/1990;;"The objective of the HTDS project is to develop a prototype integrated tool system based on a PCTE environment to support automatic testing, high-level debugging and remote maintenance. 
The project aims to establish a framework for the test and debug process between the compiler output and executable target code. 
The host-target development area will be examined with a view to specifying a development system. Naked microprocessors, industry standard boards and industry standard computers will be considered as targets. The advantages of distributing the tools between the host and target systems will be considered. 
Prototype systems will be realised with tools in the areas of automatic testing, high-level debugging and remote maintenance. 
Standard solutions to the communications problems of developing host target systems, will be sought. It is anticipated that results from the CHAMELEON project (1256) will be of help in this task. 
The objective of the project was to develop a prototype integrated tool system based on a portable common tool environment (PCTE) to support automatic testing, high level debugging and remote maintenance. A preliminary test and debug specification has been written. This specification includes a full list and description of commands necessary to test and debug executable code in the proposed environments. Two levels of interface are being defined in the process between the compiler output and the execution mapping. The upper level lends itself to the human interface and the lower level to the machine. At the final review a demonstration in a HOOD environment was given. This incorporated diagnostics at the HOOD object design level being executed by running the resultant code on 68000 code emulators. The process visibility generated in the windowing system was good.
A preliminary test and debug specification has been written. This specification includes a full list and description of commands necessary to test and debug executable code in the proposed environments. 
Two levels of interface are being defined in the process between the compiler output and the execution mapping. The upper level lends itself to the human interface and the lower level to the machine. 
At the final review a demonstration of the HTDS in a HOOD environment was given. This incorporated diagnostics at the HOOD object design level being executed by running the resultant code on 68000 code emulators. The process visibility generated in the windowing system was good. 
Exploitation 
This project will engender a common approach to the test and debug phase of system development with the associated standardisation benefits.";;;;;Not Available;;"Marconi Underwater Systems Ltd;Softlab GmbH für Systementwicklung und EDV-Anwendung;Société Française de Génie Logiciel SA;Logica Ltd";"UK;DE;FR";
18174;BAP*0363;CARBBANK;;FP1-BAP;;FP1;A STRUCTURAL AND BIBLIOGRAPHIC DATA BASE FOR COMPLEX CARBOHYDRATES;01/01/1989;31/03/1991;;"The objective was the development of the Complex Carbohydrate Structural Database (CCSD) and the database management program CarbBank which will give systematic access to published carbohydrate structures. Collection of structural data is performed manually by a systematic survey of the existing carbohydrate literature, relevant citations are obtained by computer assisted searching on the Chemical Abstract CAS ONLINE service and other important data (for example a compressed structural formula, optical rotation, nuclear magnetic resonance data, melting point) are added manually. The first version of the CCSD and CarbBank released in October 1989 has been revised and updated, the latest version (December 1990) now contains 3888 complex carbohydrate structures. A contract has been negotiated between the European partners, the American collaborators in Georgia and Chemical Abstract services, which has resulted in free exchange of data and thereby securing a much more complete database.
Correlation of structures with Nuclear Magnetic Resonance Spectroscopic data has been facilitated by creating a computer program, which allows easy connection between structure and data. The program is available as a test version.";;;;CSC;Universität Hamburg;DE;;;
21422;998;MARS;;FP1-ESPRIT 1;;FP1;Highly Secure Office Information Systems;18/12/1985;18/12/1988;;"This project addressed the area of security and integrity in office systems in order to make substantial and innovative proposals to deal with the needs of future office systems. The objectives of the project were to: 
-study the current nature of security threats and examine state-of-the-art countermeasures in office information systems 
-develop a security model for an office information system, with particular emphasis on the banking environment 
-produce guidelines for implementing standards for secure office information systems, again emphasising banking 
-specify the requirements for a key-management centre and end-user security facilities. 

MARS produced a comprehensive description of possible threats and risk-analysis methods and the ways and means of implementing appropriate safeguards. Two security models were developed and guidelines produced. 
 The security models comprise a workstations model and a communication model. Based on a component/countermeasures matrix with eight different levels of security, the workstation security model supports the implementation of security measures by analysing the workstation into its component parts and determining the countermeasures needed. The communication model supports the design and the tests by providing a medium through which the results of the design can be expressed. 
Together with the models, the guidelines promote the implementation of security in office automation systems by supplying precisely defined recommendations in the areas of access control, workstations, encryption and auditing. 
In the last phase of the project work was directed towards applying the models and recommendations to an existing office application requiring a high level of security in order to define requirements and design specifications. The security system was specified around an ISO/OSI architecture that clearly specifies the components and protocol layers. End-User Security Facilities (EUSFs) protect both the application interfacing to the user and the transport layer in the communications system by using the services provided by a Key-Management Centre (KMC). 
The key-management facilities have been based on a three-level hierarchy using symmetrical keys for confidentiality and data integrity. Asymmetrical keys have been specified for authentication, non-repudiation and key management. A security officer appointed in each branch should handle the local security management, and personal chipcards would be used in the identification process. 
The EUSFs are viewed as integrated parts of the workstations and the front-end processors and would consist of hardware in a cryptobox as well as software running on the processor. Based on public keys, the system design anticipates for the future by allowing users registered by the KMC to set up secure communications by the automatic exchange of secret keys. 
Exploitation 
The requirements and design specifications, together with the enhanced ability to specify and design secure systems, will have a very positive impact on the reliability of future secure office systems. The project has clearly shown the importance of well-defined and standardised security facilities and has demonstrated how these can be integrated into the systems themselves. The results from the project support the development of secure office systems from European manufacturers, and provides input for further standardisation in the area.";;;;;ESPRIT INFORMATION DESK;BE;"University of East Anglia;Bertin & Cie;COPS (EUROPE) LTD;BBN COMMUNICATION A/S;Protexarms;Universität Köln";"UK;FR;IE;DK;DE";
18173;BAP*0362;CARBBANK;;FP1-BAP;;FP1;A STRUCTURAL AND BIBLIOGRAPHIC DATA BASE FOR COMPLEX CARBOHYDRATES;01/01/1989;31/03/1991;;"The objective was the development of the Complex Carbohydrate Structural Database (CCSD) and the database management program CarbBank which will give systematic access to published carbohydrate structures. Collection of structural data is performed manually by a systematic survey of the existing carbohydrate literature, relevant citations are obtained by computer assisted searching on the Chemical Abstract CAS ONLINE service and other important data (for example a compressed structural formula, optical rotation, nuclear magnetic resonance data, melting point) are added manually. The first version of the CCSD and CarbBank released in October 1989 has been revised and updated, the latest version (December 1990) now contains 3888 complex carbohydrate structures. A contract has been negotiated between the European partners, the American collaborators in Georgia and Chemical Abstract services, which has resulted in free exchange of data and thereby securing a much more complete database.
Correlation of structures with Nuclear Magnetic Resonance Spectroscopic data has been facilitated by creating a computer program, which allows easy connection between structure and data. The program is available as a test version.";;;;CSC;DANMARKS TEKNISKE HOEJSKOLE;DK;;;
21681;1453;ROSE;;FP1-ESPRIT 1;;FP1;Research Open Systems For Europe;01/11/1983;01/11/1988;;"The ROSE project brought together five major European computer manufacturers to develop software for Open System Interconnection (OSI). The objectives of the project were to: 
promote OSI concepts and reinforce standardisation work by implementing standards and demonstrating them 
accelerate the availability of OSI products by developing prototypes conforming to CEN/CENELEC profiles. 
The process is an implementation under UNIX of the International Standardisation Organisation (ISO) session service. The main features of the implementation are conformance to the standards, portability of the code and ease of adaptation to different transport service interfaces. Software development has been conducted according to a methodology adapted to the production of portable roots. The protocol machine is clearly isolated from the lower and higher interfaces, and is independent of the system environment (no system cells).

The process is an implementation under UNIX of the International Standardisation Organisation (ISO) session service. The main features of the implementation are conformance to the standards, portability of the code and ease of adaptation to different transport service interfaces. Software development has been conducted according to a methodology adapted to the production of portable roots. The protocol machine is clearly isolated from the lower and higher interfaces, and is independent of the system environment (no system cells).

The project brought together 5 major European computer manufacturers to develop software for Open System Interconnection (OSI). The objectives of the project were to promote OSI concepts and reinforce standardization work by implementing standards and demonstrating them, and to accelerate the availability of OSI products by developing prototypes conforming to Comite europeen normalisation/comite european normalisation electrotechnique (CEN/CENELEC) profiles. At the end of the project, each partner had a complete OSI stack, composed of proprietary implementations, for which interoperability had been demonstrated in both local area network (LAN) (ETHERNET) and wide area network (WAN) environments. Services implemented on top of these stacks included packet assembly and disassembly (PAD) access (X.3, X.28, X.29), X.400 based message handling systems, and file transfer, access and management (FTAM). Prototype network management software was also developed and ported onto all the partners' machines.
At the end of the project, each partner had a complete OSI stack, composed of proprietary or ROSE implementations, for which interoperability had been demonstrated in both LAN (ETHERNET) and WAN environments. Services implemented on top of these stacks included PAD access (X.3, X.28, X.29), X.400-based message-handling systems, and File Transfer, Access and Management (FTAM). Prototype network management software was also developed and ported onto all the partners' machines. As the culmination of the project, a major demonstration was made during the 1988 ESPRIT Conference. 
Exploitation 
The ROSE project largely met its objectives. During its first phase it raised issues related to the implementation of OSI concepts in the real world, such as the methodology of developing conformant products, the need for common interfaces, and the problems raised by the definition and building of OSI networks. During its second phase the validity of the OSI approach was demonstrated by the implementation of common prototypes and their demonstration on different type and makes of hardware. Finally, the know-how gained during the project accelerated the availability of OSI networking products from the partners, either through them deriving products from the ROSE software or by validating existing proprietary products.";;;;;Not Available;;;;
12590;EN3S0086;PASSYS;;FP1-ENNONUC 3C;;FP1;PASSYS;01/07/1986;31/12/1989;;"Work has been done on the design and testing of an advanced passive solar cell test facility.

Work done: PASSYS-test cell improvement, call for tenders for the second series of test cells, HRS installation and test of the first prototype on 19-02-1988, improvement of first prototype, installation and acceptance test of the second prototype on 14-04-1988.
ON THE BASIS OF THE WORK DONE FOR THE FINAL REPORT 'DESIGN OF AN ADVANCED PASSIVE SOLAR TEST FACILITY' (CONTRACT NO. 2498-84-11ED ISP D) THE DFVLR PURSUED THESE ACTIVITIES IN MORE DETAIL. OUR MAIN AREAS OF INTEREST IN 1987 WERE AS FOLLOWS: DESIGN AND CALL FOR TENDERS FOR THE PASSIVE SOLAR TEST CELLS, INSTALLATION ON SITE, PROPOSAL FOR DAS, REDESIGN AND CALL FOR TENDERS AND QUOTATIONS FOR AN ADVANCED HEAT REMOVAL SYSTEM (HRS). 

AS A MEMBER OF THE COORDINATING COMMITTEE (CC) THE DFVLR WAS ASSISTING THE PASSYS COORDINATOR IN THE EXPERIMENTAL PART OF THE PROJECT AND WAS CHARGED BY THE CC WITH THE RESPONSABILITY FOR THE HRS AND TO WRITE A SPECIAL REPORT ('PASSYS - HEAT REMOVAL SYSTEM', MAY 1987), WHICH SHOULD PROVIDE INFORMATION TO ALL THE PASSYS PARTICIPANTS FOR AN ASSESSMENT OF THE TECHNICAL FEASIBILITY OF THE DESIGN PROPOSAL. 
SUBSEQUENTLY WE WERE COORDINATING THE DISCUSSIONS AND IN JULY - ON BEHALF OF THE CC - WE REQUESTED ALL PARTICIPANTS TO ORDER THE SELECTED HRS. THEN WE CONSTRUCTED THE METEOROLOGICAL STATION AND WE INSTALLED THE MEASURING EQUIPMENT PROCURED. 
DUE TO PROBLEMS OF SETTING THE DAS INTO OPERATION WE CONTACTED OUR FRENCH PARTNERS. THE MG1-COMPUTER HAD A HARDWARE ERROR AND WAS SENT TO ENGLAND FOR REPAIR PURPOSES. MEMBERS OF OUR GROUP PARTICIPATED IN SEVERAL SUBGROUP-MEETINGS AND IN THE CEC CONTRACTORS' COORDINATION MEETING IN BRUSSELS.";;;;CSC;GERMAN AEROSPACE CENTRE;DE;UNIVERSITAET STUTTGART;DE;
11707;FI1W0218;COSA;;FP1-RADWASTOM 3C;;FP1;PARTICIPATION IN THE COSA COMMUNITY PROJECT (COMPARISON OF ROCK-MECHANICS CODES FOR SALT).;01/10/1988;30/04/1989;;"EXTENSION OF THE COSA PROJECT TO OTHER TEAMS POSSESSING SKILLS IN CALCULATING THE MECHANICAL BEHAVIOUR OF ROCK SALT AS A DISPOSAL MEDIUM. 

THE COSA PROJECT (CONTRACT FI1W005400) WAS LAUNCHED PRIOR TO SPAIN'S ACCESSION TO THE EUROPEAN COMMUNITIES. THIS CONTRACT COVERS SPAIN'S CONTRIBUTION TO THE PROJECT: DESIGN OF THE THREE LEVELS OF THE EXERCISE, USING APPROPRIATE CODES.";;;;CSC;EMPRESA NACIONAL DE RESIDUOS RADIOACTIVOS S.A.;ES;ESCUELA TECNICA SUPERIOR DE INGENIEROS DE MINAS;ES;
12592;EN3S0088;ARCHISOL;;FP1-ENNONUC 3C;;FP1;ARCHITECTURE AND SOLAR ENERGY;01/08/1986;31/12/1989;;"ARCHISOL HAS THE GOAL OF ADVANCING THE INTRODUCTION OF ENERGY-CONSCIOUS BUILDING INTO THE MAINSTRAM OF ARCHITECTURAL DESIGN. AN EXPERT TEAM OF NATIONAL SUB-CONTRACTORS FORMS THE BASIS OF AN INFORMATION NETWORK AND ACTS AS AN ADVISORY GROUP, REVIEWING THE PROGRESS AND DIRECTION OF THE SOLINFO AND ARCHISOL PROJECTS TWICE ANNUALLY. THERE IS ALSO A SERIES OF RELATED TASKS. THE AREAS OF WORK MAY BE CATEGORISED BROADLY AS FOLLOWS: 
- CONSULTATION; 
- PROFESSIONAL MEDIA; 
- LAY LITERATURE; 
COMPETITIONS; 
- REALISATION. 

SEVERAL INITIATIVES HAVE BEEN IMPLEMENTED TO IMPROVE THE SPEED, QUALITY AND EFFECTIVENESS OF COMMUNICATIONS WITHIN THE GROUP. PRINCIPAL AMONG THESE IS THE USE OF EUROKOM, THE ESPRIT ELECTRONIC MAIL AND COMPUTER CONFERENCING SERVICE. SOME EARLY DIFFICULTIES IN USE HAVE BEEN EXPERIENCED, BUT THE SYSTEM HAS CONSIDERABLE ATTRACTIONS. 
SEVERAL FEATURE ARTICLES AND REVIEWS OF EXEMPLARY PASSIVE SOLAR BUILDINGS HAVE BEEN PLACED IN NATIONAL AND INTERNATIONAL ARCHITECTS'JOURNALS. IN ADDITION, THE BUILDINGS FEATURED IN THE PROJECT MONITOR BROCHURES HAVE BEEN BROUGHT TO A WIDER AUDIENCE THROUGH A SERIES OF REPRINTS IN PROFESSIONAL PERIODICALS. WORKING RELATIONSHIPS WITH JOURNALISTS AND EDITORS HAVE BEEN ESTABLISHED. CONTACT HAS BEEN INITIATED WITH CICA, THE INTERNATIONAL ORGANISATION OF ARCHITECTURAL CRITICS. 
AN INNOVATIVE EXHIBITION OF TRADITIONAL OR VERNACULAR ENERGY-SENSITIVE ARCHITECTURE FROM THE DIFFERENT EUROPEAN REGIONS IS BEING PREPARED. THE EXHIBITION, IN THE FORM OF A NUMBER OF HIGH-QUALITY POSTERS, IS TARGETED PRIMARILY AT ARCHITECTS AND STUDENTS OF ARCHITECTURE, AND WILL BE WIDELY DISSEMINATED. 
A VIDEO PROGRAMME IN THE ENGLISH LANGUAGE TO INTRODUCE PASSIVE SOLAR DESIGN TO EUROPEAN LAY AUDIENCES IS NEARING COMPLETION. THE TARGET AUDIENCE ARE THOSE PEOPLE WHO HAVE AN INVOLVEMENT IN ORGANISING AND FUNDING BUILDING AND RENOVATION PROJECTS BUT WHO DO NOT THEMSELVES HAVE ANY TECHNICAL TRAINING. THE VIDEO IS BEING DESIGNED TO ALLOW FOR EVENTUAL TRANSLATION INTO OTHER EC OFFICIAL LANGUAGES. 
'WORKING IN THE CITY', THE THIRD EC ARCHITECTURAL IDEAS COMPETITION - SPECIFICALLY FOR THE DESIGN OF NON-DOMESTIC BUILDINGS IN EUROPEAN CITIES AND TOWNS - WAS LAUNCHED IN MAY 1988, AND IS OPEN TO ALL ARCHITECTS RESIDENT IN THE EC. THERE IS A SEPARATE SECTION FOR STUDENT ENTRIES. DOCUMENTS ARE AVAILABLE IN ALL NINE EC OFFICIAL LANGUAGES, AND THERE IS A TOTAL PRIZE FUND OF 40000 ECUS. THE CLOSING DATE FOR ENTRIES IS 30 NOVEMBER 1988. THE TECHNICAL ASSESSORS AND THE ARCHITECTURAL JURY - FIVE OF EUROPE'S LEADING ARCHITECTS, FROM BRITAIN, FRANCE, GERMANY, ITALY AND PORTUGAL - WILL COMPLETE THEIR WORK IN JANUARY 1989. A BOOK OF THE WINNING ENTRIES WILL BE PUBLISHED. 
ALL THOSE WHO REGISTER FOR THE COMPETITION WILL RECEIVE THE PUBLICATION, 'TECHNICAL DESIGN GUIDELINES FOR THE THERMAL AND DAYLIGHTING DESIGN OF NON-DOMESTIC BUILDINGS'. THE PUBLICATION AND A NEW EUROPEAN DAYLIGHT FACTOR METER HAVE BEEN SPECIFICALLY DEVELOPED FOR THE COMPETITION, BUT ARE SUITABLE FOR WIDER APPLICATION.";;;;CSC;UNIVERSITY COLLEGE DUBLIN;IE;;;
11913;EV4V0076;EUROCORE;;FP1-ENVPROT 4C;;FP1;A EUROPEAN ICE-CORE PROGRAMME ON ATMOSPHERIC CHEMISTRY AND CLIMATE;01/01/1988;31/03/1992;;"TO STUDY THE ATMOSPHERIC CHEMISTRY CHANGES AND THE COMPOSITION OF THE PRE-INDUSTRIAL ATMOSPHERE IN THE NORTHERN HEMISPHERE FROM APPROXIMATELY 800 AD TO PRESENT.
A 300 m deep ice core was drilled at Summit (central Greenland) in order to study the atmospheric chemistry changes and the composition of the preindustrial atmosphere in the Northern Hemisphere over the last millennium and to investigate more specifically the changes in composition, chemical element concentrations and seasonal deposition patterns caused by anthropogenic activities.

The results from the project involved the following:
new analytical methods for ice stripes;
determination of the isotopic temperature;
determination of the lag between the age of the gas entrapped in the bubbles and that of the ice in which they are contained (210 y at Summit);
confirmation of the carbon dioxide increase since the industrial revolution;
observation of strong seasonal variations and a 50% increase in hydrogen peroxide levels over the last 200 years;
linking concentration of hydrogen peroxide in the ice with the oxidation capacity of the atmosphere;
observation of increased concentrations of nitrate sulphate ions (2 and 3 to 4 times higher respectively than the preindustrial levels);
observation of strong seasonal variations (summer maxima) of methylsulfonate concentrations;
determination of carboxylic acids in the ice at the parts per billion (ppb) level;
observation of lack of increase in background ammonium level in relation to pollution;
observation of increased hydrochloric acid concentrations by about 50% during the last decades (a similar trend is observed for fluoride);
a study of carbonaceous aerosol at various depths;
determination of trace metal concentrations at parts per thousand (ppt) levels;
nitrogen isotope measurements in nitrate which indicate a significant difference between preindustrial (\12 to \18%) and present figure (0%) which are very similar to European rain values;
detection of the most important volcanic eruptions of the Northern Hemisphere over the last 12 centuries by electroconductometric (ECM) measurements.
THE PROJECT IS DIRECTED TO EXTRACT SEVERAL ICE CORES FROM A REMOTE SITE IN GREENLAND IN 1989 AND TO DETERMINE TRACE GASES, OTHER ELEMENTS AND VARIOUS OTHER PARAMETERS IN THESE CORES. 

IT IS IMPLEMENTED WITH THE CONTRIBUTIONS FROM 3 INSTITUTES: 
 PROPOSAL 208, CNRS GRENOBLE, PROPOSAL 466, UNIVERSITY OF COPENHAGEN AND A CONTRIBUTION FROM SWITZERLAND, UNIVERSITY OF BERN. 

THE PROJECT COMPRISES THE PREPARATION OF THE DRILLING OPERATIONS, EQUIPMENT DESIGN AND CONSTRUCTION AND THE ANALYSES OF THE DEEP - FROZEN ICE-CORE; IT WILL PERMIT TO ESTABLISH A RECORD OF THE EVOLUTION OF ALL IMPORTANT TRACE GASES IN THE ATMOSPHERE DURING THE LAST 1200 YEARS AND HENCE SUPPLY ESSENTIAL DATA FOR THE WHOLE CLIMATOLOGY PROGRAMME.";;;;CSC;CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE;FR;UNIVERSITY OF COPENHAGEN;DK;
12595;EN3S0085;PASSYS;;FP1-ENNONUC 3C;;FP1;PASSYS;01/03/1986;31/12/1989;;"THE GENERAL OBJECTIVES OF PASSYS ARE TO INCREASE CONFIDENCE IN PASSIVE SOLAR SIMULATION MODELS AND DESIGN TOOLS WHICH HAVE TO BE FURTHER DEVELOPED AND VALIDATED, AND TO DEVELOP RELIABLE AND AFFORDABLE TEST PROCEDURES FOR PASSIVE SOLAR COMPONENTS AND SYSTEMS. 

THE GENERAL OBJECTIVES OF PASSYS ARE TO INCREASE CONFIDENCE IN PASSIVE SOLAR SIMULATION MODELS AND DESIGN TOOLS WHICH HAVE TO BE FURTHER DEVELOPED AND VALIDATED, AND TO DEVELOP RELIABLE AND AFFORDABLE TEST PROCEDURES FOR PASSIVE SOLAR COMPONENTS AND SYSTEMS. 

THE WORK ARE BASED ON TEST CELLS IN WHICH PASSIVE SOLAR SYSTEMS WILL BE INVESTIGATED, AND BY MEANS OF THE ENERGY SIMULATION MODEL ESP BY WHICH THE PERFORMANCE OF DIFFERENT PASSIVE SOLAR SYSTEMS CAN BE CALCULATED. 

TWO TEST CELLS ARE CONSTRUCTED, AND PLACED AT THE TEST SITE OF THE TECHNICAL UNIVERSITY. THE DATA ACQUISITION SYSTEM, THE WIRING AND THE SENSORS ARE INSTALLED. THE SIMULATION MODEL ESP IS INSTALLED ON AN SUN WORKING STATION. 

DENMARK IS THE PROJECT LEADER OF THE SUBGROUP: MODEL VALIDATION AND DEVELOPMENT. THE WORK IN THIS GROUP INCLUDES A REVIEW OF PAST AND CURRENT VALIDATION WORK, AND ON THE BASIS OF THIS THE WORK WILL BE CONCENTRATED ON AN ALGORITMIC LEVEL FOR A NUMBER OF DIFFERENT TOPICS. FOR EACH OF THESE WILL BE ELABORATED: A REVIEW OF THE THEORY BEHIND THE PHYSICAL PROCESSES, A STUDY OF THE ALGORITMS IN ESP, DEVELOPMENT AND EXECUTION OF ANALYTICAL AND CONSISTENCY CHECKS.";;;;CSC;TECHNICAL UNIVERSITY OF DENMARK;DK;PARTICIPANTS IN PROJECT PASSYS;;
12043;EV4C0060;ARCTEMIZ;;FP1-CLIMAT 3C;;FP1;OBSERVATIONS-MODELLING OF AIR-SEA-ICE INTERACTION NORTH OF EUROPE;01/12/1987;30/11/1991;;"TO UNDERSTAND THE SEA-ICE SEASONAL AND INTERANNUAL CYCLE. 

THE GENERAL APPROACH FOR THIS PROJECT IS :   1. FROM OBSERVATIONS SUCH AS AVERAGE SURFACE WIND FIELDS, SURFACE OCEAN CURRENTS SST AND SEA-ICE EXTEND AND AIR-OCEAN FLUXES, TO INFER FORCING FUNCTIONS TO DRIVE OCEAN-ICE MODELS.   2. TO CONTROL FROM OBSERVATIONS SUCH AS SEA-ICE CONCENTRATION MOTIONS, DEFORMATIONS THICKNESS DISTRIBUTIONS AND ICE FLUXES THROUGH THE STRAITS, HOW WELL MODELS ARE GOOD AT REPRODUCING AND PREDICTING MAIN FEATURES AND EVENTUALLY TO APPLY NECESSARY CORRECTIONS.   IN THAT CONTEXT, REMOTE SENSING INFORMATIONS FROM SAR IN PARTICULAR WILL BE OF UPMOST IMPORTANCE IN COMBINATION WITH IN SITU DATA AND OTHER SATELLITE INFORMATIONS AS STATED BY THE PIPOR GROUP. (PROGRAM FOR INTERNATIONAL POLAR OCEANS RESEARCH).A. TO OBSERVE SIMULTANEOUSLY ICE MOTIONS, SURFACE WINDS AND CURRENTS, SEA-ICE GROWTH AND DECAY, CONCENTRATION AND THICKNESS DISTRIBUTION.REGARDING SEA-ICE MOTIONS AND SURFACE CURRENTS. WE WILL MOSTLY RELY ON LAGRAGIAN TECHNICS SUCH AS ARGOS BUOYS AND SOFAR FLOATS FOR IN SITU OBSERVATIONS, AND HIGH RESOLUTION REMOTE SENSING.CONCERNING SURFACE WINDS, IN A FIRST APPROACH, WE SHALL CONSIDER GEOSTROPHIC WINDS PRODUCED FROM SURFACE ATMOSPHERIC PRESSURE MEASURED AT BUOYS LOCATIONS AND LAND STATIONS ON NORTH COAST OF GREENLAND AND ON SVALBARD. REGARDING SEA-ICE GROWTH AND DECAY ARGOS BUOYS WILL BE EQUIPED WITH THERMISTOR CHAIN GOING ACROSS THE ICE FROM WHICH WE CAN DEDUCE LOCALLY ICE THICKNESS VARIATIONS AND HEAT FLUXES AT THE ICE-OCEAN INTERFACE. SEA-ICE CONCENTRATION AND THICKNESS DISTRIBUTION WILL BE DEDUCED TEMPORARILY FROM REMOTE-SENSING OBSERVATIONS SUCH AS VISIBLE (SPOT) INFRARED (AVHRR AND LATER ON, MORE REGULARLY, FROM ACTIVE AND PASSIVE MICROWAVE (SAR ON ERSI - SSM/I ON DMSP). IN ADDITION THICKNESS DISTRIBUTION WILL BE IMPROVED BY ADDING INVERTED ECHO SOUNDERS ON SOFAR FLOATS (NEUTRALLY BUOYANT DRIFTING FLOATS).B. TO DEVELOP A HIERARCHY OF ICE-OCEAN COUPLED MODELS DEDICATED TO PRECISE ESTIMATIONS OF ICE-OCEAN FLUXES OF MOMENTUM, HEAT AND SALT UNDER PROPER ATMOSPHERIC FORCING RESULTING FROM A DETAILED ANALYSIS OF METEOROLOGICAL OBSERVATIONS.   THE MAIN FEATURES OF THESE ICE-OCEAN MODELS USING TENSORIAL COORDINATES TO AVOID INCOHERENCY ON GRID SCALING WILL BE :   A 3D STRATIFIED OCEAN MODEL USING PRIMITIVE EQUATATIONS ALREADY EXISTING AT LODYC COUPLED WITH A MIXED LAYER MODEL TAKING CARE OF A NON HOMOGENEOUS SURFACE LAYER RELATED TO VARIABLE SEA-ICE CONCENTRATIONS. THE 'HETEROGENEOUS' MIXED LAYER MODEL WILL COMPUTE THE TEMPERATURE AND THICKNESS OF THE MIXED LAYER. IT WILL ALSO CONSIDER A SALT BALANCE DUE TO THE MELTING-FREEZING CYCLES AND INCORPORATE THE SURFACE HETEROGENCEITY INTO THE COMPUTATION THROUGH A 2D DIFFUSION MODEL. THE MIXED LAYER MODEL WILL BE COUPLED, ITS A SEA-ICE DYNAMICAL-THERMODYNAMICAL MODEL.THE WIND FORCING ON AN ICE EDGE WILL BE ANALYSED BOTH BY ANALYTICAL AND NUMERICAL MODELLING DEPENDING UPON THE ORIENTATION OF THE WIND RELATIVE TO THE ICE EDGE AND DEPENDING UPON THE GEOMETRY OF THE EDGE.";;;;CSC;Centre National de la Recherche Scientifique (CNRS);FR;"UCL;RIJKSUNIVERSITEIT;LAB METEOROLOGIE DYNAMIQUE;CENTRE NATIONAL DE RECHERCHE METEOROLOGIQUE;UK METEOROLOGICAL OFFICE;SCOTT POLAR RESEARCH INSTITUTE";;
11694;FI1W0245;COMPAS;;FP1-RADWASTOM 3C;;FP1;ASSESSMENT OF STRUCTURAL PERFORMANCE OF HLW CONTAINERS (EXTENSION OF CONTRACT FI1W021900);01/01/1989;31/12/1989;;"THE COMMISSION OF THE EUROPEAN COMMUNITIES HAS LAUNCHED A PROJECT ON THE ASSESSMENT OF THE MECHANICAL PERFORMANCE OF METALLIC CONTAINERS TO BE USED AS OVERPACKS FOR THE DISPOSAL OF VITRIFIED HIGH LEVEL WASTE IN DEEP GEOLOGICAL FORMATIONS (PROJECT COMPAS). THE PROJECT COVERS BOTH COMPUTATIONAL AND EXPERIMENTAL WORK AND IS COORDINATED BY OVE ARUP & PARTNERS UNDER CONTRACT WITH THE CEC. 

ENRESA WILL PARTICIPATE IN THE SECOND BENCHMARK EXERCISE. 
THIS EXERCISE WILL MAINLY CONCERN THE CALCULATION OF BENCHMARK PROBLEMS BASED ON EXPERIMENTAL TESTS ON THE MECHANICAL BEHAVIOUR OF METALLIC CONTAINERS. IN PRINCIPLE THREE DIFFERENT KIND OF EXPERIMENTAL TESTS ARE PLANNED: 
   - PRELIMINARY TESTS ON SIMPLE RING ELEMENTS 
   - INTERMEDIATE TESTS ON SIMPLIFIED CONTAINER MODELS 
   - ADVANCED TESTS ON SCALE CONTAINER MODELS; 
ENRESA WILL PARTICIPATE IN THE BENCHMARK PROBLEMS, ON THICK WALL CONTAINER CONCEPT, DEFINED ON THE BASIS OF THE EXPERIMENTAL TESTS MENTIONED ABOVE. 
THE CALCULATION WILL BE CARRIED OUT BY USING THE ANSYS COMPUTER PROGRAMME.";;;;CSC;EMPRESA NACIONAL DE RESIDUOS RADIOACTIVOS S.A.;ES;OVE ARUP & PARTNERS;CH;
12028;EV4C0080;HAPEX;;FP1-CLIMAT 3C;;FP1;SPATIAL VARIABILITY OF LAND-SURFACE PROCESSES;01/11/1987;31/10/1990;;"FIVE MAIN STEPS WILL BE FOLLOWED. WE WILL : 

I) USE FINER-SCALE, HIGHER-FREQUENCY, RADIOSOUNDING NETWORK ON THE ONE HAND, AND MESO-SCALE ANALYSIS AND MODEL-ASSIMILATION ON THE OTHER HAND, IN ORDER TO BETTER DESCRIBE THE 'LARGE-SCALE' ATMOSPHERIC FORCING ACTING ON LAND-SURFACE PROCESSES ; 

II) USE THE ABOVE LARGE-SCALE ATMOSPHERIC FORCING AND THE 13 LOCAL MEASUREMENTS OF EVAPORATION FLUXES AND RELATED SURFACE PARAMETERS TAKEN AT THE SPECIALLY INSTRUMENTED MICROMETEOROLOGICAL STATIONS AND THE FOREST MAST, TO CALIBRATE UP TO 13 VERSIONS OF A SIMPLE ONE-DIMENSIONAL LAND-SURFACE MODEL ; 

III) USE SURFACE FIELDS OF VARIOUS PARAMETERS, E.G. ALBEDO, EMISSIVITY, TYPE OF SOIL, TYPE AND MATURITY OF VEGETATION,..., TO DISTINGUISH BETWEEN AT MOST 13 DIFFERENT CLASSES OF SURFACE CHARACTERISTICS, EACH OF WHICH BEING POSSIBLY DESCRIBED BY ONE OF THE ABOVE LAND-SURFACE MODELS ; 

IV) IMPLEMENT THE THREE-DIMENSIONAL NUMERICAL MODEL WITH SURFACE FEATURES AND PARAMETERIZATION SCHEMES VARYING HORIZONTALLY ACCORDING TO STEPS (II) AND (III), AND ESTIMATE FROM IT THE TOTAL EVAPORATION FLUX OVER THE HM86 NETWORK AS WELL AS THE EFFECTIVE EVAPORATION FLUX CORRESPONDING TO THE FLIGHT PATH OF THE INSTRUMENTED AIRPLANE ; 

V) COMPARE THE 'MODEL' AIRPLANE FLUX TO THE OBSERVED ONE, AND RESOLVE POSSIBLE DISCREPENCIES BY GOING BACK TO STEP (I) FOR DEFINING THE ATMOSPHERIC FORCING OR TO STEP (III) FOR MODIFYING THE PORTION OF THE TOTAL AREA WHERE A GIVEN TRANSFER MODEL IS SUPPOSED TO BE REPRESENTATIVE.";;;;CSC;Centre National de la Recherche Scientifique (CNRS);FR;"INST DE MECANIQUE DE GRENOBLE;METEOROLOGICAL OFFICE;UNIVERSITY OF BOLOGNA;DEPT OF CIVIL ENGINEERING;AGRICULTURAL UNIV WAGENINGEN;LMD DU CNRS";;
14019;FI1W0047;PACOMA;;FP1-RADWASTOM 3C;;FP1;VALIDATION OF THE VAULT COMPUTER MODEL 'VERMIN' FOR POST-CLOSURE BEHAVIOUR OF REPOSITORIES IN GEOLOGICAL FORMATIONS (CLAY).;01/10/1986;31/05/1987;;"THE COMPUTER MODEL VERMIN HAS BEEN DEVELOPED TO SIMULATE THE POST CLOSURE TIME DEPENDENT BEHAVIOUR OF THE VAULT SECTION OF SHALLOW AND DEEP LAND BURIAL TYPES OF REPOSITORY. DEVELOPMENT WAS CARRIED OUT WITHIN THE CONTRAINTS OF THE PROBABILITIC ASSESSMENT COMPUTER CODE SYVAC/1/. 
THE PRESENT RESEARCH CONDUCTED FOR THE UK DEPARTMENT OF ENVIRONMENT INVOLVES BOTH THE GATHERING OF EXPERIMENTAL DATA AND ITS USE IN VALIDATING THE VERMIN SUB-MODEL WITHIN SYVAC. THE EXPERIMENTAL DATA WILL BE USED TO VALIDATE THE PROCESSES CURRENTLY MODELLED OF NUCLIDE MIGRATION AND GROUNDWATER IN A REPOSITORY. TO UPDATE VERMIN WHERE THE RESULTS OF THE VALIDATION EXERCISE SUGGEST THAT IT IS NECESSARY. TO IDENTIFY NEEDS FOR FURTHER EXPERIMENTAL WORK IN ORDER TO CALIDATE ASPECTS OF VER\IN AND POSSIBLE NEW ASPECTS OF THE VAULT MODEL FOR WHICH NO APPLICABLE DATA EXIST.  
FINALLY, TO ENSURE THAT VERMIN PROVIDES A  SUITABLE SOURCE TERM FOR THE AERE GEOSPHERE MODEL. CONCERNING THIS LAST OBJECTIVE, FINAL AGREEMENT ON THE UK INVENTORY MUST ALSO BE REACHED. 

B.1. IDENTIFICATION OF FUNDAMENTAL PHYSICAL AND CHEMICAL PROCESSES FOR EACH ELEMENT OF THE REPOSITORY MODEL. 
B.2. GATHERING AND SORTING EXPERIMENTAL DATA FOR THE PROCESSES IDENTIFIED. 
B.3. AREAS REQUIRING FURTHER EXPERIMENTAL WORK MUST BE IDENTIFIED AND EXPERIMENTS SUGGESTED. 
B.4. VALIDATION FOR VERMIN MODEL. 
B.5. REFINEMENTS TO THE VERMIN MODEL WHERE THE RESULTS OF THE VALIDATION EXERCISE SUGGEST IT IS NECESSARY, INCLUDING THE POSSIBLE ADDITION OF NEW PHYSICAL AND CHEMICAL PROCESSES. 
B.6. ACHIEVEMENT OF FINAL AGREEMENT ON THE UK INVENTORY. 
B.7. VERMIN WILL BE ADAPTED TO PROVIDE A COMPATIBLE SOURCE TERM FOR THE AERE GEOSPHERE MODEL.";;;;CSC;Electrowatt Engineering Services Ltd;UK;;;
13697;BAP*0193;MINE;;FP1-BAP;;FP1;A EUROPEAN NETWORK OF MICROBIAL CULTURE COLLECTION DATABANKS: INTEGRATED CATALOGUE;01/03/1987;31/12/1990;;"CATALOGUE INFORMATION AND STRAIN DATA OF THE MAJOR EC CULTURE COLLECTIONS WILL BE AVAILABLE ON-LINE FOR RESEARCH WORKERS, INDUSTRIALISTS AND OTHER USERS. 

ULTIMATELY, THE PROJECT WILL LEAD TO A GREATER INTEGRATION OF EC CULTURE COLLECTIONS AND TO THEIR INCREASED COMPETITIVITY. 
The MINE project was started to meet society's increasing need for up to date, rapidly accessible and authoratative information on microorganisms kept in culture collections. This need is particularly manifest for biotechnology. In this light, the European Economic Community (EEC) activated collections in Belgium, Germany, the Netherlands and the United Kingdom (UK), to start a common information network, which has now been extended to collections in France, Greece, Italy, Portugal and Spain.

The major result of this project is that agreement has been reached on storage of microbial data according to a common format. The information stored in important collections has now been formatted according to this system. Part of the local and national collections can be consulted online. The national collections in turn act as focal points for collections in the respective countries. The network has thus developed with many more participants than orginally stated. Integrated databases have been created for fungi and yeasts and for bacteria. Each of these databases contains catalogue and extended data from various national nodes.
REPRESENTATIVES OF CULTURE COLLECTIONS IN BELGIUM, GERMANY, THE NETHERLANDS, THE UNITED KINGDOM AND PORTUGAL, WILL ESTABLISH A MICROBIAL INFORMATION NETWORK FOR EUROPE (MINE) DURING THE PERIOD 1986-1989. 

THE NETWORK WILL CONSIST OF A CENTRAL DIRECTORY INTERFACED WITH REGIONALLY CO-ORDINATED DATABASES. IT IS ANTICIPATED THAT ALL PUBLIC CULTURE COLLECTIONS IN COUNTRIES PARTICIPATING IN THE MINE PROJECT WILL BE REPRESENTATED BY A DATABASE CREATED BY THE CURATOR OF THE COLLECTION IN CONJUNCTION WITH TECHNICAL AND DATA ENTRY PERSONNEL AT THE REGIONAL DATABASE SITE. 

AIM OF THE PORTUGUESE PROJECT :  

A) REIDENTIFICATION OF THE 1 400 STRAINS OF THE YEAST CULTURE COLLECTION OF THE GULBENKIAN INSTITUTE OF SCIENCE, OEIRAS, PORTUGAL, BASED ON LABORATORY DATA OBTAINED FOLLOWING THE MINE FORMAT FOR YEAST STRAIN RECORDS; 
B) INTRODUCING OF IMPROVED METHODS FOR THE MAINTENANCE OF CULTURE COLLECTIONS; 
C) PREPARATION AND PUBLICATION OF A CATALOGUE OF THE COLLECTION; 
D) INTEGRATION OF THE COLLECTION IN THE 'MICROORGANISMS INFORMATION NETWORK IN EUROPE' (MINE) AND PERSPECTIVE DATA BANK(S).";;;;CSC;INSTITUTO GULBENKIAN DE CIENCIA;PT;"CBS;Commonwealth Agricultural Bureaux (CAB);SPPS;Deutsche Sammlung von Mikroorganismen und Zellkulturen GmbH";"NL;UK;BE;DE";
13661;BAP*0235;TGEV;;FP1-BAP;;FP1;PRODUCTION OF GLYCOPOLYPEPTIDE ANTIGENS OF PORCINE TRANSMISSIBLE GASTROENTERITIS VIRUS (TGEV);01/04/1987;31/12/1989;;"OBTENTION OF A VACCINE AGAINST TRANSMISSIBLE GASTRO-ENTERITIS OF PIG. 
Studies were aimed at identifying, characterizing and defining the roles of the gene products of poraine transmissable gastroenteritis virus (TGEV) in pathogenesis and immunity by means of recombinant deoxyribonucleic acid (DNA) technology. Two of the viral strucutral proteins were glycosylated and one of them, the peplomer, contained regions to which antiboides could attach, thereby preventing viral growth. In order to express the peplomer protein and identify regions involved in immunity, the isolation, sequencing and expression of TGEV genes in recombinant viruses and in yeast was carried out. Seven TGEV genes were identified and sequenced. Three of the gene products, nucleoprotein, integral membrane protein and peplomer, were involved in the structure of the virus particle and have been expressed in bacteria, yeast and vaccinia virus. Specific antibodies were raised against the structural proteins and these led to the identification of a specific antibody binding site on the nucleoprotein and several specific sites on the peplomer. The peplomer protein expressed by vaccinia virus still reacted with all the specific antibodies and the relative positions of 4 antigenic sites were identified on the peplomer protein. Antisera to the peplomer expressed by vaccinia appeared to prevent viral growth and disease in piglets.
THE OBJECTIVE OF THE RESEARCH IS TO CLONE THE MAIN STRUCTURAL PROTEINS OF THE TRANSMISSIBLE GASTRO-ENTERITIS VIRUS, TO OBTAIN THE EXPRESSION IN VACCINIA VIRUS, YEAST OR IN ESCHERICHIA COLI. PURIFICATION OF THE PROTEINS OBTAINED AND TESTING OF THEIR IMMUNOLOGICAL PROPERTIES.";;;;CSC;INSTITUTE FOR ANIMAL HEALTH;UK;UNIVERSIDAD DE OVIEDO;ES;
13990;FI1W0111;COMPAS;;FP1-RADWASTOM 3C;;FP1;ASSESSMENT OF STRUCTURAL PERFORMANCE OF HLW CONTAINERS;01/04/1987;31/12/1989;;"THE COMPAS PROJECT HAS BEEN DESIGNED TO LOOK AT THE MECHANICAL PERFORMANCE OF THOSE CONTAINERS WHICH WILL BE USED FOR OVERPACKING AND DISPOSING OF HIGH LEVEL RADIOACTIVE WASTE. BY AGREEMENT OF THE PARTNERS IT WILL BE RESTRICTED TO THE EXAMINATION OF CONTAINERS FOR VITRIFIED WASTE RATHER THAN CONTAINERS FOR THE DIRECT DISPOSAL OF SPENT FUEL. THE PROJECT IS NOT CONCERNED WITH THE PRODUCTION OF A SPECIFIC DESIGN FOR LICENSING PURPOSES; IT IS ONLY INTENTED TO INVESTIGATE THE CHARACTERISTICS OF REPRESENTATIVE DESIGNS 

THE OBJECTIVES OF THE COMPAS PROJECT ARE TO LOOK AT THE MECHANICAL PERFORMANCE OF THESE CONTAINERS AND DEVELOP AN UNDERSTANDING OF HOW THEY WILL BEHAVE WHEN SUBJECT TO THE MOST EXTREME CONDITIONS WHICH CAN BE FORESSEN IN REALISTIC DISPOSAL SCENARIOS. 

IN ORDER TO PREDICT THE ULTIMATE MECHANICAL PERFORMANCE OF THE DISPOSAL CONTAINERS IT WILL BE NECESSARY TO USE COMPUTER AIDED MODELLING TECHNIQUES. THE EARLY PART OF THE COMPAS PROJECT THEREFORE INCLUDES A CONSIDERABLE AMOUNT OF COMPUTATIONAL WORK WHICH IS AIMED AT DEVELOPING CONFIDENCE IN THE USE OF THESE TECHNIQUES. 

DURING THE YEAR THE CONTRACT WAS EXTENDED TO INCLUDE A MORE COMPREHENSIVE PROGRAMME OF TESTWORK AND ASSOCIATED COMPUTING. THE REVISED PROJECT PLAN NOW COMPRISES THE FOLLOWING ACTIVITIES: 
1. DIRECTORY OF COMPUTER CODES 
2. CONTAINMENT CONCEPTS 
3. FIRST BENCHMARK EXERCISE 
4. PRELIMINARY RING TESTS 
5. INTERMEDIATE TESTWORK 
6. ANDVANCED TESTWORK 
7. PREDICTION OF ULTIMATE PERFORMANCE.";;;;CSC;OVE ARUP PARTNERSHIP LTD;UK;STEAG KERNENERGIE;BE;
14134;BI6*0298;THOROTRAST;;FP1-RADPROT 6C;;FP1;THOROTRAST INVESTIGATIONS TO EVALUATE THE LONG TERM EFFECTS CAUSED BY ARTIFICIAL RADIATION IN MAN (THOROTRAST PATIENTS) FOLLOW-UP STUDY;01/01/1985;30/04/1992;;"In 1929 Radt (Berlin) and Oka (Tokyo) introduced a stabilized 25% colloidal solution of thorium dioxide as a radiodiagnostic contrast medium which was sold under the trade name Thorotrast. The predominant form of application was an intravascular injection, especially for cerebral angiography. After intravascular injection the ThO2 aggregates accumulate in the reticuloendothelial system (RES) and are stored for life. 

From the data on the 232Thorium distribution in the tissue and the activity ratios combined with information about the various types of radiation, the average energy per decay of each radionuclide and the cell absorption of alpha-particles in ThO2 aggregates, Kaul and Noffz calculated mean values for the annual radiation dose of the organs of the RES. A  mean intravascular injection of 25 ml Thorotrast in a 70 kg person causes the following absorbed dose rates: liver 25 cGy/year; spleen 70 cGy/year; bone marrow 9 cGy/year; endothelial layer in bone 16 cGy/year; kidneys 0.4 cGy/year. The radiation dose in the lung tissue is mainly caused by the daughter product 220Rn which is exhaled by the breath. 

The objective of the German Thorotrast study was: 
to trace the largest possible number of Thorotrast patients who had been given intravascular injection; 
to determine the thorioum dioxide quantities incorporated; 
to compare the health and the fate of Thorotrast patients with those of a control group; 
to relate long term effects of Thorotrast found to the radiation dose in the depository organs. 

Apart from answering these scientific questions, it was intended to provide a comprehensive treatment for these patients and to advise the physicians as well as the patients themselves. 

Objectives for 1990 and 1991 

The working programme will be continued according to the recommendations of the coordinating committee: 
regular correspondence with about 600 patients of the Thorotrast and control group as well with the respective family physicians; 
outpatient reexaminations of Thorotrast carriers and patients of the control group at two years intervals; 
computer suitable registration of examination data and medical reports of the family doctors as well as the treating hospitals; 
controlling of the stored data and preparation of final statistical evaluation. 
The aim of the study was to uncover the late effects of incorporated colloidal thorium dioxide by epidemiological observation and clinical and biophysical examination and to compare the results with those of a corresponding control group.

The final fate of the thorotrast patients is the most important parameter for the calculation of the thorotrast late effects. The following 3 groups of diseases leading to death are discussed:
 diseases with high excess rate in the group of thorotrast patients;
diseases with possible excess rate;
diseases without apparent excess rate.

Diseases with high excess rate:
A significant excess rate was observed in malignant liver tumours, liver cirrhosis, myeloid leukaemias and bone marrow failures. The relative risk of malignant liver tumours for all thorotrast patients is about 200. The latency period of malignant liver tumours ranged from 16 to more than 45 years. In 5 patients sarcoma and carcinoma simultaneously manifested in 1 liver. Cirrhosis was present in about 30% of liver tumour patients and in about 10% of the nonliver tumour patients.

The cumulative rate of malignant liver tumours and leukaemias was calculated with the sum limit method by putting each case of liver cancer in relation to the number of individuals still at risk; this fraction is summed by year by year. The frequency of malignant liver tumours in male patients is significantly higher than in female patients. However, there was no difference between male and female patients. However, there was no difference between male and female patients with regard to age at injection, mean volume of injected thorotrast and exposure time; so it must be stated that males are more sensitive than females to thorotrast induced liver cancer. About 6% of liver cancer patients suffered from a second neoplastic disease.

The induction of malignant liver tumours is caused by the chronic irradiation and not by the foreign body effect. For the calculation of the relationsh ip between dose rate and effect 3 cohorts were formed being injected with 1 to 10 ml, 11 to 20 ml, and more than 20 ml thorotrast. The correlation between the dose rate to the liver expressed by the mean volume of administered thorotrast and the cumulative rate of malignant liver tumours is quite evident.
4 cohorts were formed to study the frequency of liver tumours as a function of the age at injection.

 In each age group a marked increase in the liver tumour rate occurs 30 to 40 years after injection.

In each age group a marked increase in the liver tumour rate occurs 30 to 40 years after injection.

The risk estimates for malignant liver tumours in the German thorotrast study were calculated for all patients that had either whole body counting or the injected thorotrast volume recorded in the patient file with the following assumptions. Patients who have died within the first 15 years of exposure were excluded from the evaluation as they are not at risk for malignant liver tumours. The dose delivered during the last 10 years before clinical manifestation of the malignant liver tumours will be looked upon as wasted dose decause the tumour already exists growing from microscopical to clinical dimensions. There is a clear difference between the risk for male and female patients, which comes up after 40 years to 500 and 300 malignant liver tumours per E4 person Gy, respectively. In the thorotrast patients with liver cancer, the 3 lowest doses at 10 years before diagnosis were 1.88, 2.65 and 2.71 Gy in female and 1.98, 2.06 and 2.30 Gy in male patients.

Myeloproliferative diseases (n=37) were observed about 10 times more often in the thorotrast group as compared to the control group. The majority were classified as acute myeloid leukaemias (25 cases); the reminder were described as erythroleukaemia (3 cases), monocytic leukaemia (5 cases) and chronic myeloid leukaemia (4cases). The relatively high number of erythroleukaemia, which was also described in the Japanese thorotrast study is remarkable. The shortest latency period ina luekaemia case was 5 years. A close correlation between dose rate in the bone marrow and frequency of leukaemias could not yet be proved. The 3 smallest accumulative doses to the red bone marrow at time of death in myeloid leukaemia patients were 0.23, 0.69 and 0.73 Gy. The term bone marrow failure was used collectively for aplastic anaemia, agranulocytosis and thrombocytopenia. It is well known that these diseases may be caused by a variety of drugs, however, they are clearly more frequent in the group of thorotrast patients.

Diseases with a probable excess rate:
 An excess rate of some neoplastic diseases in the thorotrast group is possible. However, consideration must be given to the fact that these figures may change in the following years. The last years have shown an increase of carcinomas of the extrahepatic bile ducts including carcinoma of the gall bladder. Daughter products in the bile and irradiation of the gall bladder wall by thorium aggregates in the surrounding liver could be the source of irradiation. The excess rate of oesophageal cancer and pancreatic cancer is difficult to explain. The excess or laryngeal cancer, however, might be related to the exhaled thoron. There is a constant small excess of the non-Hodgkin lymphoma during the last years. The same is true with regard to bone sarcomas; these 4 patients were injected at the end of their skeletal growth phase and had long exposure times of more than 30 years. According to the results induction of plasmacytomas by internal irradiation is possible. Malignant mesotheliomas of the pleura and the peritoneum occured only in the thorotrast group and not in the control group. The diagnoses of these patients are histologically confirmed. Of special interest are the peritoneal mesotheliomas arising from the peritoneum surrounding liver and spleen. The tumours could be explained by the fact that the adjacent layer of peritoneal c ells can be reached by the alpha particles emitted from the thorium aggregates of liver and spleen. These tumours appeared after a long latency period of more than 30 years. A problem which needs a special comment are the paravascular deposits. In the group of the examined patients 256 paravascular deposits of very different extension were detected. 146 patients suffered from late effects after more than 15 years of latency. Tumours close to the deposits are extremely rare and only 1 sarcoma of the soft tissue was observed. In 2 other cases a causal connection to the thorium deposits is possible but uncertain.

Diseases without apparent excess rate:
The 2 subgroups of organs which have to be considered are organs which are exposed to a small dose rate and organs which are exposed to an extremely low dose rate at least the dose arising from the daughters in the blood stream. Morbus Hodgkin is found equally distributed in the thorotrast and in the control group.
An important result of the study is the similar number of lung cancer in both groups, though the bronchi are exposed to chronic alpha irradiation by the exhaled thoron. Hornik et al (1989) reevaluated the calculations of the dose to the bronchi. The results give an explanation of the fact that up to now there is no excess of bronchogenic carcinomas in the thorotrast group. The kidneys are exposed to a mean dose of 40 mGy/year. No increase in renal cancer could be observed. Cancer of the urinary bladder and the adrenals (which are part of the reticuloendothelial system) have the same frequency in both groups.

Life spans of thorotrast patients:
During the past years there is a constant trend that thorotrast patients die earlier compared to patients of the control group. This phenomenon is dependent on the amount of thorotrast injected. However, as the frequency of malignant liver timours increases with the incorporated volume of thorotrast, this result could be caused by the high numbers of liver cancer. 
It can be stated that there is a thorotrast volume dependent influence to the age at death with regard to neoplastic and nonneoplastic diseases, but we are not yet able to give a fundamental explanation.

The German Thorotrast Study has been setup in order to uncover the late effects of incorporated colloidial thoriumdioxide by epidemiological observations and clinical and biophysical examination of the patients. The results of those of a corresponding control group have been compared to assess the relationship between late effects and radiation dose. Furthermore appropriate diagnostic facilities and if possible therapeutic facilities are offered and advice is given to the family physicians of the patients.

The German Thorotrast Study comprises 2326 Thorotrast patients and 1890 contemporary matched patients in the control group to be evaluated. 899 Thorotrast patients and 662 controls and clinical and biophysical follow up examinations every 2 years since 1969. The recent most important results of the study are: a high excess rate of primary liver cancer (Thorotrast/control) (411/2) was observed beginning after the 15th year of exposure. 31% of the tumours are combined with cirrhosis and 6% with other neoplastic diseases. A clear (mean) dose rate effect relationship exists. The tumour frequency depends on the time of exposure or the cumulative dose to the liver respectively and not primarily on the age at injection. The lowest cumulative dose at 10 years before diagnosis of liver cancer were about 2 Gy. Risk estimates for liver cancer after 40 years of exposure are 500 malignant tumours per 1 E4 person-Gy for man and 300 for women.

A high excess rate exists also for nonlymphocytic leukaemia starting already 5 years after Thorotrast injection (39/4). The lowest cumulative doses to the red bone marrow at time of death were about 0.5 Gy. According to the present results an excess rate can be expected for carcinomas of the extrahepatic bile ducts, pancreas, oesophagus, larynx, as well as non-Hodgkin's lymphoma, bone sarcomas, plasmacytomas and mesotheliomas.
Patients and methods of examination 

Most of our patients were injected intravascularly with Thorotrast in the period between 1937 and 1947. The names and addresses of more than 5000 patients who had cerebral arteriography (70%) or arteriography of the upper and lower limbs (30%) with Thorotrast were obtained from the records of different hospitals in West Germany. In none of our patients was Thorotrast injected for the actual detection of liver disease. 

A pseudorandomized non-Thorotrast control group was set up. It was made up of persons who had been inpatients at the same hospital and in the same year as the Thorotrast patients. To set up the roster,  only patients with a surname starting with the letter B were used. The conditions for which either the Thorotrast patients or the controls were admitted to hospital was not considered in the selection. The control group and the group of Thorotrast patients were only matched for age and sex of the patients. In 1968 when the study was started a large number of the Thorotrast patients had already died. The causes of the death of those patients were clarified by hospital records, postmortem examinations, etc.. Patients who died in the first three years after Thorotrast injection were excluded from the evaluation to minimize the influence of the underlying diseases. Excluding the patients who died within the first three years, patients who are not traceable and those not responding, the German Thorotrast study co prises 2326 Thorotrast patients and 1890 control patients of which 2151 Thorotrast patients and 1493 controls have died up to 1990). 

Organs with extremely low doses from the locally incorporated Thorotrast are reached, however, by the daughter product radon which is distributed by the blood stream. It is of high interest to calculate the cumulative dose for those organs which show no cancer excess rate. 

During the past years there has been a constant trend for Thorotrast patients to die earlier compared to controls. This phenomenon depends on the amount of Thorotrast injected. Excluding from the analysis those patients who died from Thorotrast specific diseases (liver cancer, cirrhosis or leukaemias) we see similar results in dose-rate dependent life shortening. So it is most probable that there is a Thorotrast dependent influence on age at death.";;;;CSC;Deutsches Krebsforschungszentrum;DE;;;
8666;1541;MULTILINGUAL;;FP1-ESPRIT 1;;FP1;Multilingual Speech Input-Output: Assessment, Methodology and Standardisation;01/01/1987;01/01/1988;;"The objective of the project was to provide a pan-European basis for the assessment of speech technology devices. 
The objective of the project was to provide a pan-European basis for the assessment of speech technology devices.

It involves recogniser and synthesiser assessment in each of the participating countries, and is founded on the use and systematic archiving of available databases of words and sounds for general use within the Community. The collation of material coming from the United Kingdom, France, Netherlands, Denmark, Italy and North America was undertaken as a first step. Within this definition phase, tentative uniform protocols were established at the technical level for media and recording conditions. Work was directed towards the establishment of a set of strictly practical tools for everyday use in laboratories and industrial settings in the Community, and also aimed to establish the basis for future techniques, for both speech recognition and speech synthesis. EUROM, a first multilingual database of sounds for language independent assessment of codes, was developed on compact disc read only memory (CD-ROM), and the standard workstation and complete hardware architecture for the speech input output assessment defined.
The completed definition phase was allied to project 64, SPIN. The full project now runs under the Information Processing System and Software (IPSS) area of ESPRIT as SAM (project 2589). It involves recogniser and synthesiser assessment in each of the participating countries, and is founded on the use and systematic archiving of available databases of words and sounds for general use within the Community. The collation of material coming from the UK, France, Holland, Denmark, Italy and North America was undertaken as a first step. 
Within this definition phase, tentative uniform protocols were established at the technical level for media and recording conditions. Work was directed towards the establishment of a set of strictly practical tools for everyday use in laboratories and industrial settings in the Community, and also aimed to establish the basis for future development in the field of language-independent assessment techniques, for both speech recognition and speech synthesis. 
Exploitation 
EUROM, a first multilingual database of sounds for language-independent assessment of codes, was developed on CD-ROM, and the standard workstation and complete hardware architecture for the speech input-output assessment defined.";;;;;Birkbeck College, University of London;UK;"CNET France Télécom;UNIV VAN AMSTERDAM;JYDSK TELEFON (JTAS);Centro Studi e Laboratori Telecomunicazioni SpA";"FR;NL;DK;IT";
8412;866;COUSTO;;FP1-ESPRIT 1;;FP1;Integrated Optical Technologies for Real-Time Wideband Optical Signal Processing;21/01/1986;21/01/1990;;"The objective of COUSTO was to develop an integrated acousto-optical device including processing in the 0.1-1GHz range. This was to include various optical elements as well as the radiation source and suitable detectors for a 1-D signal. Applications for such a device range from super-fast LAN connections to 1-D correlation in radar processing systems (for dynamic clutter rejection). 
The key to acoustooptics is the interaction between sound and light in a crystal (the Bragg cell). The interaction modifies not only the amplitude, frequency and phase of the light beam but also its direction. In this way, the information carried by both the sound and light is processed and revealed. By the use of integrated optics, the information brought by the device under development measures the degree of similarity between an input signal and a reference signal by computing their correlation. The Bragg cell used in the integrated device was a surface acoustic wave (SAW) cell. Various alternatives for the different components were studied and compared with respect to the required performances: The lithium niobate (LiNbO3) substrate on which the waveguides were fabricated was found to be the best option for the acoustooptic interaction zone. The most significant alternative material, silicon, was rejected because of its poor acoustic properties in spite of the possibility of integrating the optical detectors directly on the silicon substrate. The protonic exchange technique was selected to build the wavegudies on the Y-cut of the lithium niobate. The 2 signals, received and reference, are launched in opposite directions, and their correlation, taking place in the interaction zone, results in the deviation of the incoming laser produced light. The niobate (Nb205) Fresnel option was selected to build the collimating lens (between) the laser source and the acoustooptic interaction region) and the detector lenses (between the acoustooptic interaction region and the detector). The project pioneered a lithium niobate waveguide with the proton exchange process. A well engineered working device with integrated optics was delivered, demonstrated and evaluated, operating at a central frequency of 850 MHz with a bandwidth of 300 MHz.
The key to acousto-optics is the interaction between sound and light in a crystal (the Bragg cell). The interaction modifies not only the amplitude, frequency and phase of the light beam but also its direction. In this way, the information carried by boththe sound and light is processed and revealed. 
 By the use of integrated optics, the information brought by the device under development measures the degree of similarity between an input signal and a reference signal through computing their correlation. The Bragg cell used in the integrated device in this project was a surface acoustic wave (SAW) cell. 
Various alternatives for the different components were studied and compared with respect to the required performances: 
 -The lithium niobate (LiNbO3) substrate on which the waveguides were fabricated was found to be the best option for the acousto-optic interaction zone. The most significant alternative material, silicon, was put aside because of its poor acoustic propert ies in spite of the possibility of integrating the optical detectors directly on the silicon substrate. The protonic exchange technique was selected to build the waveguides on the Y-cut of LiNbO3. The two signals, received and reference, are launched in opposite directions, and their correlation, taking place in the interaction zone, results in the deviation of the incoming laser-produced light. 
-The Nb2O5 Fresnel option was selected to build the collimating lens (between the laser source and the acousto-optic interaction region) and the detector lenses (between the acousto-optic interaction region and the detector). 
The project pioneered a LiNbO3 waveguide with the proton exchange process. A well-engineered working device in integrated optics was delivered, demonstrated and evaluated, operating at a central frequency of 850 MHz with a bandwidth of 300 MHz. 
Exploitation 
 The partner companies will endeavour to capitalise on the results achieved so far by developing system components in integrated optics: an interferometric spectrum analyser and a wide bandwidth correlator are some of the envisaged short-term exploitation of the results. Longer-term exploitation requires improvement of performance of the device.";;;;;Selenia SpA - Industrie Electroniche Associate;IT;"GEC Marconi Research Centre;Birkbeck College, University of London";UK;
8665;1633;PODA;;FP1-ESPRIT 1;;FP1;Piloting of the Office Document Architecture;19/12/1985;19/03/1989;;"The goal of this project was to evaluate and to advance the ISO and CCITT standards on Office Document Architecture (ODA), and to accelerate the exploitation of ODA. 
FORMA is an end user oriented, native document architecture (ODA) document editor for personal computers (PC) and UNIX workstations. The FORMA document handler is an ODA structured document processing tool which is supported by character and raster graphics editors, file management, hypertext help, databases and bulletin boards. FORMA interfaces ODA documents to telex, fax and teletext. It also interfaces to desktop publishing and publishing hardware through its use of high quality device independent (DVI) imaging output. This makes FORMA suitable for both office use and typesetting in the publishing industry. The software architecture is flexible such that it is easy to integrate new components to the system, or to specialiste FORMA for particular solutions.

The project produced the following main results. Firstly, demonstration of the office document architecture (ODA) standard by the interchange of documents between commercially available office equipment (word processors, workstations, printers) from 5 different manufacturers. This included the definition of document application profiles with increasing capabilities, and the provision of converters to and from proprietary document formats. The software development has been based on commonly used software (the PODA toolkit) including an ODA formatter, an ODA storage manager and an adaptable format checker which validated the syntax of an ODIF data stream format. Secondly, development and demonstration of a final form imager which converts a formatted form ODIF document into an existing laser printer's format in order to print interchange documents; development and demonstration of a font support system; design and specification of components for an ODA-conformant formatting document editor. Thirdly, development of methods and components to handle confidential documents in office systems; investigation of concepts for data in documents; prototype work on audio systems in the context of ODA; investigation of concepts for data in documents; prototype work on audio systems in the context of ODA; investigative and prototype work on user interfaces.
PODA-1 produced the following main results: 
-ODA Document Interchange 
 Demonstration of the ODA standard by the interchange of documents between commercially available office equipment (word processors, workstations, printers) from five different manufacturers at the 1987 and 1988 Hannover Fairs. This included the definitio  n of Document Application Profiles with increasing capabilities, and the provision of converters to and from proprietary document formats. The software development has been based on commonly used software (the PODA toolkit) including an ODA formatter, an ODA storage manager and an adaptable format checker which validated the syntax of an ODIF data stream format. 
-ODA Evaluation 
Development and demonstration of a final form imager which converts a formatted-form ODIF document into an existing laser printer's format in order to print interchange documents. 
Development and demonstration of a font support system 
Design and specification of components for an ODA-conformant formatting document editor, additional and complementary to components which were prototyped in project 121, HERODE. This also included prototyping a document-class definition editor. 
-ODA Advancement 
Development of methods and components in order to handle confidential documents in office systems. 
Investigation of concepts for data in documents. 
Prototype work on audio systems in the context of ODA. 
Investigative and prototype work on user interfaces. 
Exploitation 
The experience gained from this project has been submitted to standardisation organisations, and has had an impact both on specifications ISO IS 8613 and on the Document Application Profiles. 
The results of the project, particularly from the ODA document interchange work, will be exploited through products that will become commercially available in the 1990s.";;;;;Siemens Nixdorf Informationssysteme AG;DE;"SERVICE D'ETUDES COMMUNES DE LA POSTE ET DE FRANCE TELECOM;Alcatel TITN;BULL SA;Ingegneria C. Olivetti and C. SpA;Syntax Sistemi Software SpA;OCE-NEDERLAND BV;SIEMENS-NIXDORF INFORMATIONSSYSTEME AG;International Computers Ltd (ICL);Birkbeck College, University of London";"FR;IT;NL;DE;UK";
8484;1558;EQUUS;;FP1-ESPRIT 1;;FP1;Efficient Qualitative and Quantitative Use of Knowledge-Based Systems in Financial Management;16/03/1987;16/06/1990;;"The area of application of the planned knowledge-based systems was financial portfolio management. This is not a new area for knowledge-based computing: it was identified early in the USA as a profitable area for expert system development. However successhas been limited. Clients' needs have not been correctly appreciated, and there have been shortcomings in the standard rule-based model for knowledge representation when applied to financial problems. 
EQUUS aimed to remedy this situation. Its objectives were to: 
-develop an expert system for portfolio management 
-provide the tools for acquiring knowledge and applying knowledge in the same area. 
In consequence, a major goal was to supplement standard tools and methodologies with facilities for mixed quantitative and qualitative reasoning and to organise the collected knowledge accordingly. 
The area of application of the planned knowledge based systems was financial portfolio management. The objectives were to develop an expert system for portfolio management, and provide the tools for acquiring knowledge and applying knowledge in the same area. The functional requirements for such financial system development were stated, and a generalized methodology for knowledge acquisition in the financial domain established. A survey of the French, American and British tools and applications was released. The requirement to reason qualitatively from time dependent quantitative data was approached through a study of the fundamental issues involved in applying fuzzy logic. This has been sufficiently advanced to incorporate the results in the demonstrators. A generalized methodology for knowledge acquisition in the financial domain was established. Ten prototypes allowing portfolio design exist, and are part of a general conceptual frame. The 2 main protypes are firstly, IPDS, written in OPS5: this is a portfolio design system allowing maintenance and including MPT (US Modern Portfolio Theory based on utility theory), characterizing the investment risks and return to be taken. Secondly, FOAL2, written in QSL/Lisp: this is a prototype based on fuzzy sets and necessity/possibility theory. The system is written in Vax Lisp and QSL language and runs under VAX VMS. The role of FOAL2 is to build a portfolio by sorting and selecting stocks on the basis of a client interview and by using fuzzy logic.
The functional requirements for such financial system development were stated, and a generalised methodology for knowledge acquisition in the financial domain established. A survey of the French, American and British tools and applications was released.The requirement to reason qualitatively from time-dependent quantitative data was approached through a study of the fundamental issues involved in applying fuzzy logic. This has been sufficiently advanced to incorporate the results in the demonstrators.A generalised methodology for knowledge acquisition in the financial domain was established. 
Ten prototypes allowing portfolio design exist, and are part of a general conceptual frame, QUIDS (Equus Integration Decision System). The two main prototypes are: 
-IPDS at Citymax, written in OPS5: this is a portfolio design system allowing maintenance and including MPT (US Modern Portfolio Theory based on utility theory), characterising the investment risks and return to be taken. 
-FOAL2 at DATAID written in QSL/LISP: this is a prototype based on fuzzy sets and necessity/possibility theory. The system is written in Vax Lisp and QSL language and runs under VAX VMS. The role of FOAL2 is to build a portfolio by sorting and selectingstocks on the basis of a client interview and by using fuzzy logic. 
The project has also produced documents on expert systems, evaluation and metrication. These are relevant to other evaluation projects (numbers 857 (GRADIENT), 1257 (MUSE), 1570 (ESCA) and 2148 (VALID)). 
Exploitation 
One of the prototypes, the chartist advisor of RIADA, has been integrated with the main database of RIADA and produces daily recommendations. Other prototypes (Citymax and DATAID) are planned to be progressively exploited in the future. 
At the same time, a user handbook of procedures for the production of such systems has been produced. This includes measures of performance and cost estimates for the introduction of expert systems; this document will be published by UCL a methodology book on building KBS duplications.";;;;;Citymax Ltd;UK;"DATAID;RIADA & CO;Birkbeck College, University of London";"FR;IE;UK";
11773;FI1W0044;PACOMA;;FP1-RADWASTOM 3C;;FP1;SAFETY EVALUATION OF GEOLOGICAL DISPOSAL CONCEPTS FOR MEDIUM LEVEL AND ALPHA WASTES IN ROCK SALT;01/02/1987;31/12/1989;;"THE OVERALL OBJECTIVES OF THE GSF CONTRIBUTION TO THE PACOMA PROJECT ARE TO DEVELOP AND DEMONSTRATE PROCEDURES FOR THE RADIOLOGICAL SAFETY ASSESSMENT OF A DEEP REPOSITORY FOR ALPHA-BEARING AND MEDIUM-LEVEL RADIOACTIVE WASTE IN SALT ROCKS. 

THE RESEARCH COVERS THE DISPOSAL IN A REPOSITORY MINED IN A SALT DOME. THE REFERENCE REPOSITORY DESIGN WILL BE TAKEN AS A BASIS FOR THE CALCULATIONS. DESIGN VARIANTS AND ALTERNATIVE DISPOSAL CONCEPTS ARE INVESTIGATED. THE RESULTS ARE GIVEN IN TERMS OF RELEASE RATES TO GEOSPHERE AND IN TERMS OF DOSES TO THE INDIVIDUALS AND POPULATIONS. 
The overall objective of the Pacoma project was the assessment of the consequences associated with deep disposal of radioactive waste in 3 types of geological formation. The project objective was to develop and demonstrate procedures for radiological safety of repositories in salt domes. The influence of the appropriate choice of the repository design parameters on the whole system has been investigated.

The research covered deterministic calculations for 3 scenarios: the normal evolution scenario with subrosion of the salt dome, the combined brine intrusion scenario with brine intrusion from brine pockets and via an anhydrite vein, and the human intrusion scenario of solution mining of a storage cavern.

For the combined brine intrusion scenario alternative waste inventories, different disposal concepts, variants of the layout of dams and sealings were investigated, and results obtained from variations of parameter values. Additionally, for this scenario, comprehensive probabilistic calculations have been carried out with the help of a Monte Carlo simulation. Results have been obtained in the form of an uncertainty analysis of the maximum dose and global sensitivity studies of system parameters.

The main result of the assessment was that, in the reference case where the reference repository design and the reference disposal concept are applied, deterministic calculations with best estimate values as well as probabilistic calculations do not manifest unacceptable risk. Investigation of alternative concepts and design variants indicate a high potential for system optimisation.
1. DISPOSAL SITE. 
2. REPOSITORY DESIGN. 
3. SCENARIOS. 
4. MODELS 
5. CALCULATIONS.";;;;CSC;GSF - FORSCHUNGSZENTRUM FUER UMWELT UND GESUNDHEIT GMBH;DE;;;
8482;1550;DRAGON;;FP1-ESPRIT 1;;FP1;Distribution and Reusability of Ada Real-Time Applications through Graceful and On-Line Operations;27/04/1987;27/04/1990;;"The objective of DRAGON was to develop methods and provide tools for designing reusable software for distributed real-time applications of a long-lived nature (such as flexible manufacturing systems and space application systems). 
 Criteria for structuring systems in terms of reusable, target-independent Ada components were investigated in two aspects: formal specifications of module interfaces and operations, and support for distribution and target computer and plant configuration management. 
Changes in target architecture and plant dimension and parameters are a major cause of unanticipated software changes, making software hard to reuse: this issue was addressed in the project by structuring the program as distributable units that were completely insensitive to target characteristics. 
Provisions for reconfiguration, task migration and modification in non-stop mode require careful analysis of the Ada tasking system: the intended approach was to start from existing formalisations of Ada semantics and then extend them. Reusability was obtained by assembling components and tailoring highly generic ones. A database library of existing components was to be designed. 
The objective was to develop methods and provide tools for designing resusable software for distributed real timme applications of a long lived nature (such as flexible manufacturing systems and space application systems). Criteria for structuring systems in terms of reusable, target independent Ada components were investigated in 2 aspects: formal specifications of module interfaces and operations, and support for distribution and target computer and plant configuration management. Changes in target architecture and plant dimension and parameters are a major cause of unanticipated software changes, making software hard to reuse: this issue was addressed in the project by structuring the program as distributable units that were completely insensitive to target characteristics. Provisions for reconfiguration, task migration and modification in nonstop mode require careful analysis of the Ada tasking system; the approach was to start from existing formalizations of Ada semantics and then extend them. Reusability was obtained by assembling components and tailoring highly generic ones. A database library of existing components was designed. The object oriented language DRAGOON was developed, along with a specification of its formal semantics. Preprocessing tools were developed to support the translation of DRAGOON into Ada. Run time support has been provided by the dragoon distributive executive (DDX), which handles interprocess communication between components, dynamic loading of components, and dynamic reconfiguration. The DEMON design method for reusable software was produced. There is a toolset which supports DRAGOON and the DEMON design method. Formal methods work investigated algebraic specification techniques in object oriented environments. The industrial enhancement of a maritime surveillance system was used as a test of the methods and tools developed.
The object-oriented language DRAGOON was developed, along with a specification of its formal semantics. It is like Ada, but its classes incorporate much richer constructs for describing data and methods (including concurrency). 
Preprocessing tools were developed to support the translation of DRAGOON into Ada. 
Run-time support has been provided by the Dragoon Distributive eXecutive (DDX), which handles inter-process communication between components, dynamic loading of components, and dynamic reconfiguration. 
The DEMON design method for reusable software was produced. It is used with a formal specification such as object-oriented Z, and copes with concurrency and distribution. There is a toolset (eg structure editor) which supports DRAGOON and the DEMON designmethod. 
Formal methods work investigated algebraic specification techniques in object-oriented environments. 
The industrial enhancement of a maritime surveillance system was used as a test of the methods and tools developed in DRAGON. An object-oriented approach was followed. 
Exploitation 
The project will contribute to the industrial use of Ada and will advance industrial understanding of the problems and opportunities of software reuse.";;;;;TXT Ingegneria Informatica SpA;IT;"DORNIER SYSTEM GMBH;GSI TECSI Software SA;University of Lancaster;UNIVERSITY COLLEGE OF WALES ABERYSTWYTH";"DE;FR;UK";
8431;898;PHOX;;FP1-ESPRIT 1;;FP1;External Interface for Processing 3-D Holographic and X-Ray Images for Analysis and Control;14/02/1986;14/02/1988;;"The aim of the PHOX project was to develop an external interface system for linking physically generated 3-D images to inspection and analysis procedures. While this had to be a general and flexible system, it was demonstrated through the application of holographic interferograms and X-ray radiographs to real-time testing and inspection and to 3-D measurement. For this task, optical and electronic methods had to be combined in order to extract the relevant information from multiple 3-D images. A further aim of the project was the automation of holographic interferometry and X-ray radioscopy for online testing in the manufacturing process. . 
The aim of the project was to develop an external interface system for linking physically generated 3-dimensional images to inspection and analysis procedures. Optical and electronic methods had to be combined in order to extract the relevant information from multiple 3-dimensional images. A further aim of the project was the automation of holographic interferometry and X-ray radioscopy for online testing in the manufacturing process. Two nondestructive testing methods were combined. First, deformations of the surface of materials were detected by a holographic method. The deformations were then interpreted in terms of stress and compression on the material, using finite element methods. The stress and compression were then further explained by the use of X-ray image processing to give information regarding the interior of the materials. Various techniques for quantitative holographic interferometry were investigated, and the phase stepping method and a method based on the Fourier transform were selected. X-ray radiography interface requirements (mainly concerned with filtering noisy signals) were identified. The quality of the images was found to depend on the X-ray source, on the geometrical structure of the inspection system, and on the detector and image processing system. Consequently, controlling hardware and software were developed to optimize these conditions for performing the testing. A manipulator and its control were produced and a source control (microfocus X-ray control) developed. Low level image processing techniques were adapted for use with both X-ray images and interferograms. A common set of objects (honeycomb structures) were selected to test the methods developed for holographic interferometry and X-ray radioscopy, both individually and in combination.
The challenge of the PHOX project was to combine two non-destructive testing methods. This was done by first detecting deformations of the surface of materials by a holographic method. The deformations were then interpreted in terms of stress and compression on the material, using finite element methods. The stress and compression were then further explained by the use of X-ray image-processing to give information regarding the interior of the materials. 
Various techniques for quantitative holographic interferometry were investigated, and the phase-stepping method and a method based on the Fourier transform (invented within the project), were selected. Holographic processing combined with finite element analysis had already been successfully demonstrated. X-ray radiography interface requirements (mainly concerned with filtering noisy signals) were identified. The quality of the images was found to depend on the X-ray source, on the geometrical structure of the inspection system, and on the detector and image processing system. Consequently, controlling hardware and software were developed to automatically optimise these conditions for performing the testing. A manipulator and its control were produced and a source control (microfocus X-ray control) developed. Low-level image-processing techniques were adapted for use with both X-ray images and interferograms. A common set of objects (honeycomb structures) were selected to test the methods developed for ho l graphic interferometry and X-ray radioscopy, both individually and in combination. 
Exploitation 
PHOX advanced the technologies for designing and testing engineering structures, which is a priority for the achieving improved product quality. The creation of a prototype combining optical and electronics technologies successfully demonstrated the feasibility of a low-cost system for online testing for surface defects. 
Knowhow about non-destructive testing methods acquired through work in holographic interferometry is to be marketed by one of the partners.";;;;;Bias - Forschungs- und Entwicklungslabor Angewandte Strahltechnik GmbH;DE;"SCANRAY A/S;IRAM;GEC Engineering Research Centre;Universität Dortmund";"DK;FR;UK;DE";
8534;887;ECIP;;FP1-ESPRIT 1;;FP1;European CAD Integration Project;01/01/1986;31/12/1988;;"European computer aided design (CAD) integration project (ECIP) investigates the area of data exchange and infrastructure standards with the objective of defining and promoting them within the European information technology (IT) industry. The ability to interchange data and CAD tools between companies is a key area for bringing into practice many of the benefits of collaborative tool development in Europe, and for making available the results of ESPRIT to the wider European IT community. The final goal of ECIP is the definition of a multilayered open model for CAD systems with recommendations for rules or standards at each level.
Effective liaison between the ECIP project and all other ESPRIT CAD projects has been established, ensuring transfer of experience in both directions. In this way the standards developed in ECIP will be based on a wide experience of requirements, and they should therefore be widely acceptable to developers of present and future CAD systems.";;;;;BULL SA;FR;"Siemens AG;International Computers Ltd (ICL);PHILIPS DUPONT OPTICAL;Thomson Microelectronics Srl (SGS);Alcatel TITN";"DE;UK;NL;IT;FR";
8399;393;ACORD;;FP1-ESPRIT 1;;FP1;Construction and Interrogation of Knowledge Bases Using Natural Language Text and Graphics;01/01/1985;01/01/1990;;"The ACORD project focused on a trilingual system (English, French and German), investigating the use of both natural language (typed text) and graphics to build and query a knowledge base. The analysis of texts was based on recent results in theoretical linguistics (discourse representation theory and functional grammars). To support dialogue, the system selected appropriate presentation of output, text or graphics, and identified relevant information for output. The system interface featured an interplayof graphics and natural language. . 
The project focused on a trilingual system (English, French and German), investigating the use of both natural language (typed text) and graphics to build and query a knowledge base. The analysis of texts was based on recent results in theoretical linguistics (discourse representation theory and functional grammars). To support dialogue, the system selected appropriate presentation of output, text or graphics, and identified relevant information for output. The system interface featured an interplay of graphics and natural language. The project produced results in specifying and implementing grammatical theories and parsers for the different languages: unification categorical grammar (UCG) for English and French, and lexical functional grammar (LFG) for German. All the parsers for text and dialogue deliver a common semantic representation based on discourse representation structure (DRS). Inverse parsing in UCG is used for generation of English and French. The dialogue manager was implemented and used to coordinate graphical and textual human computer interaction, including features such as anaphora (pointing).
The project produced results in specifying and implementing grammatical theories and parsers for the different languages: Unification Categorical Grammar (UCG) for English and French, and Lexical Functional Grammar (LFG) for German. All the parsers for text and dialogue deliver a common semantic representation based on Discourse Representation Structures (DRS). Inverse parsing in UCG is used for generation of English and French. 
The dialogue manager was implemented and used to co-ordinate graphical and textual human computer interaction, including features such as anaphora (pointing). 
Exploitation 
A prototype and demonstrator of advanced linguistic and AI techniques was built, showing the relevance of the research to existing business practice. The prototype demonstrates a system for computer-aided decision-making in the field of logistics.";;;;;Alcatel Alsthom Recherche;FR;"TRIUMPH ADLER AG;Bull SA";"DE;FR";
8648;1618;MODEL-DISPLAY;;FP1-ESPRIT 1;;FP1;Modelling and Simulation of the Visual Characteristics of Modern Display Technologies under Office Work Conditions;01/10/1984;01/10/1989;;"The project objective was to design, engineer and build a hardware device able to simulate, in real time, a broad range of flat-panel displays. These include electro-luminescent (EL), thin film EL, memory EL, active matrix liquid crystal (LC), ferroelectric LC and supertwisted LC. This device can be used by office automation and display manufacturers to test the properties of new technologies and to optimise the display parameters in order to obtain good image quality and maximum user acceptability. The simulator facility can also help display designers and users (office automation manufacturers, user organisations, etc) in the definition of new products and applications. 
Specific objectives were to: 
-compare various simulated display technologies and technical solutions according to user acceptability criteria 
-perform ergonomic experiments, under prolonged office work conditions, to find the relationships between technology-dependent display properties, visual discomfort and image quality. 
The project objective was to design, engineer and build a hardware device able to simulate, in real time, a broad range of flat panel displays. These include electroluminescent (EL) displays, thin film EL displays, memory EL displays, active matrix liquid crystal (LC) displays, ferroelectric LC displays, and supertwisted LC displays. The device can be used by office automation and display manufacturers to test the properties of new technologies and to optimize the display parameters in order to obtain good image quality and maximum user acceptability. The simulator facility can also help display designers and users (office automation manufacturers, user organisations, etc) in the definition of new products and applications.

Specific objectives were to:
compare various simulated display technologies and technical solutions according to user acceptability criteria;
perform ergonomic experiments, under prolonged office work conditions, to find the relationships between technology dependent display properties, visual discomfort and image quality.

Achievements were:
demonstration of simulator;
top level design of the simulation software required for real time simulation of display technologies;
implementation and demonstration of versions of an EL display model;
design of the high resolution digitally controlled colour monitor required to visualize the simulated displays;
design of a shading correction technique for cathode ray tube (CRT);
construction of a functional model of visual perception.
Achievements were: 
-demonstration of simulator 
-top-level design of the simulation software required for real-time simulation of display technologies 
-implementation and demonstration of versions of an electro-luminescent display model 
-design of the high-resolution digitally controlled colour monitor required to visualise the simulated displays 
-design of a shading correction technique for CRT 
-construction of a functional model of visual perception. 
Exploitation 
The simulation facilities, which can help display and office automation manufacturers shorten the design cycle of displays acceptable to users, are accessible at the Universiteit van Twente. Those interested should contact the university directly as follows: 
Prof BosmanUniversiteit van TwentePostbus 217&   \31/53-892-780NL - 7500 AEfax  \31/53-354-003ENSCHEDEtelex  44200 
A further development of the high-resolution digitally controlled colour monitor developed by Barco was used in project 2649, VASARI, and is now available on the market.";;;;;OCE-NEDERLAND BV;NL;"UNIV VAN TWENTE;THOMSON CSF;Université de Paris;BARCO-INDUSTRIES NV;MYFRA SA;GEC-Marconi Materials Technology Ltd";"NL;FR;BE;UK";
8651;925;CODING-256;;FP1-ESPRIT 1;;FP1;Coding for Moving Pictures and Still Pictures at 256 Kbit/s and 64 Kbit/s;02/01/1986;02/10/1987;;"This project addressed advanced compression techniques for moving video and still picture coding for teleconferencing applications. After reviewing state-of-the-art techniques and requirements, the project objectives were to: 
-Achieve very high compression rates for videoconference-grade image motion with good resolution and quality. Advanced intraframe and interframe compression techniques were investigated, including orthogonal transform coding algorithms. 
-Achieve high picture quality and resolution for still-picture coding in order to reproduce business graphs, technical drawings, and photographs. 
-Define a proposal for a standard for moving image codecs. 
The project addressed advanced compression techniques for moving video and still picture coding for teleconferencing applications. After reviewing state of the art techniques and requirements, the project objectives were to:
achieve very high compression rates for videoconference grade image motion with good resolution and quality (advanced intraframe and interframe compression techniques were investigated, including orthogonal transform coding algorithms);
achieve high picture quality and resolution for still picture coding in order to reproduce business graphs, technical drawings, and photographs;
define a proposal for a standard for moving image codecs.

Advanced algorithms were selected, defined and tested by computer simulation. Impressive simulation results were demonstrated of the real time transmission of moving images over a 64 Kbit/s link. This technique, fully implemented, would allow the use of integrated services digital network (ISDN) as a carrier for setting up videoconferences.
Advanced algorithms were selected, defined and tested by computer simulation. Impressive simulation results were demonstrated of the real-time transmission of moving images over a 64 Kbit/s link. This technique, fully implemented, would allow the use of ISDN as a carrier for setting up videoconferences.";;;;;Alcatel TITN;FR;"Sepa Elettronica Automazione SpA;TELEFONICA INVESTIGACION Y DESARROLLO;Philips Kommunikations Industrie AG;GEC-Marconi Materials Technology Ltd;SOCIETE ANONYME DE TELECOMMUNICATIONS (SAT)";"IT;ES;DE;UK;FR";
8452;1519;ASSET;;FP1-ESPRIT 1;;FP1;Automated Support for Software Engineering Technology;01/11/1984;01/08/1985;;"The objective of ASSET was to demonstrate the technical feasibility of a proposal to develop advanced interactive graphics support for a range of methods covering each phase of the software life-cycle. The aim was to take the existing EPOS toolset out of its original framework and port it into a new generation of technology. 
The objective of the project was to demonstrate the technical feasibility of a proposal to develop advanced interactive graphics support for a range of methods covering each phase of the software life cycle. The aim was to take the existing electronics at point of sale (EPOS) toolset out of its original framework and insert it into a new generation of technology. The final report showed that the EPOS system could be a valuable basis for developing advanced interactive graphics support.
The final report showed that the EPOS system could be a valuable basis for developing advanced interactive graphics support.";;;;;PLESSEY RESEARCH;UK;GESELLECHAFT FÜR PROZESSRECHNERPROGRAMMIERUNG MBH;DE;
8415;1494;MADS;;FP1-ESPRIT 1;;FP1;Message-Passing Architectures and Description Systems;14/11/1984;14/11/1989;;"The MADS project aimed to build three levels of tools for the development of expert systems: 
-message-passing languages 
-description languages for knowledge representation 
-reasoning and strategy programming. 
 MADS was to develop techniques for implementing message-passing languages that exploit new highly parallel architectures. The techniques were to cover issues of run-time support such as allocation, migration, garbage-collection and persistency of actors. A description system was developed to support the basic mechanisms of knowledge representation: conceptual hierarchies, inheritance, and attributions. To perform reasoning on the description system, rather than providing a fixed strategy, primitives and constructs were developed that allowed the programming of deductive strategies tailored to specific applications. Strategy execution was to be performed concurrently by a large number of actors each exploring a small portion of the knowledge-base. 
The project developed techniques for implementing message passing languages that exploit new highly parallel architectures. The techniques covered issues of run time supportsuch as allocation, migration, garbage collection and persistency of actors. A description system was developed to support the basic mechanisms of knowledge representation: conceptual hierarchies, inheritance, and attributions. To perform reasoning on the description system, rather than providing a fixed strategy, primitives and constructs were developed that allowed the programming of deductive strategies tailored to specific applications. Strategy execution was performed concurrently by a large number of actors each exploring a small portion of the knowledge base. Prototypes of message passing architectures and two description systems, OMEGA and KRS, that will exploit highly parallel machines, were developed. OMEGA is a description oriented knowledge representation which allows reasoning and includes a viewpoints mechanism. Graphical tools provide an efficient environment to support the knowledge engineering activity. KRS is a concept system which allows reasoning and includes inheritance mechanisms and a consistency maintenance system. A graphical user interface was developed. Parallelism in knowledge representation was investigated. The use of the language LISP in parallel processing and appropriate knowledge representation led to the implementation DELPHI Common LISP, including a multithread facility for concurrency, and the integration of the language PROLOG.
Prototypes of message-passing architectures and two description systems, OMEGA and KRS, that will exploit highly parallel machines, were developed: 
-OMEGA is a description-oriented knowledge representation which allows reasoning and includes a viewpoints mechanism. Graphical tools provide an efficient environment to support the knowledge engineering activity. 
-KRS is a concept system which allows reasoning and includes inheritance mechanisms and a consistency maintenance system. A graphical user interface was developed. Parallelism in knowledge representation was investigated. 
The use of LISP in parallel processing and appropriate knowledge representation led to the implementation DELPHI Common LISP, including a multi-thread facility for concurrency, and the integration of PROLOG. 
Exploitation 
The prototypes that have been implemented constitute the first steps to future industrialisation. Both OMEGA and KRS are being used in pilot applications outside the project.";;;;;Delphi SpA;IT;"BELL TELEPHONE MFG CO NV;VRIJE UNIVERSITEIT BRUSSEL;Alcatel Alsthom Recherche";"BE;FR";
8488;1592;TAO;;FP1-ESPRIT 1;;FP1;Therapy Adviser for Oncology;01/01/1987;01/04/1990;;"The TAO project aimed to evaluate the effects consequent on the introduction of a knowledge-based system to advise on the chemotherapy of lung cancer. A therapy adviser for oncology, TAO, was to be developed, to provide chemotherapy, patient and other information in response to interactive queries by doctors. 
The early phase of the project was concerned with the refinement of knowledge bases, the construction of the patient-specific database and the design of the man-machine interface. 
The second phase of the project consisted mainly of the implementation of the knowledge and inference architecture, using a skeletal system already developed by one of the partners. 
 The final phase focused on the evaluation of the system in the context of its use in a domain where heavy reliance is already placed on data analysis techniques. This took into account the attitude of staff and patients and the impact of the tool on work practices, against measures of efficiency, safety, and costs. The description of the evaluation scheme was an early deliverable. 
The modern management of the treatment of cancer requires the physician to follow complex therapy protocols and to respond with precision and expertise to changes in the patient's condition. Computers are routinely used for oncology protocol data analysis and management. However, most do not directly facilitate the physician's treatment decision process.

The project aimed to evaluate the effects consequent on the introduction of a knowledge based system to advise on thechemotherapy of lung cancer. A therapy adviser for oncology, TAO, was developed, to provide chemotherapy, patient and other information in response to interactive queries by doctors. The early phase of the project was concerned with the refinement of knowledge bases, the construction of the patient specific database and the design of the man machine interface. The second phase of the project consisted mainly of the implementation of the knowledge and inference architecture, using a skeletal system. The final phase focused on the evaluation of the system in the context of its use in a domain where heavy reliance is already placed on data analysis techniques. This took into account the attitude of staff and patients and the impact of the tool on work practices, against measures of efficiency, safety, and costs. System building tools were ported to the project for the implementation of TAO on the MIKIC system. Two preliminary implementations of modules of the knowledge based system using different tools were demonstrated. Human computer interaction and graphic interfaces were specified and implemented. Three hospitals were chosen for the validation of the system, located in England, France and Spain, and a statement of the evaluation criteria and an analysis of the operational environment produced.
The system-building tools developed in project 387 (KRITIC) were ported by Framentec to the project for the implementation of TAO on the MIKIC system. Two preliminary implementations of modules of the knowledge-based system using different tools were demonstrated. HCI and graphic interfaces were specified and implemented. 
Three hospitals were chosen for the validation of the system, located in England, France and Spain, and a statement of the evaluation criteria and an analysis of the operational environment produced. 
Scientific links were established with the ONCOCIN project at Stanford University. 
Exploitation 
By its provision of evaluation methodologies and by reporting experience of their use, the outcome of this project has enlarged knowledge of the design and introduction of successful techno-medical knowledge-based systems. Such an evaluation both of expert systems in themselves and of their performance in an operational environment is a prerequisite to their use in industry. 
The project provided a demanding testbed for the system building tools from KRITIC. 
A study in a Madrid hospital is evaluating TAO in a clinical environment.";;;;;Meterquest Ltd;UK;"Medimatica Ltd;UNIVERSITY OF LEEDS;Framentec SA;CITSA";"UK;FR;ES";
8655;1627;IKAROS;;FP1-ESPRIT 1;;FP1;Intelligence and Knowledge-Aided Recognition of Speech;01/01/1986;01/03/1989;;"The aim of the IKAROS project was to evaluate artificial intelligence techniques for speech understanding. This project was complementary to project 64, SPIN. 
The final demonstrator of the project was to be a speech understanding system running a real application, with the following performance specification: 
-recognition of up to one thousand words of continuous speech 
-multi-speaker recognition 
-multi-lingual processing (handling French, English and German) 
-natural-type spoken language processing (distinguishing the IKAROS system from most other speech understanding systems, which process artificial languages) 
-dialogue management. 
The aim of the project was to evaluate artificial intelligence techniques for speech understanding. The following attributes were required: recognition of up to 1000 words of continuous speech; multispeaker recognition; multilingual processing (handling French, English and German); natural spoken language processing (distinguishing the system from most other speech understanding systems, which process artificial languages); and dialogue management. The project ended with the presentation of an experimental demonstrator, which will act as a vehicle for experimentation, aiding investigation in the use of artificial intelligence techniques and high level knowledge, and demonstrate the style and feasibility of the proposed approach.
The project ended with the presentation of an experimental demonstrator, whose purposes were to: 
-act as a vehicle for experimentation, aiding investigation in the use of artificial intelligence techniques and high-level knowledge 
-demonstrate the style and feasibility of the proposed approach.";;;;;Alcatel Alsthom Recherche;FR;"Fraunhofer-Gesellschaft zur Förderung der Angewandten Forschung eV (FhG);GEC-Marconi Materials Technology Ltd;Universität Stuttgart";"DE;UK";
8659;1629;A-SI IMAGER;;FP1-ESPRIT 1;;FP1;Amorphous Silicon Contact Imager for Office and Graphic Applications;01/01/1986;01/04/1988;;"The three main objectives for the project, containing both short and medium-term goals, were to: 
-prototype a very compact contact imager with amorphous silicon sensor elements, creating a linear scanning array with better opto-electronic properties than those currently available 
-investigate alternative deposition techniques for amorphous silicon (homo-cvd, photo-cvd), aiming at an increase in the stability of the deposited films 
-study the integration of thin-film switches and shift registers on the same substrate, in order to avoid cumbersome and expensive hybrid interconnections. 
2 scanners (10 cm long, 4 pixels per mm and 21 to 25 cm long, 8 pixels per mm) were developed, using glow discharge deposition for the amorphous silicon sensor elements. Electrical measurements on single sensor elements proved the concept. According to the readout results 2 different phenomena were apparent, each addressing different application fields: a fast (2 milliseconds per line) linear readout, and a slow but cheap matrix readout without crossovers. The sensor arrays were assembled in an A4 package, and a readout technique based on crystalline driver chips in a linear integrated mode was proposed and developed. A microfilm scanner was set up as an in systemevaluation tool. The measurements on single photosensors were compared with measurements on commercially available contact imagers. The alternative deposition techniques (homo-chemical vapour deposition (CVD) and photodissociation with ultraviolet light and argon flouride laser) were thoroughly investigated and optimized. For homo-CVD it was found that very good boron doped window layers could be produced for the sensor elements, and that the Staebler-Wronski effect played a much less severe role than on glow discharge deposited films. The most cost effective way of fabricating the complete contact imager appeared to be to integrate everything, including switches and shift registers, on the same substrate. A theoretical study proved that in this case polysilicon thin film transistors (TFT) were necessary because of speed (carrier mobility) considerations. Discrete polysilicon TFTs were fabricated using a technological process never exceeding 630 C and not using ion implantation. This resulted in a channel mobility of 16.5 square centimetres per volt second and a current on/off ratio of more than 105. Finally, the possibilities of continuous wave and pulsed laser recrystallization of amorphous silicon to produce large grain, high quality polysilicon at low temperatures were investigated.
Two scanners (10 cm long, 4 pixels per mm and 21-25 cm long, 8 pixels per mm) were developed, using glow-discharge deposition for the amorphous silicon sensor elements. Electrical measurements on single sensor elements proved the concept. According to the read-out results two different phenomena were apparent, each addressing different application fields: a fast (2 ms/line) linear read-out, and a slow but cheap matrix read-out without crossovers. The sensor arrays were assembled in an A4 package, and a re ad-out technique based on crystalline driver chips in a linear integrated mode was proposed and developed. A microfilm scanner was set up as an in-system evaluation tool. The measurements on single photosensors were compared with measurements on commercially available contact imagers. 
The alternative deposition techniques (homo-cvd and photodissociation with UV light and ArF laser) were thoroughly investigated and optimised. For homo-cvd it was found that very good boron-doped window layers could be produced for the sensor elements, and that the Staebler-Wronski effect played a much less severe role than on glow discharge deposited films. 
The most cost-effective way of fabricating the complete contact imager appeared to be to integrate everything, including switches and shift registers, on the same substrate. A theoretical study proved that in this case polysilicon thin-film transistors were necessary because of speed (carrier mobility) considerations. Discrete polysilicon TFTs were fabricated using a technological process never exceeding 630C and not using ion implantation. This resulted in a channel mobility of 16.5 cm2/Vs and a current on/off ratio of more than 105. Finally, the possibilities of CW and pulsed laser recrystallisation of amorphous silicon to produce large-grain, high quality polysilicon at low temperatures were investigated.";;;;;IMEC VZW;BE;"Centre National de la Recherche Scientifique (CNRS);MBB-MESSERSCHMITT BOLKOW BLOHM GMBH;AGFA GEVAERT AG";"FR;DE;BE";
8644;1608;LION;;FP1-ESPRIT 1;;FP1;Local Integrated Optical Network;16/09/1984;16/07/1989;;"This project aimed at the definition, design, prototype development and demonstration of a high-speed local communication network based on optical technology, with an OSI-consistent protocol architecture suitable for user interfacing at different layers. LION is a multiservice business network intended for global communications in different environments such as offices, industrial and research laboratories universities, hospitals and manufacturing plants. Sources that can access LION include any mix of terminals for speech, data, control signals, graphics and compressed video images. Each service is guaranteed the required performance. 
LION is also a distributed access protocol which implements a hybrid switching technique to provide both circuit and packet communications. The network nodes regularly monitor channel activity, and each in turn gains access following an ordered collision-avoidance procedure. The frame structure is flexible and can efficiently host services with different bit-rates. 
The LION 140 Mbit/s transmission subsystem exploits optical technologies. A self-healing topology is provided using a two-fibre cabling with active taps, as dictated by today's commercially available components. When a link or node goes out of service, anautomatic procedure isolates the failed element, restores network continuity and resumes operation among the remaining nodes. 
The project aimed at the definition, design, prototype development and demonstration of a high speed local communication network based on optical technology, with an open systems interconnection (OSI) consistent protocol architecture suitable for user interfacing at different layers. Specific achievements of the project were:
a 3-node prototype network with applications, showing local integrated optical network's (LION) ability to integrate voice, data and video communications (each node of the prototype takes advantage of a modular structure with specific hardware and firmware, interfaces, multiprocessor boards and software packages) specific access modules to connect user terminals, such as telephones, data terminals, host computers and videoconference equipment (these modules are assembled within a LION node cabinet);
interworking devices gateways to interconnect LION with the integrated services digital network (ISDN) the Telecom-1 satellite network, and Ethernet like local area networks (LAN);
network management and control systems, based on hierarchical functionalities provided at node level with a management module, and at global level with a network control centre. (A measurement centre was also implemented to test and monitor the network performance during operation);
circuit integration of the transmission subsystem (based on application specific integrated circutis (ASIC) and a 565 Mbit/s prototype breadboard, including access control functionalities).
Specific achievements of the project were: 
-A three-node prototype network with applications (spring 1989), showing LION's ability to integrate voice, data and video communications. Each node of the prototype takes advantage of a modular structure with specific hardware and firmware, interfaces,multi-processor boards and software packages. This prototype was produced in stages, with the demonstration of node breadboards in 1986, one assembled node with selected applications in 1987, and two cooperating nodes in 1988, before the 1989 final prototype. 
-Specific access modules to connect user terminals, such as telephones, data terminals, host computers and videoconference equipment. These modules are assembled within a LION node cabinet. 
-Interworking devices (gateways) to interconnect LION with the integrated services digital network (ISDN) the Telecom-1 satellite network, and Ethernet-like LANs. 
 -Network management and control system, based on hierarchical functionalities provided at node level (Management Module) and global level (Network Control Centre). A Measurement Centre was also implemented to test and monitor the network performance duri ng operation. 
-Circuit integration of the transmission subsystem (based on application-specific integrated circuits (ASICs) and a 565 Mbit/s prototype breadboard, including access control functionalities). 
Exploitation 
LION can be considered as the initial step of an overall strategy to develop multi-service networks in the sectors of extended LANs and metropolitan area networks (MANs) for public usage.";;;;;Centro Studi e Laboratori Telecomunicazioni SpA;IT;"UNIV OF PATRAS;Politecnico di Milano;NKT ELEKTRONIK;Université de Paris;ALCATEL TITN;UNIVERSITE PAUL SABATIER DE TOULOUSE III;British Telecom plc (BT)";"EL;IT;DK;FR;UK";
28486;RI1B0081;MODESTI;;FP1-BRITE;;FP1;MOULD DESIGN AND MANUFACTURING OPTIMISATION BY DEVELOPMENT STANDARDISATION AND INTEGRATION OF CAD/CAM PROCEDURES;01/07/1986;31/12/1990;;TO STRENGTHEN S.M.E. MOULDMAKING INDUSTRY BY DEVELOPING NEW INTEGRATED CAD-CAM FUNCTIONS AND NEW LINKS TO PRODUCTION EQUIPMENT (EDM, CMM AND 5-AXIS MILLING) IN ORDER TO FASTEN AND OPTIMIZE THE DESIGN, SET-UP, PRODUCTION AND CONTROL OF DIES AND ALLOW SMALL BATCH SIZES.;;;;CSC;Centre de Recherches Scientifiques et Techniques de l'Industrie des Fabrications Métalliques - CRIF/WTCM;BE;"Europart Electronik- und Kunststoffwerke GmbH;Tecno Design Engineering Ltd;CIG-Intersys Systems;Cadco NV;ALCATEL BELL NV;Klöckner Desma Schuhmaschinen GmbH;Picanol NV;Universität Bremen";"DE;IE;BE";
12472;EN3W0047;AWEC-60;;FP1-ENNONUC 3C;;FP1;DEVELOPMENT OF AN ADVANCED WIND TURBINE OF THE 1 MW RANGE;01/10/1986;28/02/1994;;"THE AWEC-60 PROJECT IS BEING DEVELOPED BY A CONSORTIUM OF THE FIRMS (ASINEL, IER, UEF, AND MAN) WITH THE OBJECTIVE OF CONSTRUCTING AND EXPERIMENTING A 1,2 MW WIND GENERATOR.  AWEC-60 INCORPORATES A NUMBER OF INNOVATIVE FEATURES THAT INTEND TO REDUCE THE INSTALLATION COSTS OF THE MACHINE AND INCREASE ITS OPERATION FLEXIBILITY.  ALL THIS WILL REDUCE THE OPERATING COSTS, MAKING THE 1 MW CLASS AEROGENERATORS MORE COMPETITIVE. 
A new process for manufacturing blades for large scale wind turbines in composite materials has been developed. In particular, a set of 3 blades, in glassfibre reinforced polyester (GFRP), 30 m long, has been manufactured for a 1.2 MW prototype wind turbine.
A prototype was made available on 14/11/89
DURING THE YEAR 1988 ALL THE ENGINEERING ACTIVITIES HAVE BEEN FINISHED AND THE MANUFACTURING OF THE DIFFERENT PARTS HAS BEEN PERFORMED.  NEXT ACTIVITY WILL BE ASSEMBLY.   

THE ASSEMBLY WILL BE MADE IN TWO STAGES.  FIRST IN MADRID AT BOETICHER Y NAVARRO, S.A. WORKSHOP.  THE MAIN COMPONENTS OF THE DRIVE TRAIN SUCH AS SHAFT, SHAFT-BEARINGS AND GEAR-BOX, TOGETHER WITH THE CENTRAL HYDRAULIC OIL SUPPLY SYSTEM WILL BE MOUNTED ON THE BASE FRAME OF THE NACELLE AND THEN TRANSPORTED TO LA CORUNA.   

SECONDLY, ALREADY IN LA CORUNA, THE REST OF THE ELEMENTS OF DRIVE TRAIN AND PITCH CONTROL, THE CONTROL SYSTEM, DATA ACQUISITION, COVER STRUCTURE AND HOUSING WILL BE ASSEMBLED IN ANOTHER WORKSHOP.   

AFTER THAT, THE WHOLE ASSEMBLY WILL BE TRANSPORTED TO THE SITE AND ERECTED THERE.";;;;CSC;Asociación de Investigación Industrial Electra;ES;"JEN INSTITUTO ENERGY REMOVABLES;UNION ELECTRICA FENOSA;MAN";"ES;DE";
14017;FI1W0054;COSA II;;FP1-RADWASTOM 3C;;FP1;FURTHER BENCHMARK EXERCISES TO COMPARE GEOMECHANICAL COMPUTER CODES FOR SALT;01/11/1986;31/01/1989;;"RESEARCH INTO GEOMECHANICAL ASPECTS OF RAW REPOSITORIES IN SALT FORMATIONS HAS BEEN ACTIVE IN THE EUROPEAN COMMUNITY FOR NEARLY TWO DECADES, WITH PARTICULAR INTEREST BEING PLACED ON PROBLEMS OF HEAT PRODUCING WASTE. CENTRAL TO THIS WORK IS THE PREDICTION OF STRESSES AND DEFORMATIONS IN THE HOST STRATA, FOR WHICH A NUMBER OF COMPUTER CODES HAVE BEEN USED /1/. A PRELIMINARY EXERCICE ('COSA 1') TO COMPARE THE ABILITY OF THE DIFFERENT CODES /2/ PROVIDED A LIMITED 'SNAPSHOT' OF THE EUROPEAN CAPABILITY TO PREDICT THE BEHAVIOUR OF ROCK SALT UNDER WELL DEFINED CONDITIONS. THE PURPOSE OF THE PRESENT CONTRACT IS TO EXTEND THE COMPARISON TO MORE COMPLEX BUT REALISTIC SITUATIONS. 
COMPARISON PROBLEMS IN COSA 1 WERE RELATIVELY SIMPLE, AND A NUMBER OF DIFFICULTIES TO DO WITH MODELLING THE IN-SITU BEHAVIOUR OF ROCK SALT WERE DELIBERATELY AVOIDED. THE PRESENT EXERCISE IS DIRECTED AT COMPARISONS OF REALISTIC, ALBEIT RELATIVELY SHORT-TERM, IN-SITU BEHAVIOUR. EMPHASIS IS PLACED ON THE REQUIREMENT TO PREDICT (RATHER THAN REPLICATE) REAL-LIFE BEHAVIOUR AND INDIVIDUAL PARTICIPANTS ARE ALLOWED CONSIDERABLE FREEDOM TO CHARACTERISE THE PHYSICAL SITUATION AND MATERIAL BEHAVIOUR ACCORDING TO THE DICTATES OF THEIR EXPERIENCE. 
THERE ARE 10 PARTICIPANTS IN THE EXERCISE, EACH ACTING AS A SUB-CONTRACTOR TO THE COORDINATOR. IN ADDITION TWO INDEPENDENT EXPERTS PROVIDE ADVICE AS NECESSARY ON ASPECTS OF SALT RHEOLOGY (TABLE 1). 

B1. TO AGREE, AT PLENARY MEETINGS, SUITABLE IN-SITU BENCHMARK PROBLEM(S) TO BE SOLVED BY PARTICIPANTS. 
B2. CO-ORDINATOR TO PREPARE DISCUSSION DOCUMENTS AND CIRCULATE TO PARTICIPANTS AS NECESSARY. 
B3.CO-ORDINATOR TO PREPARE AND CIRCULATE DETAILED SPECIFICATIONS OF AGREED PROBLEM(S). 
B4. PARTICIPANTS TO SOLVE AGREED BENCHMARK PROBLEM(S) TO THE BEST OF THEIR ABILITY USING APPROPRIATE CODES, ACCORDING TO THE SPECIFICATIONS PRODUCED BY THE CO-ORDINATOR. 
B5. CO-ORDINATOR TO COLLECT AND COMPILE RESULTS AND OTHER DATA FROM PARTICIPANTS. 
B6. CO-ORDINATOR TO PREPARE DRAFT REPORTS FOR DISCUSSION AT PLENARY MEETINGS TO BE HELD APPROXIMATIVELY EVERY SIX MONTHS. 
B7. CO-ORDINATOR TO PREPARE AND ISSUE FINAL REPORTS TAKING ACCOUNT OF PARTICIPANTS'COMMENTS.";;;;CSC;Atkins Wootton Jeffreys Consultants Ltd;UK;;;
12566;EN3S0121;ACIPA;;FP1-ENNONUC 3C;;FP1;ACTUATION OF FOUR SLIDING GATES AND OF A TRASH-RACK RAKE BY MEANS OF A PV PLANT;01/01/1988;30/09/1990;;"THE PRIMARY AIM OF THE ANCIPA PROJECT IS THE SETTING UP OF A PLANT TO SUPPLY THE ELECTRIC POWER NECESSARY TO DRIVE FOUR SLIDING GATES AND A TRASH-RACK RAKE SITED ON THE SPILLWAY OF THE RIVER BRACALLA IN THE NEBRODY MOUNTAIN RANGE IN NE SICILY. 
A photovoltaic plant has been constructed to supply the power necessary for activating a trash rack rake and 4 sliding gates belonging to the intake of the Bracalla Torrent, located in the watershed of the Ancipa Dam.

The system has been monitored for the whole of 1990. Activation of the gates for the gravel and sand clarification beds has always worked automatically. The trash rack rake operated automatically during the spring and autumn and was operated manually during the summer. During this first year of operation, the photovoltaic plant was always able to supply the power necessary for the hydraulic equipment. However, this was a year of particularly low precipitation and several times on a typical day the photovoltaic arrays had to be disconnected from the electrical equipment to prevent the voltage corresponding to battery boiling point from being exceeded.

The data acquisition systems also worked efficiently and the most heavily stressed component was the control system which had to continually regulate the flow of powder from the photovoltaic arrays to the batteries.
THIS SPILLWAY IS ONE OF FIVE WHOSE WATERS FLOW INTO ANCIPA RESERVOIR, ONE OF SICILIAN BIGGEST HYDROPOWER PLANTS. ALONG ITS COURSE, THE RIVER BRACALLA ENCOUNTERS A SCREEN LOCATED AT THE INTAKE OF THE TUNNEL CANAL FLOWING INTO ANCIPA RESERVOIR. 
 A TRASH-RACK RAKE REMOVES LARGE STONES FROM THE SCREEN, WHILE TWO OF THE FOUR SLIDING GATES ARE OPERATED IN SUCH A WAY AS TO PREVENT GRAVEL AND SAND FROM ENTERING THE RESERVOIR. THE OTHER TWO GATES ARE USED, WHEN SAFETY DEMANDS IT, TO PREVENT WATER FROM FLOWING TO THE ANCIPA DAM. 
THE TOTAL AMOUNT OF ELECTRIC POWER REQUIRED DAILY BY THE LOAD IS LOW, A 1.5 KWP PV PLANT WITH 500 AH E.C. STORAGE BEING SUFFICIENT TO OPERATE THE HYDRAULIC CONVERTER DRIVING THE RAKE AND THE GATES. 
ENEL REGARDS THIS PILOT PLANT AS A PROTOTYPE FOR FUTURE SIMILAR APPLICATIONS IN REMOTE MOUNTAINOUS LOCATIONS. 
AS THE END OF THE YEAR 1988 THE FINAL DESIGN OF THE PLANT HAS BEEN ACCOMPLISHED. THE SUPPLYING OF THE MAIN APPARATUS (BATTERIES, DATA ACQUISITION SYSTEMS ETC.) IS IN PROGRESS. 
THE PLANT WILL BE IN OPERATION BY JUNE 1989 AND THE DATA ACQUISITION WILL START SOON AFTER.";;;;CSC;Ente Nazionale per l'Energia Elettrica SpA (ENEL);IT;CONPHOEBUS SCRL - ISTITUTO DI RICERCHE PER LE ENERGIE RINNOVABILI E IL RISPARMIO ENERGETICO;IT;
11748;FI1W0104;PAGIS II;;FP1-RADWASTOM 3C;;FP1;SUMMARY AND REVIEW OF PAGIS- PHASE 2.;01/09/1986;31/03/1988;;"THE OBJECTIVES OF THE WORK ARE : 

 - TO PREPARE A SUMMARY OF THE RESULTS AND CONCLUSIONS OF THE PERFORMANCE ASSESSMENTS OF THE REPOSITORIES FOR HLW IN DEEP GEOLOGICAL FORMATIONS COVERING FOUR OPTIONS (CLAY, GRANITE, SALT AND THE SUB-SEABED) OF THE PAGIS PROJECT. 

 - TO REVIEW CRITICALLY THE BASIS, METHODS, MODELS AND DATA USED FOR THE PERFORMANCE ASSESSMENTS AND TO PREPARE A REPORT SETTING OUT COMMENTS AND SUGGESTIONS RELEVANT TO FURTHER ACTIONS OF THE PAGIS PROJECT. 

THE 'SUMMARY' REPORT IS INTENDED FOR PUBLICATION. THE 'COMMENTS AND SUGGESTIONS' REPORT IS FOR USE  BY THE COMMISSION AND THE PAGIS SECRETARIES.
The main objectives were:
 to coordinate an effort at European level on performance assessment of nuclear waste disposal;
 to promote a series of coordinated safety assessment studies on the most promising options to demonstrate the feasibility of the disposal practice and the capability of European teams to perform all the steps of a complex assessment on specific disposal sites;
 to provide guidance for the research and development programmes on waste immobilisation and confinement;
 to improve exchange among the European Community member states on the various options and variants studied;
 to reinforce the confidence in, and confirm the feasibility of, the disposal practice.
B1. DISCUSSIONS WITH THE REPRESENTATIVES OF THE CEC AND AGREEMENT OF THE STUDY BASIS, INCLUDING IDENTIFICATION OF THE REFERENCE PROJECT REPORTS. 

B2. COLLATION AND INITIAL REVIEW OF THE PAGIS PHASE I, AND AS THEY BECAME AVAILABLE, PHASE II DOCUMENTS AND SUPPORTING MATERIAL. 

B3. DISCUSSIONS WITH PAGIS SECRETARIES AND OTHER RELEVANT ORGANISATIONS, WITH THE AIMS OF ASSESSING BACKGROUND AND CLARIFYING PUBLISHED MATERIAL. 

B4. PREPARATION OF A DRAFT 'SUMMARY' REPORT OF 200 TO 250 PAGES, GIVING COMPREHENSIVE COVERAGE OF THE RESULTS AND CONCLUSIONS OF THE PERFORMANCE ASSESSMENTS FOR THE FOUR GEOLOGICAL OPTIONS. 

B5. DETAILED CRITICAL REVIEW OF THE APPROACH, THE METHODOLOGIES, MODELS AND DATA, AND PREPARATION OF A DRAFT 'COMMENTS AND SUGGESTIONS' REPORT. 

B6. COLLATION WITH THE PAGIS SECRETARIES AND THE CEC REPRESENTATIVES TO PRODUCE FINAL VERSIONS OF THE TWO REPORTS. 

B7. PRODUCTION OF MASTER COPIES OF THE FINAL REPORTS.";;;;CSC;Associated Nuclear Services Ltd;UK;;;
11775;FI1W0042;PACOMA;;FP1-RADWASTOM 3C;;FP1;ACQUISITION OF SUBJECTIVE DATA FOR USE IN MODELS FOR WASTE SITE ASSESSMENTS;01/08/1986;30/06/1989;;"IN THE MODELLING OF RADIONUCLIDE MOVEMENT FROM A REPOSITORY, A COMPROMISE MUST BE ACHIEVED BETWEEN ACCURACY AND COST. FOR PROBABILISTIC SITE ASSESSMENT USING MONTE CARLO SIMULATION, ONE DIMENSIONAL MODELS ARE USED DUE TO THEIR SMALL COMPUTATIONAL COST WHEREAS FOR DETERMINISTIC MODELLING MORE DETAILED TWO- AND THREE-DIMENSIONAL MODELS ARE USED. THE OBJECTIVES OF THIS PROGRAMME OF WORK ARE TO DEVELOP AND DEMONSTRATE CONSISTENT DATA ACQUISITION AND PREPARATION TECHNIQUES FOR PROBABILISTIC SITE ASSESSMENT AND FOR DETAILED DETERMINISTIC MODELLING OF RADIONUCLIDE MOVEMENT FROM A REPOSITORY FOR INTERMEDIATE LEVEL WASTE UNDER THE HARWELL SITE/.A COMPARISON OF RADIONUCLIDE RISKS DERIVED FROM BOTH ASSESSMENT PROCEDURES WILL BE MADE AND ANY INCONSISTENCIES IN THE INPUT DATA AND RESULTING INCONSISTENCIES IN THE RISK ESTIMATES WILL BE INVESTIGATED. 
The objectives of the work were as follows:
 to develop and demonstrate consistent data acquisition and preparation procedures for probabilistic risk assessment, and for detailed deterministic modelling, of radionuclide movement from a hypothetical repository for intermediate level waste;
 to carry out a comparison of the results derived from both assessment procedures;
 to qualify any inconsistencies in input data;
 to investigate the reasons for any inconsistencies in the model results.
B1. RESEARCH PROGRAMME : DEVELOPMENT OF METHODOLOGY FOR COMPARING PROBABILISTIC SITE ASSESSMENT CODES AND DETAILED DETERMINISTIC MODELS; PLANNING FOR THE DATA ACQUISITION EXERCISE. 

B2. DATA ACQUISITION : THE USE OF EXPERT OPINION TO ACQUIRE DATA FOR 5 TO 10 PARAMETERS. 

B3. MODEL COMPARISON : COMPARISON OF INPUT DATA AND EXPECTED RISKS.";;;;CSC;Principia Mechanica Ltd;UK;;;
8485;1570;ESCA;;FP1-ESPRIT 1;;FP1;Application of Expert Systems to Industrial Chemical Analysis;16/03/1987;16/09/1989;;"The ESCA project aimed to replicate a specific area of human expertise in chromatography and chemistry by artificial intelligence systems. There were two main areas of research: the formalisation of the knowledge base in this area, and the selection of the most suitable expert system shells and tools to represent this type of knowledge base. 
The first work-package was to select a suitable specific area of chromatography application to pharmaceutical analysis, where the knowledge is sufficiently established to provide a valid test of an artificial intelligence system. 
The second work-package was to formalise the knowledge of this specific area by a set of logical rules and facts suitable for expression as an expert system. 
It was planned to select about eight candidate shells and tool sets and to evaluate their suitability for representing this type of knowledge. The next step was make a selection of three of these candidates for the implementation task. 
The application of AI to chemometrics, ie the use of mathematical techniques for setting up experiments and for analysing the results, was to be examined. 
The final product was to be a comparison of the performance of these three expert systems (using different characteristics, but with identical knowledge) for real chemical analyses. 
The project aimed to replicate a specific area of human expertize in chromatography and chemistry by artificial intelligence systems. There were 2 main areas of research: the formalization of the knowledge base in this area, and the selection of the most suitable expert system shells and tools to represent this type of knowledge base. The first work package was to select a suitable specific area of chromatography application to pharmaceutical analysis, where the knowledge is sufficiently established to provide a valid test of an artificial intelligence system. The second work package was to formalize the knowledge of this specific area by a set of logical rules and facts suitable for expression as an expert system. The application of artificial intelligence (AI) to chemometrics, ie, the use of mathematical techniques for setting up experiments and for analysing the results, was examined. High performance liquid chromatography (HPLC) was chosen as the area of application. Three expert system developement tools were selected from the 8 evaluated. The acquisition of knowledge from each of the application domains, which together cover the entire area of method development in HPLC, was completed. its representation in the form of several expert systems was carried out, and integration into one system (from the chemist's point of view) was achieved.
High Performance Liquid Chromatography (HPLC) was chosen as the area of application. Three expert system development tools were selected from the eight evaluated. The acquisition of knowledge from each of the application domains, which together cover the entire area of method development in HPLC, was completed. Its representation in the form of several expert systems was carried out, and integration into one system (from the chemist's point of view) was achieved. 
The presentation of the results at international symposia has increased awareness of the field and heightened debate about the issues involved. 
Exploitation 
Chromatography is a major analytical tool in pharmaceutical research. However, its use requires the selection of a suitable chromatographic method and the optimisation of parameters for each analysis. At present these actions are dependent on the skills of an expert chromatographer. 
The ESCA project aimed to alleviate this situation by developing the application of expert systems to a real-life analytical problem: method development for the analysis of novel compounds in the pharmaceutical industry. 
The experience and knowledge gained through the prototypes developed and the comparison studies carried out will accelerate the introduction of expert systems in real-life industrial applications related to chemical domains.";;;;;PHILIPS SCIENTIFIC;UK;"KATHOLIEKE UNIVERSITEIT NIJMEGEN;VRIJE UNIVERSITEIT BRUSSEL;ORGANON INTERNATIONAL BV";"NL;BE";
8810;1636;CATHEDRAL;;FP1-ESPRIT 1;;FP1;Advanced Algorithms, Architecture and Layout Techniques for VLSI Dedicated Signal-Processing Chips;01/09/1983;01/09/1988;;"The objectives were to produce: 
-A set of methods, algorithms and CAD tools for the design of digital signal processing chips in state-of-the-art CMOS technology using new advanced optimised circuit techniques and clocking schemes. 
-Tools to support formal as well as interactive design from specifications down to chip layout. The CAD tools so produced should be capable of optimising chip area and power dissipation for given system requirements. 
Design methodologies and the appropriate design tools for several specific digital signal processing architectures have been developed. These architectures are: 
A.Bit-Serial architecture 
B.Cooperating Datapath architecture: restricted to linear pipelined bit-parallel hardwired structures within the project 
C.Pipelined Regular Array structures: restricted to systolic or semi-systolic arrays within the project 
D.Micro-coded Multi-Processor structures. 
The objectives were to produce:
a set of methods, algorithms and computer aided design (CAD) tools for the design of digital signal processing chips in state of the art complementary metal oxide semiconductor (CMOS) technology using new advanced optimised circuit techniques and clocking schemes;
tools to support formal as well as interactive design from specifications down to chip layout.

Design methodologies and the appropriate design tools for several specific digital signal processing architectures have been developed. These architectures are:
bit serial architecture;
cooperating datapath architecture (restricted to linear pipelined bit parallel hardwired structures);
pipelined regular array structures (restricted to systolic or semisystolic arrays);
micro coded multiprocessor structures.
The operating environment is as follows :
Computer aided design (CAD) and design methodologies
A.Bit-Serial 
The work on the hardwired bit-serial architecture has resulted in a complete set of integrated tools to specify a filter, synthesise it in a wave digital form, simulate it on different levels, optimise the coefficients and the data-wordlengths, map the algorithm - including the control - into the bit-serial primitives and generate the complete layout. 
A study of design methods for two-dimensional wave digital filters with approximately circular symmetry has been made. Besides the design of two-dimensional cross-antimetric filters, a new method has been worked out, which can be extended to any number ofdimensions. Several structures for two-dimensional antimetric filters have been developed with a high degree of modularity. 
The whole integrated CAD package, which is a fully operational silicon compiler from specifications to layout,is called CATHEDRAL-I. 
B.Cooperating Datapath 
A novel carry-save technique and special circuit cells for overflow protection have been studied and documented with the intention of achieving a 100 MHz clocking rate in a modern CMOS technology. This is very important in order to achieve the performanceaimed at, for example, in the RACE programme, with more traditional and therefore cheaper technologies than GaAs. The set of software tools that has been developed is embedded in the CATHEDRAL-III environment. 
C.Regular Array 
 A standard module library which can be used to span most of the arithmetic-intensive operations in the area of image processing has been derived, and a composition methodology has been studied which can later be translated in a set of synthesis tools for regular array structures (not part of this project). 
Self-test approaches for the concurrent sorting architecture have been investigated. A fault coverage of 100% for stuck-at and up to 99.6% for stuck-open faults have been obtained for a bit-serial word sorter. Two word-parallel bit-serial sorting networkshave been implemented using MGE. The circuits occupy areas of 13.6 mm2 and 36.6 mm2 respectively. 
D.Multi-Processor 
 The main emphasis was placed on this type of architecture. It is most suited for a large majority of applications in the spectrum up to 1 MHz sample rate and it addresses the implementation of more general real-time algorithms. The design methodology for this architecture has been derived from four large applications in speech processing and telecommunications. 
This work resulted in a true silicon compiler, CATHEDRAL-II. It translates a behavioural, flowgraph-type algorithm description, expressed in the SILAGE language, into a dedicated multi-processor architecture. It allows the system designer to investigate and compare in an interactive way a number of silicon implementations of a certain digital signal processing algorithm. 
The datapath of the chip is constructed from a customised set of parameterisable execution units. This customised datapath is generated automatically from the high-level behavioural specification. The set of available execution units is restricted to six:ALU/shift, Address Computation Unit, multiplier/accumulator, comparator, normaliser, RAM/FIFO. A study has been made on the interprocessor communication protocols, addressing techniques and bus interconnection strategy. The results have been embedded ina software tool outside the scope of the project (IMEC). 
 Although the first CATHEDRAL-II prototype showed very promising results, the different exercises that have been done have shown that the inference mechanism, as implemented, was not efficient enough for larger examples and missed the robustness to handle complicated nestings of loops and conditionals. A new inference mechanism was therefore implemented, based on demand-driven rule firing, by which a higher efficiency is reached for much more complex examples (IMEC). 
Exploitation 
A.Bit-Serial 
CATHEDRAL-I has already been installed at different universities, research institutes and companies throughout the world. Besides installation at the partner sites, the software is also used at, amongst others, Italtel, RCA, University of California (Berkeley, USA), University of Lund (Sweden), Institut de Microtechnique de l'Universit de Neuchtel (Switzerland), University of So Paulo (Brazil), etc. 
The CAD system has been successfully applied to the design of a viewdata filter (Philips, IMEC) and to the design of a PCM-FDM Transmultiplexer with a complexity of 35 000 transistors (Siemens, IMEC). 
B.Cooperating Datapath 
CATHEDRAL-III is oriented to the efficient synthesis of high-throughput digital signal processing circuits in which the clock rate/sample rate ratios vary between one and twenty. 
A bit-parallel digital transversal filter, with real-time programmable coefficients, has been designed in a 1.5 micron CMOS technology. It has been measured and verified for a clock rate of up to 50 MHz. A third-order wave digital filter has been designedby Siemens, and implemented on chip. The total chip area is 14.7 mm2 (in a 2 micron CMOS technology) and the maximum measured clock rate is 50 MHz. 
Other demonstrators are the integration of a Cordic algorithm and a digital video signal convertor (RGB to luminance/chrominance) with decimation filters (DMF). This last application will be used in a 140 Mbit/s video codec in order to replace analogue circuitry. The design is suitable for implementation with a 1.5 micron CMOS technology, yielding a chip with about 80 000 transistors on a total chip area of about 35 mm2 (Siemens, IMEC). 
C.Regular Array 
At IMEC, architectures for the distance computation unit in a video codec have been investigated in cooperation with Alcatel/Bell Telephone. In addition, several efficient semi-systolic architectures for one-dimensional and two-dimensional running order statistics filters have been developed. 
D.Multi-Processor 
Different instances of almost all required execution units have been put on MPC in a 3 micron and a 2.4 micron double-metal CMOS technology and tested successfully. This has been done partly outside the scope of project (by IMEC). A 1.6 micron version hasbeen developed by Philips, also outside the scope of the project. 
From this, a powerful microcode ROM based multi-branch controller architecture has been selected (IMEC, Philips), though other architectures such as a simple FSM can also be incorporated. Alcatel/Bell has studied one particular controller architecture, the binary decision machine, and has translated this into a set of specifications for dynamic ROM and RAM structures. 
The CATHEDRAL-II version, as delivered at the end of the project, has proven its usefulness in different applications. Within Philips, CATHEDRAL-II has been used in order to build PIRAMID, an operational silicon compiler fitted to Philips' requirements. Different designs have been completed. CATHEDRAL-II and PIRAMID are being used intensively within IMEC, Philips and Alcatel/Bell Telephone. 
EDC (European Development Centre), a research and development organisation located in Leuven, Belgium, jointly owned by Mentor Graphics, Philips International BV and IMEC, is using and commercialising the major results of the project. The resulting products and technologies will be distributed by Mentor Graphics as part of their Falcon Framework.";;;;;IMEC VZW;BE;"BELL TELEPHONE MFG CO NV;PHILIPS DUPONT OPTICAL;EUROPEAN DEVELOPMENT CENTER;Siemens Nixdorf Informationssysteme AG;RUHR-UNIVERSITY BOCHUM";"BE;NL;DE";
8471;1258;TRUST;;FP1-ESPRIT 1;;FP1;Testing and Consequent Reliability Estimation for Real-Time Embedded Software;17/11/1986;17/11/1989;;"The objective of TRUST was to assess the impact of the major current design methods on the testability and reliability of software. The aim was to generate software which was not only testable but, by virtue of its intrinsic structure, more reliable.The approach included investigating development method characteristics and measuring progress through the use of tools especially developed within TRUST. 
The objective was to assess the impact of the major current design methods on the testability and reliability of software. The aim was to generate software which was not only testable but, by virtue of its intrinsic structure, more reliable. The approach included investigating development method characteristics and measuring progress through the use of tools especially developed within the project. A survey of languages (high and low level) for real time embedded systems was completed. This survey included the identification of the characteristic features of these languages, varying between generations and levels, which impact on the ability to test real time embedded systems. These characteristics were found to include hardware and input/output support, concurrent task support, and exception handling. Analysis of source host/target communication was completed. This also identified the key features, such as speed and capacity, that are affected by host/target communication mechanisms. Surveys of software test usage and testing tools were completed. Statistics and metrics for software reliability and scope were identified, and a first analysis tool written for several assembler languages. An interactive mutation tool was developed. The following tools and prototypes were developed for use in monitoring and analysing real time systems embedded in target computers: a communication box (ComBox) which facilitates communication between software systems embedded in a target computer and a host computer; a set of modules to be incorporated into an existing testbed to provide statistical reports from statistics accumulated over many analysis runs; and 2 prototypes of efficient source code instrumentors.
Results were as follows: 
 -A survey of languages (high and low level) usable for real-time embedded systems was completed. This survey included the identification of the characteristic features of these languages, varying between generations and levels, which impact on the abilit y to adequately test real-time embedded systems. These characteristics were found to include hardware and I/O support, concurrent task support, and exception handling. 
-Analysis of source host/target communication was completed. This also identified the key features, such as speed and capacity, that are affected by host/target communication mechanisms. 
-Surveys of software test usage and testing tools were completed. 
-Statistics and metrics for software reliability and scope were identified, and a first analysis tool written for several assembler languages. 
-An interactive mutation tool was developed. 
The following tools and prototypes were developed for use in monitoring and analysing real-time systems embedded in target computers: 
-ComBox: a communication box which facilitates communication between software systems embedded in a target computer and a host computer. 
-Statistical Profiler: a set of modules to be incorporated into an existing testbed to provide statistical reports from statistics accumulated over many analysis runs. 
-CS-Testbed and IL-Testbed: two prototypes of efficient source code instrumentors. 
Exploitation 
The results of the TRUST project will help to assess the real-time and host/target aspects of software products during the test and development phases. This will provide data for management control. The prototype tools developed provide a basis for commercial products.";;;;;University of Liverpool;UK;"Software Engineering Services GmbH;City University;John Bell Technical Systems Ltd;Liverpool Data Research Association";"DE;UK";
8455;1063;INSTIL;;FP1-ESPRIT 1;;FP1;Integration of Symbolic and Numeric Learning Techniques;01/10/1985;01/10/1988;;"The objective of INSTIL was to improve knowledge acquisition for knowledge-based systems by the application of machine learning techniques. The method of knowledge acquisition to be developed was the generation of a knowledge-base from an analysis of examples of sets of field data by the formulation of rules in the application domain. 
The project set out to identify the best features from different approaches to knowledge acquisition, in order to improve the quality of rules extracted from noisy data. Use was made of existing software: MAIN, based on Michalski's INDUCE and AQ11, a symbolic learner; AGAPE and AGAPE-C, which use theorem-proving techniques and taxonomies of descriptors of example sets; and NEDDIE, an extended version of Quinlan's ID3, which uses numerical manipulation to constrain its search space. 
The objective was to improve knowledge acquisition for knowledge-based systems by the application of machine learning techniques. The method of knowledge acquisition developed was the generation of a knowledge base from an analysis of examples of sets of field data by the formulation of rules in the application domain. The project set out to identify the best features from different approaches to knowledge acquisition, in order to improve the quality of rules extracted from noisy data. Use was made of existing software: MAIN, a symbolic learner; AGAPE and AGAPE-C, which use theorem providing techniques and taxonomies of descriptors of example sets; and NEDDIE, which uses numerical manipulation to constrain its search space. Improved versions were produced of the programs and ported to the chosen development environment. Prototypes integrating MAIN, NEDDIE and AGAPE were completed and distributed for experimentation. The most promising prototype used MAGGY (augmented AGAPE) to generalize cluster descriptions obtained by NEDDIE. This prototype forms the basis of the system, which is now being finalized and documented. An object oriented representation language, the generalization oriented language (GOL), was implemented and documented. It is used to represent background knowledge, examples, and the rules synthesised by the system. The integrated learning system is being strengthened by studies on dealing with noise in knowledge acquisition. The system has ben tested on several large-scale applications in various domains including agriculture (diagnosis of disease in crops), image understanding (object recognition, mosquito recognition, medical diagnosis, air traffic control, and fault recognition in turbine generators.
An example application was demonstrated to show integrated learning of rules using symbolic and numerical methods. 
Improved versions were produced of the programs previously developed separately by project team members at their locations, and ported to the chosen development environment. Prototypes integrating MAIN, NEDDIE and AGAPE were completed and distributed to the partners for experimentation. The most promising prototype used MAGGY (augmented AGAPE) to generalise cluster descriptions obtained by NEDDIE. This prototype forms the basis of the INSTIL system, which is now being finalised and documented. An object-o riented representation language, the generalisation-oriented language (GOL), was implemented and documented. It is used to represent background knowledge, examples, and the rules synthesised by INSTIL. The integrated learning system is being strengthened by studies on dealing with noise in knowledge acquisition. 
The INSTIL system has been tested on several large-scale applications in various domains including agriculture (diagnosis of disease in crops), image understanding (object recognition), mosquito recognition, medical diagnosis, air traffic control, and fault recognition in turbine generators. 
Exploitation 
It is expected that the lessons learned will be incorporated in tool environments for expert system construction in the form of an automatic rule refinement and acquisition module. The final prototype of this module and a complete user manual is now available. 
Cognitech intends to enhance the set of expert systems under development for diagnosing disease in 30 different crops by the addition of an automatic rule-refinement and acquisition module. Cognitech also intends to incorporate a similar rule-learning module in their integrated laboratory for teaching AI. 
GEC-RL intends to link a rule-learning element from INSTIL to a tool environment for expert system construction with which they are involved. 
Test sites of an industrial, commercial, or medical nature are being sought for the INSTIL system. GEC and the University of Paris are using INSTIL in traffic control, case law deduction, and the identification of address locations on parcels. 
Results from INSTIL have been incorporated in ESPRIT project 2154, MLT (Machine Learning Toolbox).";;;;;GEC Marconi Research Centre;UK;"Framentec Cognitech SA;Université de Paris XI (Université Paris-Sud)";FR;
8657;890;PANGLOSS;;FP1-ESPRIT 1;;FP1;Parallel Architecture for Networking Gateways Linking OSI Systems;01/01/1986;01/01/1990;;"The primary goal of the PANGLOSS project was to develop a systematic design and development methodology for concurrent systems which would reduce the amount of compromise and resolve the inconsistencies commonly encountered in the early stages of a designprocess. 
The main aims were to: 
-define a methodology for the development of concurrent systems 
-define a gateway architecture for the interworking of OSI system networks 
-design a high-performance network gateway using the defined methodology. 
In addition, and by way of proving the methodology, the project aimed to design a high-performance network gateway for linking OSI systems using the PANGLOSS method. Whilst the methodology can be applied to concurrent systems in general, the choice of a gateway was seen as a sufficiently difficult target for testing the usability method. This is because of the predicted need for high traffic loads and transfer rates for gateways if they are to meet the demands of the new networking technologies (such as local area networks, satellite links, fibre optics, broadband systems, and integrated services digital networks). 
The primary goal of the parallel architecture for networking gateways linking open systems interconnection (OSI) systems (PANGLOSS) project was to develop a systematic design and development methodology for concurrent systems which would reduce the amount of compromise and resolve the inconsistencies commonly encountered in the early stages of a design process.

The PANGLOSS method relied on the use of a reference architecture, obtained and refined during the lifetime of the project by a process of abstraction from a number of well defined scenarios, from which an implementation design was then developed. The design process was guided at each stage by performance considerations which provide feedback to both the architectural and implementation work. Performance objectives were met by modular design and flexible topologies so that modules could be added when performance requirements increased. An important feature of the project the project was the use of formal methods as a design tool. This enabled the design process to be verified at each stage to show logical consistency and conformity to objectives. The project demonstrated the feasibility of the method, though for widespread industrial use more tools to support the formal processes are required. The method is in use in adapted form. The example design of the gateway was produced to demonstrate the method, and could form the basis of a family of gateway products.
The PANGLOSS method relies on the use of a reference architecture, obtained and refined during the lifetime of the project by a process of abstraction from a number of well-defined scenarios, from which an implementation design can then be developed. The design process is guided at each stage by performance considerations which provide feedback to both the architectural and implementation work. Performance objectives are met by modular design and flexible topologies so that modules can be added when performance requirements increase. An important feature of the project was the use of formal methods as a design tool. This enabled the design process to be verified at each stage to show logical consistency and conformity to objectives. 
The project demonstrated the feasibility of the method, though for widespread industrial use more tools to support the formal processes are required. The method is in use in adapted form. The example design of the gateway was produced to demonstrate the method, and could form the basis of a family of gateway products.";;;;;Cap Scientific Ltd;UK;"UNIV DE LIEGE;University of Reading;UNIV VAN TWENTE;7-TECHNOLOGIES A/S";"BE;UK;NL;DK";
8637;1600;FAOR;;FP1-ESPRIT 1;;FP1;Functional Analysis of Office Requirements;01/09/1984;01/07/1987;;"The FAOR project aimed to develop a methodology to identify and evaluate the requirements which determine the design of office systems set up to achieve particular organisational objectives. The main aims were to: 
-Develop and validate a methodology for understanding a client's objectives in improving the operation of their office. 
-Apply the methodology, adapted for each client study and based on an understanding of the client's objectives, to assist the client in understanding the task in hand. 
-Determine the client's IT requirements in order to improve their ability to meet their objectives. 
-Develop a cost-benefit analysis method able to clearly and concisely demonstrate both the tangible and intangible costs and benefits to clients of alternative IT options. 
-Develop a generic model of the office, together with a means of tailoring the model to reflect specific office categories. In the pre-analysis phase this helped synthesise a tailored version of the generic methodology. 
 -Define a formal approach to multi-client surveys. This involved the determination of mechanisms for abstracting, from a number of client studies, a generic or multi-client view of IT requirements. (These requirements could have been used to plan researc h and development for future IT products, though such product planning did not, however, form part of the FAOR project.)
The project aimed to develop a methodology to identify and evaluate the requirements which determine the design of office systems set up to achieve particular organisational objectives.

Several different methodological and modelling components were brought together to form a comprehensive approach to the analysis of information technology (IT) requirements. This approach was structured around a loose procedural framework of analytical activities called the activity framework. The main activities were: office exploration, method tailoring, and requirements analysis and evaluation. The soft system methodology (SSM) was employed as a general framework for coordinating the analytical activities and as a conceptual basis for determining requirements for changing the office organization.
A generic office frame of reference (GOFOR), supported by a library of perspectives, was developed. This made it easier to understand the different office perspectives and assist in the client specific tailoring of models and methodologies. GOFOR contains the reference base of office knowledge structured as multiple perspectives and formally described with the aid of Petri nets. Various instruments provided tools, techniques and applications guidelines for the practical application of the multiple perspectives in a client investigation. A benefits analysis framework was also produced to support the evaluation of requirements and changes represented by a proposed office system.
FAOR drew together several different methodological and modelling components to form a comprehensive approach to the analysis of IT requirements. This approach was structured around a loose procedural framework of analytical activities called the Activity Framework. The main activities were: office exploration, method tailoring, and requirements analysis and evaluation. FAOR employed the Soft System Methodology (SSM), developed by Peter Checkland, as a general framework for coordinating the analytical act ivities and as a conceptual basis for determining requirements for changing the office organisation. 
A Generic Office Frame of Reference (GOFOR), supported by a library of perspectives, was developed. This made it easier to understand the different office perspectives (information, function, task, communication, resource, time and personnel) and assist in the client-specific tailoring of models and methodologies. GOFOR contains the reference base of office knowledge structured as multiple perspectives and formally described with the aid of Petri-nets. Various instruments provided tools, techniques and applications guidelines for the practical application of the multiple perspectives in a client investigation. 
A benefits analysis framework was also produced to support the evaluation of requirements and changes represented by a proposed office system. Practical evaluation of the methodology was aided by a field study at Essex County Council in England. 
Exploitation 
A comprehensive final report covering the whole FAOR approach and including extensive application guidelines has been published as a book. 
The results of the project were further developed in project projects 813, TODOS, and 1030, IT-UPTAKE.";;;;;BNR Europe Ltd;UK;"Universität Köln;Gesellschaft für Mathematik und Datenverarbeitung mbH;THE EAST ASIATIC COMPANY LTD";"DE;DK";
8467;1257;MUSE;;FP1-ESPRIT 1;;FP1;Software Quality and Reliability Metrics for Selected Domains: Safety Management and Clerical Systems;01/01/1987;01/01/1990;;"The objective of MUSE was to produce demonstrable quality and reliability metrics focused on three specific application domains: safety, management and clerical systems. These metrics were applied to real software development projects to provide experimental trials data and user reactions for their analysis and evaluation. The research staff included specialists from the fields of software engineering, artificial intelligence, human factors and statistics. In addition, external fields such as construction, engineering and manufacturing were surveyed to see if they had quality and reliability paradigms of relevance to software. 
In addition to researching and testing both domain-specific metrics and generic metrics for the selected areas, the project sought to establish a basis for new generation metrics using AI methods. 
The objective was to produce demonstrable quality and reliability metrics focused on 3 specific application domains: safety, management and clerical systems. These metrics were applied to real software development projects to provide experimental trials data and user reactions for their analysis and evaluation. In addition to researching and testing both domain specific metrics and generic metrics for the selected areas, the project sought to establish a basis for new generation metrics using artificial intelligence (AI) methods. Following a comparative survey in USA and Europe, the quality and reliability metrics and factors for use in the project were selected. The project achieved a discrimination between 3 applications (clerical, management and safety systems), which is new and probably quite marketable. Many other relevant activities and studies were pursued, such as on usability, on the relation between prototyping and metrics, and on software quality aspects of trans-European information systems. Demonstrations were made of: SAMSON, an expert system for measuring and assessing the quality of safety critical systems; SMACK, the use of quality tools integrated within a smalltalk environment; and ATHENA, tools for complexity measurements and maintenance assistance.
Following a comparative survey in USA and Europe, the quality and reliability metrics and factors for use in the project were selected. 
The project achieved a discrimination between three applications (clerical, management and safety systems), which is new and probably quite marketable. 
Many other relevant activities and studies were pursued, such as on usability, on the relation between prototyping and metrics, and on software quality aspects of trans-European information systems. 
The project was involved in UK and ISO standard software Q & R panels. 
Demonstrations were made of: 
-SAMSON, an Expert System for measuring and assessing the quality of safety critical systems 
-SMACK, the use of quality tools integrated within a smalltalk environment 
-ATHENA, tools for complexity measurements and maintenance assistance. 
A MUSE Metrics Handbook book has been issued which also outlines all the main project results. 
Activities are now supported by partners through projects 5494 (AMI) and 5425, PYRAMID. 
Relations with Japanese quality societies have been established. 
Exploitation 
Software quality and reliability metrics in the field of safety, management and clerical systems are of immediate interest for the European IT industry, and all project deliverables which are public can be requested to the project consortium. 
The SAMSON prototype is to become a commercial product being already requested for use by several companies.";;;;;Brameur Ltd;UK;"Conception et Réalisation Industrielle de Logiciel (CRIL);EBO;Rheinisch-Westfälischer Technischer Überwachungsverein";"FR;EL;DE";
8341;1480;SACODY;;FP1-ESPRIT 1;;FP1;A High-Performance Flexible Manufacturing System Robot with Dynamic Compensation;01/01/1987;01/01/1991;;"The objective of this project was to develop the necessary know-how to control a high-performance robot for use in Flexible Automated Assembly System (FAAS) environments. The major design aims were to compensate for the reduced rigidity of the mechanical structure, while improving speed of operation and overall static and dynamic control. Solutions to the critical problems associated with active control of articulated non-rigid structures were implemented within a comprehensive software package which, following the modelling of the structural dynamics, permitted computer-aided design of control rules. The programme was as follows: 
-development of innovative sensors, aimed at improving the global positioning accuracy of FMS robots while ensuring tracking and vibration control 
-development of software tools for test and identification, modelling and design of control laws for flexible poly-articulated mechanisms 
-development of sensor systems adapted to the online control of robot vibrations and to the testing of robot performance 
-demonstration of the improvement is performance obtained with the new control methods on an industrial robot. 
In flexible manufacturing system (FMS) robot applications there is a need to compensate for the reduced rigidity of the mechanical structure and to enhance operational speed and overall static and dynamic control. The project partners are developing innovative sensors for improved global positioning accuracy and for assured tracking and vibration control, software tools for the computer aided design (CAD) of control rules for flexible polyarticulated mechanisms, and sensor systems for on line control of robot vibrations and robot performance testing. An industrial robot is used to prove the enhanced performance capability attainable with the new control methods.

Mechanical manipulators exhibit, when submitted to high speed and acceleration rates, vibrations which limit their performances and generate additional stresses on their structure. Up to now, robot designers have solved this problem by building stiff structures, yielding bulky, energy consuming, and expensive robots. An alternative to this solution is proposed, relying on an intensive use of computer aided engineering (CAE) methods such as modal analysis and dynamic modeling. An advanced robot control is used to avoid structural vibrations. The project succeeded in demonstrating on a spot welding robot an antivibration robot control running on industrial hardware. The final results of the ESPRIT project SACODY are presented. Besides the feasibility of active vibration control, the SACODY control approach has shown significant improvements in terms of robot system behaviour and performance. The main advantages of the new control are: an important gain in robot cycle time; a robot positioning without overshooting and vibrations; a reduction of dynamic stresses on the robot structure. This control, which runs on state of the art industrial controller boards, offers a software alternative to the structure stiffening traditionally used to avoid robot vibrations. The fields of application of the antivibration control are very wide, and cover all systems that suffer from lack of structural rigidity. As well as a completely new methodology of servomechanisms control, the results of the project are: a software package for computer aided dynamic analysis; an upgraded software package for the dynamic simulation of flexible multibody systems; a high performance servo level hardware; prototypes of sensor systems for robot testing.

The objective of this project was to develop the necessary know how to control a high performance robot for use in flexible automated assembly system (FAAS) environments. The major design aims were to compensate for the reduced rigidity of the mechanical structure, while improving speed of operation and overall static and dynamic control. Solutions to the critical problems associated with active control of articulated nonrigid structures were implemented within a comprehensive software package which, following the modelling of the structural dynamics, permitted computer aided design (CAD) of control rules.
Improved control and indentification methodologies are available and have been demonstrated on laboratory prototypes. The modelling and simulation software is completed and commercialized. Some of the identification techniques developed have been integrated in commercial versions of computer aided testing (CAT) systems. Development of identification control methods continues and development of sensor systems has been initiated.
Improved control and identification methodologies are available and have been demonstrated on laboratory prototypes. The modelling and simulation software is completed and commercialised. Some of the identification techniques developed have been integrated in commercial versions of Computer-aided Testing (CAT) systems. 
Development of identification control methods continues and development of sensor systems has been initiated. 
Exploitation 
At the end of 1989 the modelling and simulation software was adapted to control design purposes and interfaced with a CAT system. By the end of 1990 a fully operational demonstrator with a new generation industrial robot controller has been completed.";;;;;Bertin & Cie;FR;"KUKA Schweißanlagen und Roboter GmbH;AEG Olympia AG;UNIV COLLEGE DUBLIN;KATHOLIEKE UNIVERSITEIT LEUVEN;LEUVEN MEASUREMENT & SYSTEMS INTERNATIONAL";"DE;IE;BE";
8345;1484;IPCES;;FP1-ESPRIT 1;;FP1;Intelligent Process Control by Means of Expert Systems;18/11/1988;18/11/1992;;"The objective of this project is to develop a set of modular building 
blocks, combining new already available technologies, which can be 
tailored and assembled to perform a range of control system functions 
in small and medium-sized manufacturing enterprises (SMEs).  Typical 
application areas will be process control and online automatic vision 
systems for quality control in the textile, electronic, food, metal 
and automotive industries. 
The principal tasks are to : 
- develop a fully automatic vision system for online product 
inspection, capable of performing ultra-high-speed hardware-based 
feature identification and contact-free measurement 
- develop a process information system with feedback  and visualisation 
capabilities, using colour graphics, process diagrams, product feature 
graphic enhancement and an information hierarchy ranked by urgency and 
importance 
- develop self-learning, self-initiating expert systems working with 
real-time process and product data and with statistically derived 
conclusions to provide suggestions for improved control, diagnoses of 
product defects and prognoses of future system behaviour, either on 
request or on the system's own initiative 
- integration and validation of the prototype system in a real 
manufacturign industry environment.   
The following commercial products are expected to be developed using 
the results of the project : 
- a rapid, high-resolution defect checker, capable of handling a wide 
image field, with possible applications in the quality control of 
lacquering, textile printing, PCB checking, etc 
- a contact-free, high-accuracy measuring system, generally applicable 
to a range of vision systems  
- a process monitoring and supervisory system controlled by an expert 
system. 
The objective of this project is to develop a set of modular building blocks, combining new and already available technologies, which can be tailored and assembled to perform a rang of control system functions in small and medium sized manufacturing enterprises (SME). Typical application areas will be process control and online automatic vision systems for quality control in the textile, electronic, food, metal and automotive industries.
The principle tasks are to: develop a fully automatic vision system for online product inspection, capable of performing ultra high speed hardware based feature identification and contact free measurement; develop a process information system with feedback and visualization capabilities, using colour graphics, process diagrams, product feature graphic enhancement and an imformation hierarchy ranked by urgency and importance; develop self learning, self initiating expert systems working with real time process and product data and with statistically derived conclusions to provide suggestions for improved control, diagnoses of product defects and prognoses of future system behaviour, either on request or on the system's own initiative; integration and validation of the prototype system in a real manufacturing industry environment.";;;;;NEDERLANDSE PHILIPS BEDRIJVEN BV;NL;"Dornier System GmbH;CENTRE D'ESTUDIS AVANCAIS DE BLANES;UNIV POLITECNICA DE CATALUNYA;MINIWATT SA;ELTEC Elektronik GmbH;Philips Composants;CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE";"DE;ES;FR";
